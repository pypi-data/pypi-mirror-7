#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import (absolute_import, division, print_function, unicode_literals)

"""tokenizers. default is the one from nltk"""

from nltk import word_tokenize as nltk_word_tokenize

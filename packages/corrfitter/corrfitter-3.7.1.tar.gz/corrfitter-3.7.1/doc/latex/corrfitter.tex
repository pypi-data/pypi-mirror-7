% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}


\title{corrfitter Documentation}
\date{May 30, 2014}
\release{3.7.1}
\author{G.P. Lepage}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}


Contents:


\chapter{\texttt{corrfitter} - Least-Squares Fit to Correlators}
\label{corrfitter:corrfitter-documentation}\label{corrfitter::doc}\label{corrfitter:corrfitter-least-squares-fit-to-correlators}

\section{Introduction}
\label{corrfitter:introduction}
This module contains tools that facilitate least-squares fits, as functions
of time \code{t}, of simulation (or other statistical) data for 2-point and
3-point correlators of the form:

\begin{Verbatim}[commandchars=\\\{\}]
Gab(t)    =  \PYGZlt{}b(t) a(0)\PYGZgt{}
Gavb(t,T) =  \PYGZlt{}b(T) V(t) a(0)\PYGZgt{}
\end{Verbatim}

where \code{T \textgreater{} t \textgreater{} 0}. Each correlator is modeled using {\hyperref[corrfitter:corrfitter.Corr2]{\code{corrfitter.Corr2}}} for 2-point
correlators, or {\hyperref[corrfitter:corrfitter.Corr3]{\code{corrfitter.Corr3}}} for 3-point correlators in terms of amplitudes for
each source \code{a}, sink \code{b}, and vertex \code{V}, and the energies
associated with each intermediate state. The amplitudes and energies are
adjusted in the least-squares fit to reproduce the data; they are defined
in a shared prior (typically a dictionary).

An object of type {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} describes a collection of correlators and is
used to fit multiple models to data simultaneously. Fitting multiple
correlators simultaneously is important if there are statistical
correlations between the correlators. Any number of correlators may be
described and fit by a single {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} object.

We now review the basic features of \code{corrfitter}. These features are also
illustrated in the context of a real application in an
{\hyperref[corrfitter:annotated-example]{\emph{Annotated Example}}}, at the end.


\section{Basic Fits}
\label{corrfitter:basic-fits}
To illustrate, consider data for two 2-point correlators: \code{Gaa} with the
same source and sink (\code{a}), and \code{Gab} which has source \code{a} and
(different) sink \code{b}. The data are contained in a dictionary \code{data},
where \code{data{[}'Gaa'{]}} and \code{data{[}'Gab'{]}} are one-dimensional arrays
containing values for \code{Gaa(t)} and \code{Gab(t)}, respectively, with
\code{t=0,1,2...63}. Each array element in \code{data{[}'Gaa'{]}} and \code{data{[}'Gab'{]}}
is a Gaussian random variable of type \code{gvar.GVar}, and specifies the mean and
standard deviation for the corresponding data point:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{print} \PYG{n}{data}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Gaa}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+go}{[0.1597910(41) 0.0542088(31) ... ]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{print} \PYG{n}{data}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Gab}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+go}{[0.156145(18) 0.102335(15) ... ]}
\end{Verbatim}

\code{gvar.GVar}s can also capture any statistical correlations between different
pieces of data.

We want to fit this data to the following formulas:

\begin{Verbatim}[commandchars=\\\{\}]
Gaa(t,N) = sum\PYGZus{}i=0..N\PYGZhy{}1  a[i]**2 * exp(\PYGZhy{}E[i]*t)
Gab(t,N) = sum\PYGZus{}i=0..N\PYGZhy{}1  a[i]*b[i] * exp(\PYGZhy{}E[i]*t)
\end{Verbatim}

Our goal is to find values for the amplitudes, \code{a{[}i{]}} and \code{b{[}i{]}}, and the
energies, \code{E{[}i{]}}, so that these formulas reproduce the average values for
\code{Gaa(t,N)} and \code{Gab(t,N)} that come from the data, to within the data's
statistical errors. We use the same \code{a{[}i{]}}s and \code{E{[}i{]}}s in both
formulas. The fit parameters used by the fitter are the \code{a{[}i{]}}s and
\code{b{[}i{]}}s, as well as the differences \code{dE{[}i{]}=E{[}i{]}-E{[}i-1{]}} for \code{i\textgreater{}0} and
\code{dE{[}0{]}=E{[}0{]}}. The energy differences are usually positive by construction
(see below) and are easily converted back to energies using:

\begin{Verbatim}[commandchars=\\\{\}]
E[i] = sum\PYGZus{}j=0..i dE[j]
\end{Verbatim}

A typical code has the following structure:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{corrfitter} \PYG{k+kn}{import} \PYG{n}{CorrFitter}

\PYG{n}{data} \PYG{o}{=} \PYG{n}{make\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{mcfile}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}          \PYG{c}{\PYGZsh{} user\PYGZhy{}supplied routine}
\PYG{n}{models} \PYG{o}{=} \PYG{n}{make\PYGZus{}models}\PYG{p}{(}\PYG{p}{)}              \PYG{c}{\PYGZsh{} user\PYGZhy{}supplied routine}
\PYG{n}{N} \PYG{o}{=} \PYG{l+m+mi}{4}                               \PYG{c}{\PYGZsh{} number of terms in fit functions}
\PYG{n}{prior} \PYG{o}{=} \PYG{n}{make\PYGZus{}prior}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}               \PYG{c}{\PYGZsh{} user\PYGZhy{}supplied routine}
\PYG{n}{fitter} \PYG{o}{=} \PYG{n}{CorrFitter}\PYG{p}{(}\PYG{n}{models}\PYG{o}{=}\PYG{n}{models}\PYG{p}{)}
\PYG{n}{fit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{)}  \PYG{c}{\PYGZsh{} do the fit}
\PYG{n}{print\PYGZus{}results}\PYG{p}{(}\PYG{n}{fit}\PYG{p}{,} \PYG{n}{prior}\PYG{p}{,} \PYG{n}{data}\PYG{p}{)}     \PYG{c}{\PYGZsh{} user\PYGZhy{}supplied routine}
\end{Verbatim}

We discuss each user-supplied routine in turn.


\subsection{a) make\_data}
\label{corrfitter:a-make-data}
\code{make\_data('mcfile')} creates the dictionary containing the data that is to
be fit. Typically such data comes from a Monte Carlo simulation. Imagine that
the simulation creates a file called \code{'mcfile'} with layout

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} first correlator: each line has Gaa(t) for t=0,1,2...63
Gaa  0.159774739530e+00 0.541793561501e\PYGZhy{}01 ...
Gaa  0.159751906801e+00 0.542054488624e\PYGZhy{}01 ...
Gaa  ...
.
.
.
\PYGZsh{} second correlator: each line has Gab(t) for t=0,1,2...63
Gab  0.155764170032e+00 0.102268808986e+00 ...
Gab  0.156248435021e+00 0.102341455176e+00 ...
Gab  ...
.
.
.
\end{Verbatim}

where each line is one Monte Carlo measurement for one or the other
correlator, as indicated by the tags at the start of each line. (Lines for
\code{Gab} may be interspersed with lines for \code{Gaa} since every line has a
tag.) The data can be analyzed using the \code{gvar.dataset} module:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{gvar} \PYG{k+kn}{as} \PYG{n+nn}{gv}

\PYG{k}{def} \PYG{n+nf}{make\PYGZus{}data}\PYG{p}{(}\PYG{n}{filename}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{dset} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{Dataset}\PYG{p}{(}\PYG{n}{filename}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{avg\PYGZus{}data}\PYG{p}{(}\PYG{n}{dset}\PYG{p}{)}
\end{Verbatim}

This reads the data from file into a dataset object (type
\code{gvar.dataset.Dataset}) and then computes averages for each
correlator and \code{t}, together with a covariance matrix for the set of
averages. Thus \code{data = make\_data('mcfile')} creates a dictionary where
\code{data{[}'Gaa'{]}} is a 1-d array of \code{gvar.GVar}s obtained by averaging over the
\code{Gaa} data in the \code{'mcfile'}, and \code{data{[}'Gab'{]}} is a similar array
for the \code{Gab} correlator.


\subsection{b) make\_models}
\label{corrfitter:b-make-models}
\code{make\_models()} identifies which correlators in the fit data are to be fit,
and specifies theoretical models (that is, fit functions) for these
correlators:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{corrfitter} \PYG{k+kn}{import} \PYG{n}{Corr2}

\PYG{k}{def} \PYG{n+nf}{make\PYGZus{}models}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{models} \PYG{o}{=} \PYG{p}{[} \PYG{n}{Corr2}\PYG{p}{(}\PYG{n}{datatag}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Gaa}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{tdata}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tfit}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{,}
                    \PYG{n}{a}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{b}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dE}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}

               \PYG{n}{Corr2}\PYG{p}{(}\PYG{n}{datatag}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Gab}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{tdata}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tfit}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{,}
                    \PYG{n}{a}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{b}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{b}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dE}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
             \PYG{p}{]}
    \PYG{k}{return} \PYG{n}{models}
\end{Verbatim}

For each correlator, we specify: the key used in the input data dictionary
\code{data} for that correlator (\code{datatag}); the values of \code{t} for which
results are given in the input data (\code{tdata}); the values of \code{t} to
keep for fits (\code{tfit}, here the same as the range in the input data, but
could be any subset); and fit-parameter labels for the source (\code{a}) and
sink (\code{b}) amplitudes, and for the intermediate energy-differences
(\code{dE}). Fit-parameter labels identify the parts of the prior,
discussed below, corresponding to the actual fit parameters (the labels are
dictionary keys). Here the two models, for \code{Gaa} and \code{Gab}, are
identical except for the data tags and the sinks. \code{make\_models()} returns
a list of models; the only parts of the input fit data that are fit are
those for which a model is specified in \code{make\_models()}.

Note that if there is data for \code{Gba(t,N)} in addition to \code{Gab(t,N)}, and
\code{Gba = Gab}, then the (weighted) average of the two data sets will be
fit if \code{models{[}1{]}} is replace by:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{Corr2}\PYG{p}{(}\PYG{n}{datatag}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Gab}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{tdata}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tfit}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{,}
     \PYG{n}{a}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n+nb+bp}{None}\PYG{p}{)}\PYG{p}{,} \PYG{n}{b}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{b}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n+nb+bp}{None}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dE}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n+nb+bp}{None}\PYG{p}{)}\PYG{p}{,}
     \PYG{n}{othertags}\PYG{o}{=}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Gba}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{Verbatim}

The additional argument \code{othertags} lists other data tags that correspond
to the same physical quantity; the data for all equivalent data tags is
averaged before fitting (using \code{lsqfit.wavg()}). Alternatively (and
equivalently) one could add a third \code{Corr2} to \code{models} for \code{Gba},
but it is more efficient to combine it with \code{Gab} in this way if they are
equivalent.


\subsection{c) make\_prior}
\label{corrfitter:c-make-prior}
This routine defines the fit parameters that correspond to each fit-parameter
label used in \code{make\_models()} above. It also assigns \emph{a priori} values to
each parameter, expressed in terms of Gaussian random variables (\code{gvar.GVar}s),
with a mean and standard deviation. The prior is built using class
\code{gvar.BufferDict}:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{gvar} \PYG{k+kn}{as} \PYG{n+nn}{gv}

\PYG{k}{def} \PYG{n+nf}{make\PYGZus{}prior}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{prior} \PYG{o}{=} \PYG{n}{gvar}\PYG{o}{.}\PYG{n}{BufferDict}\PYG{p}{(}\PYG{p}{)}       \PYG{c}{\PYGZsh{} prior = \PYGZob{}\PYGZcb{}  works too}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mf}{0.5}\PYG{p}{)} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}\PYG{p}{]}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{b}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{l+m+mf}{5.}\PYG{p}{)} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}\PYG{p}{]}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{l+m+mf}{0.25}\PYG{p}{,} \PYG{l+m+mf}{0.25}\PYG{p}{)} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}\PYG{p}{]}
    \PYG{k}{return} \PYG{n}{prior}
\end{Verbatim}

(\code{gvar.BufferDict} can be replaced by an ordinary Python dictionary;
it is used here because it remembers the order in which the keys are added.)
\code{make\_prior(N)} associates arrays of \code{N} Gaussian random variables
(\code{gvar.GVar}s) with each fit-parameter label, enough for \code{N} terms in the fit
function. These are the \emph{a priori} values for the fit parameters, and they
can be retrieved using the label: setting \code{prior=make\_prior(N)}, for
example, implies that \code{prior{[}'a'{]}{[}i{]}}, \code{prior{[}'b'{]}{[}i{]}} and
\code{prior{[}'dE'{]}{[}i{]}} are the \emph{a priori} values for \code{a{[}i{]}}, \code{b{[}i{]}} and
\code{dE{[}i{]}} in the fit functions (see above). The \emph{a priori} value for each
\code{a{[}i{]}} here is set to \code{0.1\(\pm\)0.5}, while that for each \code{b{[}i{]}} is
\code{1\(\pm\)5}:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{print} \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+go}{[0.10(50) 0.10(50) 0.10(50) 0.10(50)]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{print} \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{b}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+go}{[1.0(5.0) 1.0(5.0) 1.0(5.0) 1.0(5.0)]}
\end{Verbatim}

Similarly the \emph{a priori} value for each energy difference is \code{0.25\(\pm\)0.25}.
(See the \code{lsqfit} documentation for further information on priors.)


\subsection{d) print\_results}
\label{corrfitter:d-print-results}
The actual fit is done by \code{fit=fitter.lsqfit(...)}, which also prints out
a summary of the fit results (this output can be suppressed if desired).
Further results are reported by \code{print\_results(fit, prior, data)}: for
example,

\begin{Verbatim}[commandchars=\\\{\}]
def print\PYGZus{}results(fit, prior, data):
    a = fit.p[\PYGZsq{}a\PYGZsq{}]                              \PYGZsh{} array of a[i]s
    b = fit.p[\PYGZsq{}b\PYGZsq{}]                              \PYGZsh{} array of b[i]s
    dE = fit.p[\PYGZsq{}dE\PYGZsq{}]                            \PYGZsh{} array of dE[i]s
    E = [sum(dE[:i+1]) for i in range(len(dE))] \PYGZsh{} array of E[i]s
    print \PYGZsq{}Best fit values:
    print \PYGZsq{}     a[0] =\PYGZsq{},a[0]
    print \PYGZsq{}     b[0] =\PYGZsq{},b[0]
    print \PYGZsq{}     E[0] =\PYGZsq{},E[0]
    print \PYGZsq{}b[0]/a[0] =\PYGZsq{},b[0]/a[0]
    outputs = \PYGZob{}\PYGZsq{}E0\PYGZsq{}:E[0], \PYGZsq{}a0\PYGZsq{}:a[0], \PYGZsq{}b0\PYGZsq{}:b[0], \PYGZsq{}b0/a0\PYGZsq{}:b[0]/a[0]\PYGZcb{}
    inputs = \PYGZob{}\PYGZsq{}a\PYGZsq{}=prior[\PYGZsq{}a\PYGZsq{}], \PYGZsq{}b\PYGZsq{}=prior[\PYGZsq{}b\PYGZsq{}], \PYGZsq{}dE\PYGZsq{}=prior[\PYGZsq{}dE\PYGZsq{}],
              \PYGZsq{}data\PYGZsq{}=[data[k] for k in data])
    print fit.fmt\PYGZus{}errorbudget(outputs, inputs)
\end{Verbatim}

The best-fit values from the fit are contained in \code{fit.p} and are accessed
using the labels defined in the prior and the {\hyperref[corrfitter:corrfitter.Corr2]{\code{corrfitter.Corr2}}} models. Variables like
\code{a{[}0{]}} and \code{E{[}0{]}} are \code{gvar.GVar} objects that contain means and standard
deviations, as well as information about any correlations that might exist
between different variables (which is relevant for computing functions of the
parameters, like \code{b{[}0{]}/a{[}0{]}} in this example).

The last line of \code{print\_results(fit,prior,data)} prints an error budget for
each of the best-fit results for \code{a{[}0{]}}, \code{b{[}0{]}}, \code{E{[}0{]}} and
\code{b{[}0{]}/a{[}0{]}}, which are identified in the print output by the labels
\code{'a0'}, \code{'b0'}, \code{'E0'} and \code{'b0/a0'}, respectively. The error for any
fit result comes from uncertainties in the inputs --- in particular, from the
fit data and the priors. The error budget breaks the total error for a
result down into the components coming from each source. Here the sources are
the \emph{a priori} errors in the priors for the \code{'a'} amplitudes, the \code{'b'}
amplitudes, and the \code{'dE'} energy differences, as well as the errors in
the fit data \code{data}. These sources are labeled in the print output by
\code{'a'}, \code{'b'}, \code{'dE'}, and \code{'data'}, respectively. (See the
\code{gvar}/\code{lsqfit} tutorial for further details on partial standard
deviations and \code{gvar.fmt\_errorbudget()}.)

Plots of the fit data divided by the fit function, for each correlator, are
displayed by calling \code{fitter.display\_plots()} provided the \code{matplotlib}
module is present.


\section{Faster Fits}
\label{corrfitter:faster-fits}\label{corrfitter:id1}
Good fits often require fit functions with several exponentials and many
parameters. Such fits can be costly. One strategy that can speed things up is
to use fits with fewer terms to generate estimates for the most important
parameters. These estimates are then used as starting values for the full
fit. The smaller fit is usually faster, because it has fewer parameters, but
the fit is not adequate (because there are too few parameters). Fitting the
full fit function is usually faster given reasonable starting estimates, from
the smaller fit, for the most important parameters. Continuing with the
example from the previous section, the code

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{data} \PYG{o}{=} \PYG{n}{make\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{mcfile}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{fitter} \PYG{o}{=} \PYG{n}{CorrFitter}\PYG{p}{(}\PYG{n}{models}\PYG{o}{=}\PYG{n}{make\PYGZus{}models}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{p0} \PYG{o}{=} \PYG{n+nb+bp}{None}
\PYG{k}{for} \PYG{n}{N} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{,}\PYG{l+m+mi}{7}\PYG{p}{,}\PYG{l+m+mi}{8}\PYG{p}{]}\PYG{p}{:}
    \PYG{n}{prior} \PYG{o}{=} \PYG{n}{make\PYGZus{}prior}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}
    \PYG{n}{fit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{,} \PYG{n}{p0}\PYG{o}{=}\PYG{n}{p0}\PYG{p}{)}
    \PYG{n}{print\PYGZus{}results}\PYG{p}{(}\PYG{n}{fit}\PYG{p}{,} \PYG{n}{prior}\PYG{p}{,} \PYG{n}{data}\PYG{p}{)}
    \PYG{n}{p0} \PYG{o}{=} \PYG{n}{fit}\PYG{o}{.}\PYG{n}{pmean}
\end{Verbatim}

does fits using fit functions with \code{N=1...8} terms. Parameter mean-values
\code{fit.pmean} from the fit with \code{N} exponentials are used as starting values
\code{p0} for the fit with \code{N+1} exponentials, hopefully reducing the time
required to find the best fit for \code{N+1}.


\section{Faster Fits --- Postive Parameters}
\label{corrfitter:faster-fits-postive-parameters}\label{corrfitter:positive-parameters}
Priors used in {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} assign an \emph{a priori} Gaussian/normal distribution
to each parameter. It is possible instead to assign a log-normal distribution,
which forces the corresponding parameter to be positive.  Consider, for
example, energy parameters labeled by \code{'dE'} in the definition of a model
(\emph{e.g.}, \code{Corr2(dE='dE',...)}). To assign log-normal distributions to these
parameters, include their logarithms in the prior and label the logarithms
with \code{'logdE'} or \code{'log(dE)'}: for
example, in \code{make\_prior(N)} use

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{logdE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{l+m+mf}{0.25}\PYG{p}{,} \PYG{l+m+mf}{0.25}\PYG{p}{)}\PYG{p}{)} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}\PYG{p}{]}
\end{Verbatim}

instead of \code{prior{[}'dE'{]} = {[}gv.gvar(0.25, 0.25) for i in range(N){]}}. The
fitter then uses the logarithms as the fit parameters. The original  \code{'dE'}
parameters are recovered (automatically) inside the fit function from
exponentials of the \code{'logdE'} fit parameters.

Using log-normal distributions where possible can significantly improve the
stability of a fit. This is because otherwise the fit function typically has
many symmetries that lead to large numbers of equivalent but different best
fits. For example, the fit functions \code{Gaa(t,N)} and \code{Gab(t,N)} above are
unchanged by exchanging \code{a{[}i{]}}, \code{b{[}i{]}} and \code{E{[}i{]}} with \code{a{[}j{]}},
\code{b{[}j{]}} and \code{E{[}j{]}} for any \code{i} and \code{j}. We can remove this degeneracy
by using a log-normal distribution for the \code{dE{[}i{]}}s since this guarantees
that all \code{dE{[}i{]}}s are positive, and therefore that \code{E{[}0{]},E{[}1{]},E{[}2{]}...}
are ordered (in decreasing order of importance to the fit at large \code{t}).

Another symmetry of \code{Gaa} and \code{Gab}, which leaves both fit functions
unchanged, is replacing \code{a{[}i{]},b{[}i{]}} by \code{-a{[}i{]},-b{[}i{]}}. Yet another is to
add a new term to the fit functions with \code{a{[}k{]},b{[}k{]},dE{[}k{]}} where \code{a{[}k{]}=0}
and the other two have arbitrary values. Both of these symmetries can be
removed by using a log-normal distribution for the \code{a{[}i{]}} priors, thereby
forcing all \code{a{[}i{]}\textgreater{}0}.

The log-normal distributions for the \code{a{[}i{]}} and \code{dE{[}i{]}} are introduced
into the code example above by changing the corresponding labels in
\code{make\_prior(N)},  and taking logarithms of the corresponding prior values:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{gvar} \PYG{k+kn}{as} \PYG{n+nn}{gv}

\PYG{k}{def} \PYG{n+nf}{make\PYGZus{}models}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}                          \PYG{c}{\PYGZsh{} same as before}
    \PYG{n}{models} \PYG{o}{=} \PYG{p}{[} \PYG{n}{Corr2}\PYG{p}{(}\PYG{n}{datatag}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Gaa}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{tdata}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tfit}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{,}
                     \PYG{n}{a}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{b}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dE}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}

               \PYG{n}{Corr2}\PYG{p}{(}\PYG{n}{datatag}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Gab}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{tdata}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tfit}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{,}
                     \PYG{n}{a}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{b}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{b}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dE}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
             \PYG{p}{]}
    \PYG{k}{return} \PYG{n}{models}

\PYG{k}{def} \PYG{n+nf}{make\PYGZus{}prior}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{prior} \PYG{o}{=} \PYG{n}{gvar}\PYG{o}{.}\PYG{n}{BufferDict}\PYG{p}{(}\PYG{p}{)}               \PYG{c}{\PYGZsh{} prior = \PYGZob{}\PYGZcb{}  works too}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{loga}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mf}{0.5}\PYG{p}{)}\PYG{p}{)} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}\PYG{p}{]}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{b}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{l+m+mf}{5.}\PYG{p}{)} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}\PYG{p}{]}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{logdE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{l+m+mf}{0.25}\PYG{p}{,} \PYG{l+m+mf}{0.25}\PYG{p}{)}\PYG{p}{)} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}\PYG{p}{]}
    \PYG{k}{return} \PYG{n}{prior}
\end{Verbatim}

This replaces the original fit parameters, \code{a{[}i{]}} and \code{dE{[}i{]}}, by new fit
parameters, \code{log(a{[}i{]})} and \code{log(dE{[}i{]})}. The \emph{a priori} distributions for
the logarithms are Gaussian/normal, with priors of \code{log(0.1\(\pm\)0.5)} and
\code{log(0.25\(\pm\)0.25)} for the \code{log(a)}s and \code{log(dE)}s respectively.

Note that the labels are unchanged here in \code{make\_models()}. It is
unnecessary to change labels in the models; {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} will automatically
connect the  modified terms in the prior with the appropriate terms in the
models. This allows one to switch back and forth between log-normal and normal
distributions without changing the models --- only the names in the prior
need be changed. {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} also supports ``sqrt-normal'' distributions,
which are indicated by \code{'sqrt'} at the start of a parameter-name in the
prior; the actual parameter in the fit function is the square of this fit-
parameter, and so is again positive.

Note also that only a few lines in \code{print\_results(fit,prior,data)}, above,
would change had we used log-normal priors for \code{a} and \code{dE}:

\begin{Verbatim}[commandchars=\\\{\}]
...
a = fit.transformed\PYGZus{}p[\PYGZsq{}a\PYGZsq{}])                 \PYGZsh{} array of a[i]s
...
dE = fit.transformed\PYGZus{}p[\PYGZsq{}dE\PYGZsq{}]                \PYGZsh{} array of dE[i]s
...
inputs = \PYGZob{}\PYGZsq{}loga\PYGZsq{}:prior[\PYGZsq{}loga\PYGZsq{}], \PYGZsq{}b\PYGZsq{}:prior[\PYGZsq{}b\PYGZsq{}], \PYGZsq{}logdE\PYGZsq{}:fit.prior[\PYGZsq{}logdE\PYGZsq{}],
          \PYGZsq{}data\PYGZsq{}:[data[k] for k in data]\PYGZcb{}
...
\end{Verbatim}

Here \code{fit.transformed\_p} contains the best-fit parameter values from the
fitter, in addition to the exponentials of the \code{'loga'} and \code{'logdE'}
parameters.


\section{Faster Fits --- Marginalization}
\label{corrfitter:marginalized-fits}\label{corrfitter:faster-fits-marginalization}
Often we care only about parameters in the leading term of the fit function,
or just a few of the leading terms. The non-leading terms are needed for a
good fit, but we are uninterested in the values of their parameters. In such
cases the non-leading terms can be absorbed into the fit data, leaving behind
only the leading terms to be fit (to the modified fit data) --- non-leading
parameters are, in effect, integrated out of the analysis, or \emph{marginalized}.
The errors in the modified data are adjusted to account for uncertainties in
the marginalized terms, as specified by their priors. The resulting fit
function has many fewer parameters, and so the fit can be much faster.

Continuing with the example in {\hyperref[corrfitter:faster-fits]{\emph{Faster Fits}}}, imagine that \code{Nmax=8}
terms are needed to get a good fit, but we only care about parameter values
for the first couple of terms. The code from that section can be modified to
fit only the leading \code{N} terms where \code{N\textless{}Nmax}, while incorporating
(marginalizing) the remaining, non-leading terms as corrections to the data:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{Nmax} \PYG{o}{=} \PYG{l+m+mi}{8}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{make\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{mcfile}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{models} \PYG{o}{=} \PYG{n}{make\PYGZus{}models}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{fitter} \PYG{o}{=} \PYG{n}{CorrFitter}\PYG{p}{(}\PYG{n}{models}\PYG{o}{=}\PYG{n}{make\PYGZus{}models}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{prior} \PYG{o}{=} \PYG{n}{make\PYGZus{}prior}\PYG{p}{(}\PYG{n}{Nmax}\PYG{p}{)}        \PYG{c}{\PYGZsh{} build priors for Nmax terms}
\PYG{n}{p0} \PYG{o}{=} \PYG{n+nb+bp}{None}
\PYG{k}{for} \PYG{n}{N} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{]}\PYG{p}{:}
    \PYG{n}{fit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{,} \PYG{n}{p0}\PYG{o}{=}\PYG{n}{p0}\PYG{p}{,} \PYG{n}{nterm}\PYG{o}{=}\PYG{n}{N}\PYG{p}{)} \PYG{c}{\PYGZsh{} fit N terms}
    \PYG{n}{print\PYGZus{}results}\PYG{p}{(}\PYG{n}{fit}\PYG{p}{,} \PYG{n}{prior}\PYG{p}{,} \PYG{n}{data}\PYG{p}{)}
    \PYG{n}{p0} \PYG{o}{=} \PYG{n}{fit}\PYG{o}{.}\PYG{n}{pmean}
\end{Verbatim}

Here the \code{nterm} parameter in \code{fitter.lsqfit} specifies how many terms are
used in the fit functions. The prior specifies \code{Nmax} terms in all, but only
parameters in \code{nterm=N} terms are varied in the fit. The remaining terms
specified by the prior are automatically incorporated into the fit data by
{\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}}.

Remarkably this method is usually as accurate with \code{N=1} or \code{2} as a full
\code{Nmax}-term fit with the original fit data; but it is much faster. If this
is not the case, check for singular priors, where the mean is much smaller
than the standard deviation. These can lead to singularities in the covariance
matrix for the corrected fit data. Such priors are easily fixed: for example,
use \code{gvar.gvar(0.1,1.)} rather than \code{gvar.gvar(0.0,1.)}.
In some situations an \emph{svd} cut (see below) can also
help.


\section{Faster Fits --- Chained Fits}
\label{corrfitter:chained-fits}\label{corrfitter:faster-fits-chained-fits}
Large complicated fits, where lots of models and data are fit simultaneously,
can  take a very long time. This is especially true if there are strong
correlations in the data. Such correlations can also cause  problems from
numerical roundoff errors when the inverse of the data's covariance matrix is
computed for the \code{chi**2} function, requiring large \emph{svd} cuts which can
degrade precision (see below). An alternative approach is to use \emph{chained}
fits.  In a chained fit, each model is fit by itself in sequence, but with the
best-fit parameters from each fit serving as priors for fit parameters in  the
next fit. All parameters from one fit become fit parameters in the next,
including those parameters that are  not explicitly needed by the next fit
(since they may be correlated with the input data for the next fit or with its
priors). Statistical  correlations between data/priors from different models
are preserved  throughout (approximately).

The results from a chained fit are identical to a standard simultaneous fit in
the limit of large statistics (that is, in the Gaussian limit), but a  chained
fit never involves fitting more than a single correlator at a time.
Single-correlator fits are usually much faster than simultaneous multi-correlator
fits, and roundoff errors (and therefore \emph{svd} cuts) are much less of a
problem. Consequently chained fits can be more accurate in practice than
conventional simultaneous fits, especially for high-statistics data.

Converting to chained fits is trivial: simply replace \code{fitter.lsqfit(...)}
by \code{fitter.chained\_lsqfit(...)}. The output from this function represents
the results for the entire chain of fits, and so can be used in exactly the
same way as the  output from \code{fitter.lsqfit()} (and is usually quite
similar, to within statistical errors). Results from the different links in
the chain --- that is, from the fits for individual models --- can be accessed
after the fit using \code{fitter.fit.fits{[}datatag{]}} where \code{datatag} is the
data tag for the model of interest.

Setting parameter \code{parallel=True} in \code{fitter.chained\_lsqfit(...)} makes the
fits for each model independent of each other. Each correlator is
fit separately, but nothing is passed from one fit to the next. In particular,
each fit uses the input prior. Parallel fits can be better than chained
fits in situations where different models share few or no parameters.

It is sometimes useful to combine chained and parallel fits. This is done
by using a nested list of models. For example, setting

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{models} \PYG{o}{=} \PYG{p}{[}\PYG{n}{m1}\PYG{p}{,} \PYG{n}{m2}\PYG{p}{,} \PYG{p}{[}\PYG{n}{m3a}\PYG{p}{,}\PYG{n}{m3b}\PYG{p}{]}\PYG{p}{,} \PYG{n}{m4}\PYG{p}{]}
\end{Verbatim}

with \code{parallel=False} (the default) in \code{fitter.chained\_lsqfit} causes
the following chain of fits:

\begin{Verbatim}[commandchars=\\\{\}]
m1 \PYGZhy{}\PYGZgt{} m2 \PYGZhy{}\PYGZgt{} (parallel fit of [m3a,m3b]) \PYGZhy{}\PYGZgt{} m4
\end{Verbatim}

Here the output from \code{m1} is used in the prior for fit \code{m2}, and the
output from \code{m2} is used as the prior for a parallel fit of \code{m3a}
and \code{m3b} together --- that is, \code{m3a} and \code{m3b} are not chained,
but rather are fit in parallel with each using a prior from fit \code{m2}. The
result of the parallel fit of \code{{[}m3a,m3b{]}} is used as the prior for \code{m4}.
Different levels of nesting in the list of
models alternate between chained and parallel fits.

It is sometimes useful to follow a chained fit with an ordinary fit,
but using the best-fit parameters from the chained fit as the prior for
the ordinary fit: for example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{fit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{chained\PYGZus{}lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{)}
\PYG{n}{fit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{fit}\PYG{o}{.}\PYG{n}{p}\PYG{p}{)}
\end{Verbatim}

The second fit should,
in principle, have no effect on the results since it adds no new
information. In some cases, however, it polishes the results by making small
(compared to the errors) corrections that tighten up the overall fit. It is
generally fairly fast since the prior (\code{fit.p}) is relatively narrow.
It is also possible to polish fits using \code{fitter.chained\_lsqfit}, with
parameters \code{parallel=True} and \code{flat=True}, rather than using
\code{fitter.lsqfit}. This can be faster for very large fits.


\section{Variations}
\label{corrfitter:variations}
Any 2-point correlator can be turned into a periodic function of \code{t} by
specifying the period through parameter \code{tp}. Doing so causes the
replacement (for \code{tp\textgreater{}0})

\begin{Verbatim}[commandchars=\\\{\}]
exp(\PYGZhy{}E[i]*t)   \PYGZhy{}\PYGZgt{}   exp(\PYGZhy{}E[i]*t) + exp(\PYGZhy{}E[i]*(tp\PYGZhy{}t))
\end{Verbatim}

in the fit function. If \code{tp} is negative, the function is replaced by
an anti-periodic function with period \code{abs(tp)} and (for \code{tp\textless{}0}):

\begin{Verbatim}[commandchars=\\\{\}]
exp(\PYGZhy{}E[i]*t)   \PYGZhy{}\PYGZgt{}   exp(\PYGZhy{}E[i]*t) \PYGZhy{} exp(\PYGZhy{}E[i]*(abs(tp)\PYGZhy{}t))
\end{Verbatim}

Also (or alternatively) oscillating terms can be added to the fit by
modifying parameter \code{s} and by specifying sources, sinks and energies for
the oscillating pieces. For example, one might want to replace the sum of
exponentials with two sums

\begin{Verbatim}[commandchars=\\\{\}]
sum\PYGZus{}i a[i]**2 * exp(\PYGZhy{}E[i]*t) \PYGZhy{} sum\PYGZus{}i ao[i]**2 (\PYGZhy{}1)**t * exp(\PYGZhy{}Eo[i]*t)
\end{Verbatim}

in a (nonperiodic) fit function. Then an appropriate model
would be, for example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{Corr2}\PYG{p}{(}\PYG{n}{datatag}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Gaa}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{tdata}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tfit}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{,}
      \PYG{n}{a}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{ao}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{b}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{ao}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dE}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{logdE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{logdEo}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{s}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

where \code{ao} and \code{dEo} refer to additional fit parameters describing
the oscillating component. In general parameters for amplitudes and
energies can be tuples with two components: the first describing normal
states, and the second describing oscillating states. To omit one or the
other, put \code{None} in place of a label. Parameter \code{s{[}0{]}} is an overall
factor multiplying the non-oscillating terms, and \code{s{[}1{]}} is the
corresponding factor for the oscillating terms.

Highly correlated data can lead to problems from numerical roundoff errors,
particularly where the fit code inverts the covariance matrix when
constructing the \code{chi**2} function. Such problems show up as unexpectedly
large \code{chi**2} or fits that stall and appear never to converge. Such
situations are usually improved by introducing an \emph{svd} cut: for example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{fit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{,} \PYG{n}{p0}\PYG{o}{=}\PYG{n}{p0}\PYG{p}{,} \PYG{n}{svdcut}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}4}\PYG{p}{)}
\end{Verbatim}

Introducing an \emph{svd} cut increases the effective errors and so is a
conservative move. For more information about \emph{svd} cuts see the \code{lsqfit}
tutorial and documentation. Parameter \code{svdcut} is used to
specify an \emph{svd} cut.


\section{Very Fast (But Limited) Fits}
\label{corrfitter:very-fast-but-limited-fits}
At large \code{t}, correlators are dominated by the term with the smallest
\code{E}, and often it is only the parameters in that leading term that are
needed. In such cases there is a very fast analysis that is often almost
as accurate as a full fit. An example is:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{corrfitter} \PYG{k+kn}{import} \PYG{n}{fastfit}

\PYG{n}{data} \PYG{o}{=} \PYG{n}{make\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{mcfile}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}    \PYG{c}{\PYGZsh{} user\PYGZhy{}supplied routine \PYGZhy{} fit data}
\PYG{n}{N} \PYG{o}{=} \PYG{l+m+mi}{10}                        \PYG{c}{\PYGZsh{} number of terms in fit functions}
\PYG{n}{prior} \PYG{o}{=} \PYG{n}{make\PYGZus{}prior}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}         \PYG{c}{\PYGZsh{} user\PYGZhy{}supplied routine \PYGZhy{} fit prior}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{Corr2}\PYG{p}{(}\PYG{n}{a}\PYG{o}{=}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,} \PYG{n}{b}\PYG{o}{=}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{)} \PYG{c}{\PYGZsh{} create model describing correlator}
\PYG{n}{fit} \PYG{o}{=} \PYG{n}{fastfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{n}{model}\PYG{p}{)}
\PYG{k}{print}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{E[0] =}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{fit}\PYG{o}{.}\PYG{n}{E}\PYG{p}{)}                  \PYG{c}{\PYGZsh{} E[0]}
\PYG{k}{print}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a[0]*b[0] =}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{fit}\PYG{o}{.}\PYG{n}{ampl}\PYG{p}{)}          \PYG{c}{\PYGZsh{} a[0]*b[0]}
\PYG{k}{print}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{chi2/dof =}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{fit}\PYG{o}{.}\PYG{n}{chi2}\PYG{o}{/}\PYG{n}{fit}\PYG{o}{.}\PYG{n}{dof}\PYG{p}{)}   \PYG{c}{\PYGZsh{} good fit if of order 1 or less}
\PYG{k}{print}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Q =}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{fit}\PYG{o}{.}\PYG{n}{Q}\PYG{p}{)}             \PYG{c}{\PYGZsh{} good fit if Q bigger than about 0.1}
\end{Verbatim}

\code{fastfit} estimates \code{E{[}0{]}} by using the prior, in effect, to
remove (\emph{marginalize}) all terms from the correlator other than the
\code{E{[}0{]}} term: so the data \code{Gdata(t)} for the correlator is replaced by,
for example,

\begin{Verbatim}[commandchars=\\\{\}]
Gdata(t) \PYGZhy{} sum\PYGZus{}i=1..N\PYGZhy{}1  a[i]*b[i] * exp(\PYGZhy{}E[i]*t)
\end{Verbatim}

where \code{a{[}i{]}}, \code{b{[}i{]}}, and \code{E{[}i{]}} for \code{i\textgreater{}0} are replaced by their
values in the prior. The modified prior is then fit by a single term,
\code{a{[}0{]} * b{[}0{]} * exp(-E{[}0{]}*t)}, which means that a fit is not necessary
(since the functional form is so simple). It is important to check the
\code{chi**2} of the fit, to make sure the fit is good. If it is not, try
restricting \code{model.tfit} to larger \code{t}s (\code{fastfit} averages
estimates from all \code{t}s in \code{model.tfit}).

The marginalization of terms with larger \code{E}s allows the code to use
information from much smaller \code{t}s than otherwise, increasing precision.
It also quantifies the uncertainty caused by the existence of these terms.
This simple analysis is a special case of the more general marginalization
strategy discussed in {\hyperref[corrfitter:faster-fits]{\emph{Faster Fits}}}, above.


\section{3-Point Correlators}
\label{corrfitter:point-correlators}
Correlators \code{Gavb(t,T) = \textless{}b(T) V(t) a(0)\textgreater{}} can also be included in fits
as functions of \code{t}. In the illustration above, for example, we might
consider additional Monte Carlo data describing a form factor with the
same intermediate states before and after \code{V(t)}. Assuming the data is
tagged by \code{aVbT15} and describes \code{T=15}, the corresponding entry in the
collection of models might then be:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{Corr3}\PYG{p}{(}\PYG{n}{datatag}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{aVbT15}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{T}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,} \PYG{n}{tdata}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tfit}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{Vnn}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Vnn}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}                \PYG{c}{\PYGZsh{} parameters for V}
    \PYG{n}{a}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dEa}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}          \PYG{c}{\PYGZsh{} parameters for a\PYGZhy{}\PYGZgt{}V}
    \PYG{n}{b}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{b}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dEb}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}          \PYG{c}{\PYGZsh{} parameters for V\PYGZhy{}\PYGZgt{}b}
    \PYG{p}{)}
\end{Verbatim}

This models the Monte Carlo data for the 3-point function using the
following formula:

\begin{Verbatim}[commandchars=\\\{\}]
sum\PYGZus{}i,j a[i] * exp(\PYGZhy{}Ea[i]*t) * Vnn[i,j] * b[j] * exp(\PYGZhy{}Eb[j]*t)
\end{Verbatim}

where the \code{Vnn{[}i,j{]}}s are new fit parameters related to \code{a-\textgreater{}V-\textgreater{}b} form
factors. Obviously multiple values of \code{T} can be studied by including
multiple {\hyperref[corrfitter:corrfitter.Corr3]{\code{corrfitter.Corr3}}} models, one for each value of \code{T}. Either or both of the
initial and final states can have oscillating components (include \code{sa}
and/or \code{sb}), or can be periodic (include \code{tpa} and/or \code{tpb}). If
there are oscillating states then additional \code{V}s must be specified:
\code{Vno} connecting a normal state to an oscillating state, \code{Von}
connecting oscillating to normal states, and \code{Voo} connecting oscillating
to oscillating states.

There are two cases that require special treatment. One is when
simultaneous fits are made to \code{a-\textgreater{}V-\textgreater{}b} and \code{b-\textgreater{}V-\textgreater{}a}. Then the
\code{Vnn}, \code{Vno}, \emph{etc.} for \code{b-\textgreater{}V-\textgreater{}a} are the (matrix) transposes of
the the same matrices for \code{a-\textgreater{}V-\textgreater{}b}. In this case the models for the two
would look something like:

\begin{Verbatim}[commandchars=\\\{\}]
models = [
    ...
    Corr3(datatag=\PYGZsq{}aVbT15\PYGZsq{}, T=15, tdata=range(16), tfit=range(16),
        Vnn=\PYGZsq{}Vnn\PYGZsq{}, Vno=\PYGZsq{}Vno\PYGZsq{}, Von=\PYGZsq{}Von\PYGZsq{}, Voo=\PYGZsq{}Voo\PYGZsq{},
        a=(\PYGZsq{}a\PYGZsq{},\PYGZsq{}ao\PYGZsq{}), dEa=(\PYGZsq{}dE\PYGZsq{},\PYGZsq{}dEo\PYGZsq{}), sa=(1,\PYGZhy{}1), \PYGZsh{} a\PYGZhy{}\PYGZgt{}V
        b=(\PYGZsq{}b\PYGZsq{},\PYGZsq{}bo\PYGZsq{}), dEb=(\PYGZsq{}dE\PYGZsq{},\PYGZsq{}dEo\PYGZsq{}), sb=(1,\PYGZhy{}1)  \PYGZsh{} V\PYGZhy{}\PYGZgt{}b
        ),
    Corr3(datatag=\PYGZsq{}bVaT15\PYGZsq{}, T=15, tdata=range(16), tfit=range(16),
        Vnn=\PYGZsq{}Vnn\PYGZsq{}, Vno=\PYGZsq{}Vno\PYGZsq{}, Von=\PYGZsq{}Von\PYGZsq{}, Voo=\PYGZsq{}Voo\PYGZsq{}, transpose\PYGZus{}V=True,
        a=(\PYGZsq{}b\PYGZsq{},\PYGZsq{}bo\PYGZsq{}), dEa=(\PYGZsq{}dE\PYGZsq{},\PYGZsq{}dEo\PYGZsq{}), sa=(1,\PYGZhy{}1), \PYGZsh{} b\PYGZhy{}\PYGZgt{}V
        b=(\PYGZsq{}a\PYGZsq{},\PYGZsq{}ao\PYGZsq{}), dEb=(\PYGZsq{}dE\PYGZsq{},\PYGZsq{}dEo\PYGZsq{}), sb=(1,\PYGZhy{}1)  \PYGZsh{} V\PYGZhy{}\PYGZgt{}a
        ),
    ...
]
\end{Verbatim}

The same \code{V}s are specified for the second correlator, but setting
\code{transpose\_V=True} means that the transpose of each matrix is used
in the fit for that correlator.

The second special case is for fits to \code{a-\textgreater{}V-\textgreater{}a} where source and sink
are the same. In that case, \code{Vnn} and \code{Voo} are symmetric matrices, and
\code{Von} is the transpose of \code{Vno}. The model for such a case would look
like:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{Corr3}\PYG{p}{(}\PYG{n}{datatag}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{aVbT15}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{T}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,} \PYG{n}{tdata}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tfit}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{Vnn}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Vnn}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{Vno}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Vno}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{Von}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Vno}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{Voo}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Voo}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{symmetric\PYGZus{}V}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{,}
    \PYG{n}{a}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{ao}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dEa}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dEo}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{sa}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{c}{\PYGZsh{} a\PYGZhy{}\PYGZgt{}V}
    \PYG{n}{b}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{ao}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dEb}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dEo}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{sb}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}  \PYG{c}{\PYGZsh{} V\PYGZhy{}\PYGZgt{}a}
    \PYG{p}{)}
\end{Verbatim}

Here \code{Vno} and \code{Von} are set equal to the same matrix, but specifying
\code{symmetric\_V=True} implies that the transpose will be used for \code{Von}.
Furthermore \code{Vnn} and \code{Voo} are symmetric matrices when
\code{symmetric\_V==True} and so only the upper part of each matrix is needed.
In this case \code{Vnn} and \code{Voo} are treated as one-dimensional arrays with
\code{N(N+1)/2} elements corresponding to the upper parts of each matrix,
where \code{N} is the number of exponentials (that is, the number of
\code{a{[}i{]}}s).


\section{Testing Fits with Simulated Data}
\label{corrfitter:testing-fits-with-simulated-data}
Large fits are complicated and often involve nontrivial choices about
algorithms (\emph{e.g.}, chained fits versus regular fits), priors, and
\emph{svd} cuts --- choices that affect the values and errors for the fit
parameters. In such situations it is often a good idea to test the
fit protocol that has been selected. This can be done by fitting simulated
data. Simulated data looks almost identical to the original fit
data but has means that have been adjusted to correspond to fluctuations
around a correlator with known (before the fit) parameter values: \code{p=pexact}.
The {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} iterator \code{simulated\_data\_iter} creates any number of
different simulated data sets of this kind. Fitting any of these with
a particular fit protocol tests the reliability of that protocol since
the fit results should agree with \code{pexact}
to within the (simulated) fit's errors. One or two fit simulations of this
sort are usually enough to establish the validity of a protocol. It is also
easy to compare the performance of different fit options by applying these in
fits of simulated data, again because we know the correct answers (\code{pexact})
ahead of time.

Typically one obtains reasonable values for \code{pexact} from a fit to the
real data. Assuming these have been dumped into a file named \code{"pexact\_file"}
(using, for example, \code{fit.dump\_pmean("pexact\_file")}), a testing script
might look something like:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{gvar} \PYG{k+kn}{as} \PYG{n+nn}{gv}
\PYG{k+kn}{import} \PYG{n+nn}{lsqfit}
\PYG{k+kn}{import} \PYG{n+nn}{corrfitter}

\PYG{k}{def} \PYG{n+nf}{main}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{dataset} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{Dataset}\PYG{p}{(}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{)}       \PYG{c}{\PYGZsh{} from original fit code}
    \PYG{n}{fitter} \PYG{o}{=} \PYG{n}{corrfitter}\PYG{o}{.}\PYG{n}{CorrFitter}\PYG{p}{(}         \PYG{c}{\PYGZsh{} from original fit code}
        \PYG{n}{models} \PYG{o}{=} \PYG{n}{make\PYGZus{}models}\PYG{p}{(}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{)}\PYG{p}{,}
        \PYG{n}{prior} \PYG{o}{=} \PYG{n}{make\PYGZus{}prior}\PYG{p}{(}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{)}\PYG{p}{,}
        \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
        \PYG{p}{)}
    \PYG{n}{n} \PYG{o}{=} \PYG{l+m+mi}{2}                                   \PYG{c}{\PYGZsh{} number of simulations}
    \PYG{n}{pexact} \PYG{o}{=} \PYG{n}{lsqfit}\PYG{o}{.}\PYG{n}{nonlinear\PYGZus{}fit}\PYG{o}{.}\PYG{n}{load\PYGZus{}parameters}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{pexact\PYGZus{}file}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
    \PYG{k}{for} \PYG{n}{sdata} \PYG{o+ow}{in} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{simulated\PYGZus{}data\PYGZus{}iter}\PYG{p}{(}\PYG{n}{n}\PYG{p}{,} \PYG{n}{dataset}\PYG{p}{,} \PYG{n}{pexact}\PYG{o}{=}\PYG{n}{pexact}\PYG{p}{)}\PYG{p}{:}
        \PYG{c}{\PYGZsh{} sfit = fit to the simulated data sdata}
        \PYG{n}{sfit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{sdata}\PYG{p}{,} \PYG{n}{p0}\PYG{o}{=}\PYG{n}{pexact}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{,} \PYG{n}{svdcut}\PYG{o}{=}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{)}
        \PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{n}{check} \PYG{n}{that} \PYG{n}{sfit}\PYG{o}{.}\PYG{n}{p} \PYG{n}{values} \PYG{n}{agree} \PYG{k}{with} \PYG{n}{pexact} \PYG{n}{to} \PYG{n}{within} \PYG{n}{sfit}\PYG{o}{.}\PYG{n}{psdev} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{Verbatim}

Simulated fits provide an alternative to a \emph{bootstrap analysis} (see next
section). By collecting results from many simulated fits, one can test whether
or not fit results are distributed in Gaussian distributions around \code{pexact},
with widths that equal the standard deviations from the fit (\code{fit.psdev}
or \code{sfit.psdev}).

Fit simulations are particularly useful for setting \emph{svd} cuts. Given
a set of approximate parameter values to use for \code{pexact}, it is easy
to run fits with a range of \emph{svd} cuts to see how small \code{svdcut}
can be made before the parameters of interest deviate too far from \code{pexact}.


\section{Bootstrap Analyses}
\label{corrfitter:bootstrap-analyses}
A \emph{bootstrap analysis} gives more robust error estimates for fit parameters
and functions of fit parameters than the conventional fit when errors are
large, or fluctuations are non-Gaussian. A typical code looks something like:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{gvar} \PYG{k+kn}{as} \PYG{n+nn}{gv}
\PYG{k+kn}{import} \PYG{n+nn}{gvar.dataset} \PYG{k+kn}{as} \PYG{n+nn}{ds}
\PYG{k+kn}{from} \PYG{n+nn}{corrfitter} \PYG{k+kn}{import} \PYG{n}{CorrFitter}
\PYG{c}{\PYGZsh{} fit}
\PYG{n}{dset} \PYG{o}{=} \PYG{n}{ds}\PYG{o}{.}\PYG{n}{Dataset}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{mcfile}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{ds}\PYG{o}{.}\PYG{n}{avg\PYGZus{}data}\PYG{p}{(}\PYG{n}{dset}\PYG{p}{)}            \PYG{c}{\PYGZsh{} create fit data}
\PYG{n}{fitter} \PYG{o}{=} \PYG{n}{Corrfitter}\PYG{p}{(}\PYG{n}{models}\PYG{o}{=}\PYG{n}{make\PYGZus{}models}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{N} \PYG{o}{=} \PYG{l+m+mi}{4}                               \PYG{c}{\PYGZsh{} number of terms in fit function}
\PYG{n}{prior} \PYG{o}{=} \PYG{n}{make\PYGZus{}prior}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}
\PYG{n}{fit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{,} \PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{)}  \PYG{c}{\PYGZsh{} do standard fit}
\PYG{k}{print} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Fit results:}\PYG{l+s}{\PYGZsq{}}
\PYG{k}{print} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{exp}\PYG{p}{(}\PYG{n}{fit}\PYG{o}{.}\PYG{n}{p}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{loga}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}        \PYG{c}{\PYGZsh{} fit results for \PYGZsq{}a\PYGZsq{} amplitudes}
\PYG{k}{print} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{exp}\PYG{p}{(}\PYG{n}{fit}\PYG{o}{.}\PYG{n}{p}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{logdE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}      \PYG{c}{\PYGZsh{} fit results for \PYGZsq{}dE\PYGZsq{} energies}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{c}{\PYGZsh{} bootstrap analysis}
\PYG{k}{print} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Bootstrap fit results:}\PYG{l+s}{\PYGZsq{}}
\PYG{n}{nbootstrap} \PYG{o}{=} \PYG{l+m+mi}{10}                     \PYG{c}{\PYGZsh{} number of bootstrap iterations}
\PYG{n}{bs\PYGZus{}datalist} \PYG{o}{=} \PYG{p}{(}\PYG{n}{ds}\PYG{o}{.}\PYG{n}{avg\PYGZus{}data}\PYG{p}{(}\PYG{n}{d}\PYG{p}{)} \PYG{k}{for} \PYG{n}{d} \PYG{o+ow}{in} \PYG{n}{dset}\PYG{o}{.}\PYG{n}{bootstrap\PYGZus{}iter}\PYG{p}{(}\PYG{n}{nbootstrap}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{bs} \PYG{o}{=} \PYG{n}{ds}\PYG{o}{.}\PYG{n}{Dataset}\PYG{p}{(}\PYG{p}{)}                   \PYG{c}{\PYGZsh{} bootstrap output stored in bs}
\PYG{k}{for} \PYG{n}{bs\PYGZus{}fit} \PYG{o+ow}{in} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{bootstrap\PYGZus{}iter}\PYG{p}{(}\PYG{n}{bs\PYGZus{}datalist}\PYG{p}{)}\PYG{p}{:} \PYG{c}{\PYGZsh{} bs\PYGZus{}fit = lsqfit output}
    \PYG{n}{p} \PYG{o}{=} \PYG{n}{bs\PYGZus{}fit}\PYG{o}{.}\PYG{n}{pmean}    \PYG{c}{\PYGZsh{} best fit values for current bootstrap iteration}
    \PYG{n}{bs}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{exp}\PYG{p}{(}\PYG{n}{p}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{loga}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}  \PYG{c}{\PYGZsh{} collect bootstrap results for a[i]}
    \PYG{n}{bs}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{exp}\PYG{p}{(}\PYG{n}{p}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{logdE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}\PYG{c}{\PYGZsh{} collect results for dE[i]}
    \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}                             \PYG{c}{\PYGZsh{} include other functions of p}
    \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{n}{bs} \PYG{o}{=} \PYG{n}{ds}\PYG{o}{.}\PYG{n}{avg\PYGZus{}data}\PYG{p}{(}\PYG{n}{bs}\PYG{p}{,} \PYG{n}{bstrap}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}   \PYG{c}{\PYGZsh{} medians + error estimate}
\PYG{k}{print} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{bs}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}                  \PYG{c}{\PYGZsh{} bootstrap result for \PYGZsq{}a\PYGZsq{} amplitudes}
\PYG{k}{print} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{bs}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}                \PYG{c}{\PYGZsh{} bootstrap result for \PYGZsq{}dE\PYGZsq{} energies}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{Verbatim}

This code first prints out the standard fit results for the \code{'a'} amplitudes
and \code{'dE'} energies. It then makes \code{10} bootstrap copies of the original
input data, and fits each using the best-fit parameters from the original fit
as the starting point for the bootstrap fit. The variation in the best-fit
parameters from fit to fit is an indication of the uncertainty in those
parameters. This example uses a \code{gvar.dataset.Dataset} object \code{bs} to
accumulate the results from each bootstrap fit, which are computed using the
best-fit values of the parameters (ignoring their standard deviations). Other
functions of the fit parameters could be included as well. At the end
\code{avg\_data(bs, bstrap=True)} finds median values for each quantity in
\code{bs}, as well as a robust estimate of the uncertainty (to within 30\% since
\code{nbootstrap} is only \code{10}).

The list of bootstrap data sets \code{bs\_datalist} can be omitted in this example
in situations where the input data has high statistics. Then the bootstrap
copies are generated internally by \code{fitter.bootstrap\_iter()} from the
means and covariance matrix of the input data (assuming Gaussian statistics).


\section{Implementation}
\label{corrfitter:implementation}
{\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} allows models to specify how many exponentials to include in the
fit function (using parameters \code{nterm}, \code{nterma} and \code{ntermb}). If that
number is less than the number of exponentials specified by the prior, the
extra terms are incorporated into the fit data before fitting. The default
procedure is to multiply the data by \code{G(t,p,N)/G(t,p,max(N,Nmax))} where:
\code{G(p,t,N)} is the fit function with \code{N} terms for parameters \code{p} and
time \code{t}; \code{N} is the number of exponentials specified in the models;
\code{Nmax} is the number of exponentials specified in the prior; and here
parameters \code{p} are set equal to their values in the prior (correlated
\code{gvar.GVar}s).

An alternative implementation for the data correction is to add
\code{G(t,p,N)-G(t,p,max(N,Nmax))} to the data. This implementation is selected
when parameter \code{ratio} in {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} is set to \code{False}. Results are
similar to the other implementation.

Background information on the some of the fitting strategies used by
{\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} can be found by doing web searches for ``hep-lat/0110175'' and
``arXiv:1111.1363''. These are two papers by G.P. Lepage and collaborators
whose published versions are: G.P. Lepage et al, Nucl.Phys.Proc.Suppl.
106 (2002) 12-20; and K. Hornbostel et al, Phys.Rev. D85 (2012) 031504.


\section{Correlator Model Objects}
\label{corrfitter:correlator-model-objects}
Correlator objects describe theoretical models that are fit to
correlator data by varying the models' parameters.

A model object's parameters are specified through priors for the fit. A
model assigns labels to each of its parameters (or arrays of related
parameters), and these labels are used to identify the corresponding
parameters in the prior. Parameters can be shared by more than one model
object.

A model object also specifies the data that it is to model. The data is
identified by the data tag that labels it in the input file or \code{gvar.dataset.Dataset}.
\index{Corr2 (class in corrfitter)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.Corr2}\pysiglinewithargsret{\strong{class }\code{corrfitter.}\bfcode{Corr2}}{\emph{datatag}, \emph{tdata}, \emph{tfit}, \emph{a}, \emph{b}, \emph{dE}, \emph{s=1.0}, \emph{tp=None}, \emph{othertags=None}}{}
Two-point correlators \code{Gab(t) = \textless{}b(t) a(0)\textgreater{}}.

{\hyperref[corrfitter:corrfitter.Corr2]{\code{corrfitter.Corr2}}} models the \code{t} dependence of a 2-point correlator \code{Gab(t)}
using

\begin{Verbatim}[commandchars=\\\{\}]
Gab(t) = sn * sum\PYGZus{}i an[i]*bn[i] * fn(En[i], t)
       + so * sum\PYGZus{}i ao[i]*bo[i] * fo(Eo[i], t)
\end{Verbatim}

where \code{sn} and \code{so} are typically \code{-1}, \code{0}, or \code{1} and

\begin{Verbatim}[commandchars=\\\{\}]
fn(E, t) =  exp(\PYGZhy{}E*t) + exp(\PYGZhy{}E*(tp\PYGZhy{}t)) \PYGZsh{} tp\PYGZgt{}0 \PYGZhy{}\PYGZhy{} periodic
       or   exp(\PYGZhy{}E*t) \PYGZhy{} exp(\PYGZhy{}E*(\PYGZhy{}tp\PYGZhy{}t))\PYGZsh{} tp\PYGZlt{}0 \PYGZhy{}\PYGZhy{} anti\PYGZhy{}periodic
       or   exp(\PYGZhy{}E*t)                  \PYGZsh{} if tp is None (nonperiodic)

fo(E, t) = (\PYGZhy{}1)**t * fn(E, t)
\end{Verbatim}

The fit parameters for the non-oscillating piece of \code{Gab} (first term)
are \code{an{[}i{]}}, \code{bn{[}i{]}}, and \code{dEn{[}i{]}} where:

\begin{Verbatim}[commandchars=\\\{\}]
dEn[0] = En[0] \PYGZgt{} 0
dEn[i] = En[i]\PYGZhy{}En[i\PYGZhy{}1] \PYGZgt{} 0     (for i\PYGZgt{}0)
\end{Verbatim}

and therefore \code{En{[}i{]} = sum\_j=0..i dEn{[}j{]}}. The fit parameters for
the oscillating pied are defined analogously: \code{ao{[}i{]}}, \code{bo{[}i{]}},
and \code{dEo{[}i{]}}.

The fit parameters are specified by the keys corresponding to these
parameters in a dictionary of priors supplied by {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}}. The keys
are strings and are also used to access fit results. Any key that
begins with ``log'' is assumed to refer to the logarithm of the parameter
in question (that is, the exponential of the fit-parameter is used in
the formula for \code{Gab(t)}.) This is useful for forcing \code{an}, \code{bn}
and/or \code{dE} to be positive.

When \code{tp is not None} and positive, the correlator is assumed to be
symmetrical about \code{tp/2}, with \code{Gab(t)=Gab(tp-t)}. Data from
\code{t\textgreater{}tp/2} is averaged with the corresponding data from \code{t\textless{}tp/2}
before fitting. When \code{tp} is negative, the correlator is assumed to
be anti-symetrical about \code{-tp/2}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{datatag} (\emph{string}) -- Key used to access correlator data in the input data 
dictionary (see {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}}). \code{data{[}self.datatag{]}} is (1-d) 
array containing the correlator values (\code{gvar.GVar}s) if \code{data} is the 
input data.

\item {} 
\textbf{a} (string, or two-tuple of strings and/or \code{None}) -- Key identifying the fit parameters for the source amplitudes
\code{an} in the dictionary of priors provided by {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}}; or a
two-tuple of keys for the source amplitudes \code{(an, ao)}. The
corresponding values in the dictionary of priors are (1-d) arrays
of prior values with one term for each \code{an{[}i{]}} or \code{ao{[}i{]}}.
Replacing either key by \code{None} causes the corresponding term to
be dropped from the fit function. These keys are used to label the
corresponding parameter arrays in the fit results as well as in the
prior.

\item {} 
\textbf{b} (string, or two-tuple of strings and/or \code{None}) -- Same as \code{self.a} but for the sinks \code{(bn, bo)} instead of
the sources \code{(an, ao)}.

\item {} 
\textbf{dE} (string, or two-tuple of strings and/or \code{None}) -- Key identifying the fit parameters for the energy 
differences \code{dEn} in the dictionary of priors provided by
{\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}}; or a two-tuple of keys for the energy differences
\code{(dEn, dEo)}. The corresponding values in the dictionary of priors
are (1-d) arrays of prior values with one term for each \code{dEn{[}i{]}}
or \code{dEo{[}i{]}}. Replacing either key by \code{None} causes the
corresponding term to be dropped from the fit function. These keys
are used to label the corresponding parameter arrays in the fit
results as well as in the prior.

\item {} 
\textbf{s} (\emph{number or two-tuple of numbers}) -- Overall factor \code{sn}, or two-tuple of overall factors 
\code{(sn, so)}.

\item {} 
\textbf{tdata} (\emph{list of integers}) -- The \code{t}s corresponding to data entries in the input
data. Note that \code{len(self.tdata) == len(data{[}self.datatag{]})} is
required if \code{data} is the input data dictionary.

\item {} 
\textbf{tfit} (\emph{list of integers}) -- List of \code{t}s to use in the fit. Only data with these
\code{t}s (all of which should be in \code{tdata}) is used in the fit.

\item {} 
\textbf{tp} (integer or \code{None}) -- If not \code{None} and positive, the correlator is assumed to 
be periodic with \code{Gab(t)=Gab(tp-t)}. If negative, the correlator
is assumed to be anti-periodic with \code{Gab(t)=-Gab(-tp-t)}. Setting
\code{tp=None} implies that the correlator is not periodic, but rather
continues to fall exponentially as \code{t} is increased indefinitely.

\item {} 
\textbf{othertags} (\emph{sequence of strings}) -- List of additional data tags for data to be
averaged with the \code{self.datatag} data before fitting.

\end{itemize}

\end{description}\end{quote}
\index{builddata() (corrfitter.Corr2 method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.Corr2.builddata}\pysiglinewithargsret{\bfcode{builddata}}{\emph{data}}{}
Assemble fit data from dictionary \code{data}.

Extracts parts of array \code{data{[}self.datatag{]}} that are needed for
the fit, as specified by \code{self.tp} and \code{self.tfit}. The entries
in the (1-D) array \code{data{[}self.datatag{]}} are assumed to be
\code{gvar.GVar}s and correspond to the \code{t{}`{}`s in {}`{}`self.tdata}.

\end{fulllineitems}

\index{buildprior() (corrfitter.Corr2 method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.Corr2.buildprior}\pysiglinewithargsret{\bfcode{buildprior}}{\emph{prior}, \emph{nterm}}{}
Create fit prior by extracting relevant pieces of \code{prior}.

Priors for the fit parameters, as specificied by \code{self.a} etc., 
are copied from \code{prior} into a new dictionary for use by the
fitter. If a key \code{"XX"} cannot be found in \code{prior}, the
\code{buildprior} looks for one of \code{"logXX"}, \code{"log(XX)"}, 
\code{"sqrtXX"}, or \code{"sqrt(XX)"} and includes the corresponding
prior instead.

The number of terms kept in each part of the fit can be 
specified using \code{nterm = (n, no)} where \code{n} is the 
number of non-oscillating terms and \code{no} is the number 
of oscillating terms. Setting \code{nterm = None} keeps 
all terms.

\end{fulllineitems}

\index{fitfcn() (corrfitter.Corr2 method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.Corr2.fitfcn}\pysiglinewithargsret{\bfcode{fitfcn}}{\emph{p}, \emph{nterm=None}, \emph{t=None}}{}
Return fit function for parameters \code{p}.

\end{fulllineitems}


\end{fulllineitems}

\index{Corr3 (class in corrfitter)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.Corr3}\pysiglinewithargsret{\strong{class }\code{corrfitter.}\bfcode{Corr3}}{\emph{datatag}, \emph{T}, \emph{tdata}, \emph{tfit}, \emph{Vnn}, \emph{a}, \emph{b}, \emph{dEa}, \emph{dEb}, \emph{sa=1.0}, \emph{sb=1.0}, \emph{Vno=None}, \emph{Von=None}, \emph{Voo=None}, \emph{transpose\_V=False}, \emph{symmetric\_V=False}, \emph{tpa=None}, \emph{tpb=None}, \emph{othertags=None}}{}
Three-point correlators \code{Gavb(t, T) = \textless{}b(T) V(t) a(0)\textgreater{}}.

{\hyperref[corrfitter:corrfitter.Corr3]{\code{corrfitter.Corr3}}} models the \code{t} dependence of a 3-point correlator
\code{Gavb(t, T)} using

\begin{Verbatim}[commandchars=\\\{\}]
Gavb(t, T) = 
 sum\PYGZus{}i,j san*an[i]*fn(Ean[i],t)*Vnn[i,j]*sbn*bn[j]*fn(Ebn[j],T\PYGZhy{}t)
+sum\PYGZus{}i,j san*an[i]*fn(Ean[i],t)*Vno[i,j]*sbo*bo[j]*fo(Ebo[j],T\PYGZhy{}t)
+sum\PYGZus{}i,j sao*ao[i]*fo(Eao[i],t)*Von[i,j]*sbn*bn[j]*fn(Ebn[j],T\PYGZhy{}t)
+sum\PYGZus{}i,j sao*ao[i]*fo(Eao[i],t)*Voo[i,j]*sbo*bo[j]*fo(Ebo[j],T\PYGZhy{}t)
\end{Verbatim}

where

\begin{Verbatim}[commandchars=\\\{\}]
fn(E, t) =  exp(\PYGZhy{}E*t) + exp(\PYGZhy{}E*(tp\PYGZhy{}t)) \PYGZsh{} tp\PYGZgt{}0 \PYGZhy{}\PYGZhy{} periodic
       or   exp(\PYGZhy{}E*t) \PYGZhy{} exp(\PYGZhy{}E*(\PYGZhy{}tp\PYGZhy{}t))\PYGZsh{} tp\PYGZlt{}0 \PYGZhy{}\PYGZhy{} anti\PYGZhy{}periodic
       or   exp(\PYGZhy{}E*t)                  \PYGZsh{} if tp is None (nonperiodic)

fo(E, t) = (\PYGZhy{}1)**t * fn(E, t)
\end{Verbatim}

The fit parameters for the non-oscillating piece of \code{Gavb} (first term)
are \code{Vnn{[}i,j{]}}, \code{an{[}i{]}}, \code{bn{[}j{]}}, \code{dEan{[}i{]}} and \code{dEbn{[}j{]}} where,
for example:

\begin{Verbatim}[commandchars=\\\{\}]
dEan[0] = Ean[0] \PYGZgt{} 0
dEan[i] = Ean[i]\PYGZhy{}Ean[i\PYGZhy{}1] \PYGZgt{} 0     (for i\PYGZgt{}0)
\end{Verbatim}

and therefore \code{Ean{[}i{]} = sum\_j=0..i dEan{[}j{]}}. The parameters for the
other terms are similarly defined.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{datatag} (\emph{string}) -- Tag used to label correlator in the input \code{gvar.dataset.Dataset}.

\item {} 
\textbf{a} (string, or two-tuple of strings or \code{None}) -- Key identifying the fit parameters for the source amplitudes
\code{an}, for \code{a-\textgreater{}V}, in the dictionary of priors provided by
{\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}}; or a two-tuple of keys for the source amplitudes
\code{(an, ao)}. The corresponding values in the dictionary of priors
are (1-d) arrays of prior values with one term for each \code{an{[}i{]}}
or \code{ao{[}i{]}}. Replacing either key by \code{None} causes the
corresponding term to be dropped from the fit function. These keys
are used to label the corresponding parameter arrays in the fit
results as well as in the prior.

\item {} 
\textbf{b} (string, or two-tuple of strings or \code{None}) -- Same as \code{self.a} except for sink amplitudes \code{(bn, bo)} 
for \code{V-\textgreater{}b} rather than for \code{(an, ao)}.

\item {} 
\textbf{dEa} (string, or two-tuple of strings or \code{None}) -- Fit-parameter label for \code{a-\textgreater{}V} intermediate-state energy 
differences \code{dEan}, or two-tuple of labels for the differences
\code{(dEan,dEao)}. Each label represents an array of energy differences.
Replacing either label by \code{None} causes the corresponding term in
the correlator function to be dropped. These keys
are used to label the corresponding parameter arrays in the fit
results as well as in the prior.

\item {} 
\textbf{dEb} (string, or two-tuple of strings or \code{None}) -- Fit-parameter label for \code{V-\textgreater{}b} intermediate-state energy 
differences \code{dEbn}, or two-tuple of labels for the differences
\code{(dEbn,dEbo)}. Each label represents an array of energy differences.
Replacing either label by \code{None} causes the corresponding term in
the correlator function to be dropped. These keys
are used to label the corresponding parameter arrays in the fit
results as well as in the prior.

\item {} 
\textbf{sa} (\emph{number, or two-tuple of numbers}) -- Overall factor \code{san} for the non-oscillating \code{a-\textgreater{}V} terms 
in the correlator, or two-tuple containing the overall factors
\code{(san,sao)} for the non-oscillating and oscillating terms.

\item {} 
\textbf{sb} (\emph{number, or two-tuple of numbers}) -- Overall factor \code{sbn} for the non-oscillating \code{V-\textgreater{}b} terms 
in the correlator, or two-tuple containing the overall factors
\code{(sbn,sbo)} for the non-oscillating and oscillating terms.

\item {} 
\textbf{Vnn} (string or \code{None}) -- Fit-parameter label for the matrix of current matrix 
elements \code{Vnn{[}i,j{]}} connecting non-oscillating states. Labels that
begin with ``log'' indicate that the corresponding matrix elements are
replaced by their exponentials; these parameters are logarithms of the
corresponding matrix elements, which must then be positive.

\item {} 
\textbf{Vno} (string or \code{None}) -- Fit-parameter label for the matrix of current matrix 
elements \code{Vno{[}i,j{]}} connecting non-oscillating to oscillating
states. Labels that begin with ``log'' indicate that the corresponding
matrix elements are replaced by their exponentials; these parameters
are logarithms of the corresponding matrix elements, which must then
be positive.

\item {} 
\textbf{Von} (string or \code{None}) -- Fit-parameter label for the matrix of current matrix 
elements \code{Von{[}i,j{]}} connecting oscillating to non-oscillating 
states. Labels that begin with ``log'' indicate that the corresponding
matrix elements are replaced by their exponentials; these parameters
are logarithms of the corresponding matrix elements, which must then
be positive.

\item {} 
\textbf{Voo} (string or \code{None}) -- Fit-parameter label for the matrix of current matrix 
elements \code{Voo{[}i,j{]}} connecting oscillating states. Labels that begin
with ``log'' indicate that the corresponding matrix elements are
replaced by their exponentials; these parameters are logarithms of the
corresponding matrix elements, which must then be positive.

\item {} 
\textbf{transpose\_V} (\emph{boolean}) -- If \code{True}, the transpose \code{V{[}j,i{]}} is used in
place of \code{V{[}i,j{]}} for each current matrix element in the fit 
function. This is useful for doing simultaneous fits to 
\code{a-\textgreater{}V-\textgreater{}b} and \code{b-\textgreater{}V-\textgreater{}a}, where the current matrix elements
for one are the transposes of those for the other. Default value 
is \code{False}.

\item {} 
\textbf{symmetric\_V} (\emph{boolean}) -- 
If \code{True}, the fit function for \code{a-\textgreater{}V-\textgreater{}b} is 
unchanged (symmetrical) under the the interchange of \code{a} and
\code{b}. Then \code{Vnn} and \code{Voo} are square, symmetric matrices
with \code{V{[}i,j{]}=V{[}j,i{]}} and their priors are one-dimensional arrays
containing only elements \code{V{[}i,j{]}} with \code{j\textgreater{}=i} in the following
layout:

\begin{Verbatim}[commandchars=\\\{\}]
[V[0,0],V[0,1],V[0,2]...V[0,N],
        V[1,1],V[1,2]...V[1,N],
               V[2,2]...V[2,N],
                     .
                      .
                       .
                        V[N,N]]
\end{Verbatim}

Furthermore the matrix specified for \code{Von} is transposed before
being used by the fitter; normally the matrix specified for \code{Von}
is the same as the matrix specified for \code{Vno} when the amplitude
is symmetrical. Default value is \code{False}.


\item {} 
\textbf{tdata} (\emph{list of integers}) -- The \code{t}s corresponding to data entries in the input
\code{gvar.dataset.Dataset}.

\item {} 
\textbf{tfit} (\emph{list of integers}) -- List of \code{t}s to use in the fit. Only data with these
\code{t}s (all of which should be in \code{tdata}) is used in the fit.

\item {} 
\textbf{tpa} (integer or \code{None}) -- If not \code{None} and positive, the \code{a-\textgreater{}V} correlator is 
assumed to be periodic with period \code{tpa}. If negative, the
correlator is anti-periodic with period \code{-tpa}. Setting
\code{tpa=None} implies that the correlators are not periodic.

\item {} 
\textbf{tpb} (integer or \code{None}) -- If not \code{None} and positive, the \code{V-\textgreater{}b} correlator is 
assumed to be periodic with period \code{tpb}. If negative, the
correlator is periodic with period \code{-tpb}. Setting \code{tpb=None}
implies that the correlators are not periodic.

\end{itemize}

\end{description}\end{quote}
\index{builddata() (corrfitter.Corr3 method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.Corr3.builddata}\pysiglinewithargsret{\bfcode{builddata}}{\emph{data}}{}
Assemble fit data from dictionary \code{data}.

Extracts parts of array \code{data{[}self.datatag{]}} that are needed for
the fit, as specified by \code{self.tfit}. The entries in the (1-D)
array \code{data{[}self.datatag{]}} are assumed to be \code{gvar.GVar}s and
correspond to the \code{t{}`{}`s in {}`{}`self.tdata}.

\end{fulllineitems}

\index{buildprior() (corrfitter.Corr3 method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.Corr3.buildprior}\pysiglinewithargsret{\bfcode{buildprior}}{\emph{prior}, \emph{nterm}}{}
Create fit prior by extracting relevant pieces of \code{prior}.

Priors for the fit parameters, as specificied by \code{self.a} etc., 
are copied from \code{prior} into a new dictionary for use by the
fitter. If a key \code{"XX"} cannot be found in \code{prior}, the
\code{buildprior} looks for one of \code{"logXX"}, \code{"log(XX)"}, 
\code{"sqrtXX"}, or \code{"sqrt(XX)"} and includes the corresponding
prior instead.

The number of terms kept in each part of the fit can be 
specified using \code{nterm = (n, no)} where \code{n} is the 
number of non-oscillating terms and \code{no} is the number 
of oscillating terms. Setting \code{nterm = None} keeps 
all terms.

\end{fulllineitems}

\index{fitfcn() (corrfitter.Corr3 method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.Corr3.fitfcn}\pysiglinewithargsret{\bfcode{fitfcn}}{\emph{p}, \emph{nterm=None}, \emph{t=None}}{}
Return fit function for parameters \code{p}.

\end{fulllineitems}


\end{fulllineitems}

\index{BaseModel (class in corrfitter)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.BaseModel}\pysiglinewithargsret{\strong{class }\code{corrfitter.}\bfcode{BaseModel}}{\emph{datatag}, \emph{othertags=}\optional{}}{}
Base class for correlator models.

Derived classes must define methods \code{fitfcn}, \code{buildprior}, and 
\code{builddata}, all of which are described below. In addition they
can have attributes:
\begin{quote}
\index{datatag (BaseModel attribute)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:BaseModel.datatag}\pysigline{\bfcode{datatag}}
{\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} builds fit data for the correlator by extracting the
data in an input \code{gvar.dataset.Dataset} labelled by string \code{datatag}. This
label is stored in the \code{BaseModel} and must be passed to its
constructor.

\end{fulllineitems}

\index{all\_datatags (BaseModel attribute)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:BaseModel.all_datatags}\pysigline{\bfcode{all\_datatags}}
Models can specify more than one set of fit data to use in fitting.
The list of all the datatags used is \code{self.all\_datatags}. The 
first entry is always \code{self.datatag}; the other entries are
from \code{othertags}.

\end{fulllineitems}

\index{\_abscissa (BaseModel attribute)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:BaseModel._abscissa}\pysigline{\bfcode{\_abscissa}}
(Optional) Array of abscissa values used in plots of the data and
fit corresponding to the model. Plots are not made for a model that
doesn't specify this attribute.

\end{fulllineitems}

\end{quote}
\index{builddata() (corrfitter.BaseModel method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.BaseModel.builddata}\pysiglinewithargsret{\bfcode{builddata}}{\emph{data}}{}
Construct fit data.

Format of output must be same as format for fitfcn output.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{data} (\emph{dictionary}) -- Dataset containing correlator data 
(see \code{gvar.dataset}).

\end{description}\end{quote}

\end{fulllineitems}

\index{buildprior() (corrfitter.BaseModel method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.BaseModel.buildprior}\pysiglinewithargsret{\bfcode{buildprior}}{\emph{prior}, \emph{nterm=None}}{}
Extract fit prior from \code{prior}; resizing as needed.

If \code{nterm} is not \code{None}, the sizes of the priors may need
adjusting so that they correspond to the values specified in 
\code{nterm} (for normal and oscillating pieces).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{prior} (\emph{dictionary}) -- Dictionary containing \emph{a priori} estimates of the 
fit parameters.

\item {} 
\textbf{nterm} (tuple of \code{None} or integers) -- Restricts the number of non-oscillating terms in the
fit function to \code{nterm{[}0{]}} and oscillating terms to
\code{nterm{[}1{]}}. Setting either (or both) to \code{None} implies that
all terms in the prior are used.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{fitfcn() (corrfitter.BaseModel method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.BaseModel.fitfcn}\pysiglinewithargsret{\bfcode{fitfcn}}{\emph{p}, \emph{nterm=None}}{}
Compute fit function fit parameters \code{p} using \code{nterm} terms. ``
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{p} (\emph{dictionary}) -- Dictionary of parameter values.

\item {} 
\textbf{nterm} (tuple of \code{None} or integers) -- Restricts the number of non-oscillating terms in the
fit function to \code{nterm{[}0{]}} and oscillating terms to
\code{nterm{[}1{]}}. Setting either (or both) to \code{None} implies that
all terms in the prior are used.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{\texttt{corrfitter.CorrFitter} Objects}
\label{corrfitter:corrfitter-objects}
{\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} objects are wrappers for \code{lsqfit.nonlinear\_fit()} which
is used to fit a collection of models to a collection of Monte Carlo data.
\index{CorrFitter (class in corrfitter)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.CorrFitter}\pysiglinewithargsret{\strong{class }\code{corrfitter.}\bfcode{CorrFitter}}{\emph{models}, \emph{svdcut=1e-15}, \emph{tol=1e-10}, \emph{maxit=500}, \emph{nterm=None}, \emph{ratio=False}, \emph{fast=False}, \emph{processed\_data=None}}{}
Nonlinear least-squares fitter for a collection of correlators.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{models} (\emph{list or other sequence}) -- Sequence of correlator models, such as 
{\hyperref[corrfitter:corrfitter.Corr2]{\code{corrfitter.Corr2}}} or {\hyperref[corrfitter:corrfitter.Corr3]{\code{corrfitter.Corr3}}}, 
to use in fits of fit data. Individual
models in the sequence can be replaced by sequences of models
(and/or further sequences, recursively) for use by
{\hyperref[corrfitter:corrfitter.CorrFitter.chained_lsqfit]{\code{corrfitter.CorrFitter.chained\_lsqfit()}}}; such nesting
is ignored by the other methods.

\item {} 
\textbf{svdcut} (number or \code{None}) -- If \code{svdcut} is positive, eigenvalues \code{ev{[}i{]}} of the 
correlation matrix that are smaller than
\code{svdcut*max(ev)} are replaced by \code{svdcut*max(ev)}. 
If \code{svdcut} is negative, eigenvalues less than
\code{\textbar{}svdcut\textbar{}*max(ev)} are set to zero in the correlation matrix. The
correlation matrix is left unchanged if \code{svdcut} is set equal to
\code{None} (default).

\item {} 
\textbf{tol} (\emph{number or tuple}) -- Tolerance used in \code{lsqfit.nonlinear\_fit()} for the 
least-squares fits. Use a tuple to specify separate values for
the relative and absolute tolerances: \code{tol=(reltol, abstol)};
otherwise they are both set equal to \code{tol} (default=1e-10).

\item {} 
\textbf{maxit} (\emph{integer}) -- Maximum number of iterations to use in least-squares fit 
(default=500).

\item {} 
\textbf{nterm} (number or \code{None}; or two-tuple of numbers or \code{None}) -- Number of terms fit in the non-oscillating parts of fit 
functions; or two-tuple of numbers indicating how many terms to fit
for each of the non-oscillating and oscillating pieces in fits. If set
to \code{None}, the number is specified by the number of parameters in
the prior.

\item {} 
\textbf{ratio} (\emph{boolean}) -- If \code{True}, use ratio corrections for fit 
data when the prior specifies more terms than are used in the fit. If
\code{False} (the default), use difference corrections 
(see implementation notes, above).

\end{itemize}

\end{description}\end{quote}
\index{bootstrap\_fit\_iter() (corrfitter.CorrFitter method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.CorrFitter.bootstrap_fit_iter}\pysiglinewithargsret{\bfcode{bootstrap\_fit\_iter}}{\emph{datalist=None}, \emph{n=None}}{}
Iterator that creates bootstrap copies of a {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} fit using 
bootstrap data from list \code{data\_list}.

A bootstrap analysis is a robust technique for estimating means and
standard deviations of arbitrary functions of the fit parameters.
This method creates an interator that implements such an analysis
of list (or iterator) \code{datalist}, which contains bootstrap
copies of the original data set. Each \code{data\_list{[}i{]}} is a different
\code{data} input for \code{self.lsqfit()} (that is, a dictionary containing
fit data). The iterator works its way through the data sets in
\code{data\_list}, fitting the next data set on each iteration and
returning the resulting \code{lsqfit.LSQFit} fit object. Typical
usage, for an {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} object named \code{fitter}, would be:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k}{for} \PYG{n}{fit} \PYG{o+ow}{in} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{bootstrap\PYGZus{}iter}\PYG{p}{(}\PYG{n}{datalist}\PYG{p}{)}\PYG{p}{:}
    \PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{n}{analyze} \PYG{n}{fit} \PYG{n}{parameters} \PYG{o+ow}{in} \PYG{n}{fit}\PYG{o}{.}\PYG{n}{p} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{data\_list} (sequence or iterator or \code{None}) -- Collection of bootstrap \code{data} sets for fitter. If
\code{None}, the data\_list is generated internally using the 
means and standard deviations of the fit data (assuming
gaussian statistics).

\item {} 
\textbf{n} (\emph{integer}) -- Maximum number of iterations if \code{n} is not \code{None};
otherwise there is no maximum.

\end{itemize}

\item[{Returns}] \leavevmode
Iterator that returns a \code{lsqfit.LSQFit} object 
containing results from the fit to the next data set in
\code{data\_list}.

\end{description}\end{quote}

\end{fulllineitems}

\index{bootstrap\_iter() (corrfitter.CorrFitter method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.CorrFitter.bootstrap_iter}\pysiglinewithargsret{\bfcode{bootstrap\_iter}}{\emph{datalist=None}, \emph{n=None}}{}
Iterator that creates bootstrap copies of a {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} fit using 
bootstrap data from list \code{data\_list}.

A bootstrap analysis is a robust technique for estimating means and
standard deviations of arbitrary functions of the fit parameters.
This method creates an interator that implements such an analysis
of list (or iterator) \code{datalist}, which contains bootstrap
copies of the original data set. Each \code{data\_list{[}i{]}} is a different
\code{data} input for \code{self.lsqfit()} (that is, a dictionary containing
fit data). The iterator works its way through the data sets in
\code{data\_list}, fitting the next data set on each iteration and
returning the resulting \code{lsqfit.LSQFit} fit object. Typical
usage, for an {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} object named \code{fitter}, would be:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k}{for} \PYG{n}{fit} \PYG{o+ow}{in} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{bootstrap\PYGZus{}iter}\PYG{p}{(}\PYG{n}{datalist}\PYG{p}{)}\PYG{p}{:}
    \PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{n}{analyze} \PYG{n}{fit} \PYG{n}{parameters} \PYG{o+ow}{in} \PYG{n}{fit}\PYG{o}{.}\PYG{n}{p} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{data\_list} (sequence or iterator or \code{None}) -- Collection of bootstrap \code{data} sets for fitter. If
\code{None}, the data\_list is generated internally using the 
means and standard deviations of the fit data (assuming
gaussian statistics).

\item {} 
\textbf{n} (\emph{integer}) -- Maximum number of iterations if \code{n} is not \code{None};
otherwise there is no maximum.

\end{itemize}

\item[{Returns}] \leavevmode
Iterator that returns a \code{lsqfit.LSQFit} object 
containing results from the fit to the next data set in
\code{data\_list}.

\end{description}\end{quote}

\end{fulllineitems}

\index{builddata() (corrfitter.CorrFitter method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.CorrFitter.builddata}\pysiglinewithargsret{\bfcode{builddata}}{\emph{data}, \emph{prior}, \emph{nterm=None}}{}
Build fit data, corrected for marginalized terms.

\end{fulllineitems}

\index{buildfitfcn() (corrfitter.CorrFitter method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.CorrFitter.buildfitfcn}\pysiglinewithargsret{\bfcode{buildfitfcn}}{\emph{priorkeys}}{}
Create fit function, with support for log-normal,... priors.

\end{fulllineitems}

\index{buildprior() (corrfitter.CorrFitter method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.CorrFitter.buildprior}\pysiglinewithargsret{\bfcode{buildprior}}{\emph{prior}, \emph{nterm=None}, \emph{fast=False}}{}
Build correctly sized prior for fit from \code{prior}.

Adjust the sizes of the arrays of  amplitudes and energies in
a copy of \code{prior} according to  parameter \code{nterm}; return
\code{prior} if both \code{nterm} and \code{self.nterm} are \code{None}.

\end{fulllineitems}

\index{chained\_lsqfit() (corrfitter.CorrFitter method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.CorrFitter.chained_lsqfit}\pysiglinewithargsret{\bfcode{chained\_lsqfit}}{\emph{data}, \emph{prior}, \emph{p0=None}, \emph{print\_fit=True}, \emph{nterm=None}, \emph{svdcut=None}, \emph{tol=None}, \emph{maxit=None}, \emph{parallel=False}, \emph{flat=False}, \emph{fast=None}, \emph{**args}}{}
Compute chained least-squares fit.

A \emph{chained} fit fits data for each model in \code{self.models}
sequentially, using the best-fit parameters (means and
covariance matrix) of one fit to construct the prior for the
fit parameters in the  next fit: Correlators are fit one at a
time, starting with the correlator for \code{self.models{[}0{]}}. The
best-fit output from the fit for \code{self.models{[}i{]}} is fed, as
a prior, into the fit for \code{self.models{[}i+1{]}}. The best-fit
output from  the last fit in the chain is the final result.
Results from the individual fits can be found in dictionary
\code{self.fit.fits}, which is indexed  by the
\code{models{[}i{]}.datatag}s.

Setting parameter \code{parallel=True} causes parallel fits, where
each model is fit separately, using the original \code{prior}. Parallel
fits make sense when models share few or no parameters; the results
from the individual fits are combined using weighted averages of 
the best-fit values for each parameter from every fit. Parallel 
fits can require larger \emph{svd} cuts.

Entries \code{self.models{[}i{]}} in the list of models can themselves  be
lists of models, rather than just an individual model. In such a
chase, the models listed in \code{self.models{[}i{]}} are fit together using
a parallel fit if parameter \code{parallel} is \code{False} or a chained fit
otherwise. Grouping models in this ways instructs the fitter to
alternate between chained and parallel fits. For example, setting

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{models} \PYG{o}{=} \PYG{p}{[} \PYG{n}{m1}\PYG{p}{,} \PYG{n}{m2}\PYG{p}{,} \PYG{p}{[}\PYG{n}{m3a}\PYG{p}{,}\PYG{n}{m3b}\PYG{p}{]}\PYG{p}{,} \PYG{n}{m4}\PYG{p}{]}
\end{Verbatim}

with \code{parallel=False} causes the following chain of 
fits

\begin{Verbatim}[commandchars=\\\{\}]
m1 \PYGZhy{}\PYGZgt{} m2 \PYGZhy{}\PYGZgt{} [m3a,m3b] \PYGZhy{}\PYGZgt{} m4
\end{Verbatim}

where: 1) the output from \code{m1} is used as the prior for 
\code{m2}; 2) the output from \code{m2} is used as the prior for 
for a parallel fit of \code{m3a} and \code{m3b} together;
3) the output from the parallel fit of \code{{[}m3a,m3b{]}} is used
as the prior for \code{m4}; and, finally, 4) the output from 
\code{m4} is the final result of the entire chained fit.

A slightly more complicated example is

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{models} \PYG{o}{=} \PYG{p}{[} \PYG{n}{m1}\PYG{p}{,} \PYG{n}{m2}\PYG{p}{,} \PYG{p}{[}\PYG{n}{m3a}\PYG{p}{,}\PYG{p}{[}\PYG{n}{m3bx}\PYG{p}{,}\PYG{n}{m3by}\PYG{p}{]}\PYG{p}{]}\PYG{p}{,} \PYG{n}{m4}\PYG{p}{]}
\end{Verbatim}

which leads to the chain of fits
\begin{quote}

m1 -\textgreater{} m2 -\textgreater{} {[}m3a, m3bx -\textgreater{} m3by{]} -\textgreater{} m4
\end{quote}

where fits of \code{m3bx} and \code{m3by} are chained, in parallel with
the fit to \code{m3a}. The fitter alternates between chained and
parallel fits at each new level of grouping of models.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{data} (\emph{dictionary}) -- Input data. The \code{datatag}s from the 
correlator models are used as data labels, with 
\code{data{[}datatag{]}} being a 1-d array of \code{gvar.GVar}s 
corresponding to correlator values.

\item {} 
\textbf{prior} (\emph{dictionary}) -- Bayesian prior for the fit parameters used in the 
correlator models.

\item {} 
\textbf{p0} -- A dictionary, indexed by parameter labels, containing 
initial values for the parameters in the fit. Setting
\code{p0=None} implies that initial values are extracted from the
prior. Setting \code{p0="filename"} causes the fitter to look in
the file with name \code{"filename"} for initial values and to
write out best-fit parameter values after the fit (for the next
call to \code{self.lsqfit()}).

\item {} 
\textbf{parallel} (\emph{bool}) -- If \code{True}, fit models in parallel using \code{prior}
for each; otherwise chain the fits (default).

\item {} 
\textbf{flat} (\emph{bool}) -- If \code{True}, flatten the list of models thereby chaining
all fits (\code{parallel==False}) or doing them all in parallel
(\code{parallel==True}); otherwise use \code{self.models} 
as is (default).

\item {} 
\textbf{fast} -- If \code{True}, use the smallest number of parameters needed
in each fit; otherwise use all the parameters specified in 
\code{prior} in every fit. Omitting extra parameters can make 
fits go faster, sometimes much faster. Final results are 
unaffected unless \code{prior} contains strong correlations between 
different parameters, where only some of the correlated parameters 
are kept in individual fits. Default is \code{False}.

\item {} 
\textbf{print\_fit} -- Print fit information to standard output if 
\code{True}; otherwise print nothing.

\end{itemize}

\end{description}\end{quote}

The following parameters overwrite the values specified in the
{\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} constructor when set to anything other than \code{None}:
\code{nterm}, \code{svdcut}, \code{tol}, and \code{maxit}. Any
further keyword arguments are passed on to
\code{lsqfit.nonlinear\_fit()}, which does the fit.

\end{fulllineitems}

\index{collect\_fitresults() (corrfitter.CorrFitter method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.CorrFitter.collect_fitresults}\pysiglinewithargsret{\bfcode{collect\_fitresults}}{}{}
Collect results from last fit for plots, tables etc.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode

A dictionary with one entry per correlator model,
containing \code{(t,G,dG,Gth,dGth)} --- arrays containing:

\begin{Verbatim}[commandchars=\\\{\}]
t       = times
G(t)    = data averages for correlator at times t
dG(t)   = uncertainties in G(t)
Gth(t)  = fit function for G(t) with best\PYGZhy{}fit parameters
dGth(t) = uncertainties in Gth(t)
\end{Verbatim}


\end{description}\end{quote}

\end{fulllineitems}

\index{display\_plots() (corrfitter.CorrFitter method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.CorrFitter.display_plots}\pysiglinewithargsret{\bfcode{display\_plots}}{}{}
Show plots of data/fit-function for each correlator.

Assumes \code{matplotlib} is installed (to make the plots). Plots
are shown for one correlator at a time. Press key \code{n} to see the
next correlator; press key \code{p} to see the previous one; press key
\code{q} to quit the plot and return control to the calling program;
press a digit to go directly to one of the first ten plots. Zoom,
pan and save using the window controls.

\end{fulllineitems}

\index{lsqfit() (corrfitter.CorrFitter method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.CorrFitter.lsqfit}\pysiglinewithargsret{\bfcode{lsqfit}}{\emph{data}, \emph{prior}, \emph{p0=None}, \emph{print\_fit=True}, \emph{nterm=None}, \emph{svdcut=None}, \emph{tol=None}, \emph{maxit=None}, \emph{fast=None}, \emph{**args}}{}
Compute least-squares fit of the correlator models to data.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{data} (\emph{dictionary}) -- Input data. The \code{datatag}s from the 
correlator models are used as data labels, with 
\code{data{[}datatag{]}} being a 1-d array of \code{gvar.GVar}s 
corresponding to correlator values.

\item {} 
\textbf{prior} (\emph{dictionary}) -- Bayesian prior for the fit parameters used in the 
correlator models.

\item {} 
\textbf{p0} -- A dictionary, indexed by parameter labels, containing 
initial values for the parameters in the fit. Setting
\code{p0=None} implies that initial values are extracted from the
prior. Setting \code{p0="filename"} causes the fitter to look in
the file with name \code{"filename"} for initial values and to
write out best-fit parameter values after the fit (for the next
call to \code{self.lsqfit()}).

\item {} 
\textbf{print\_fit} -- Print fit information to standard output if 
\code{True}; otherwise print nothing.

\item {} 
\textbf{fast} -- If \code{True}, remove parameters from \code{prior} that are 
not needed by the correlator models; otherwise keep all 
parameters in \code{prior} as fit parameters (default). 
Ignoring extra parameters usually makes fits go faster.
This has no other effect unless there are correlations between the 
fit parameters needed by the models and the other parameters in 
\code{prior} that are ignored.

\end{itemize}

\end{description}\end{quote}

The following parameters overwrite the values specified in the
{\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} constructor when set to anything other than \code{None}:
\code{nterm}, \code{svdcut}, \code{tol}, and \code{maxit}. Any
further keyword arguments are passed on to
\code{lsqfit.nonlinear\_fit()}, which does the fit.

\end{fulllineitems}

\index{simulated\_data\_iter() (corrfitter.CorrFitter method)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.CorrFitter.simulated_data_iter}\pysiglinewithargsret{\bfcode{simulated\_data\_iter}}{\emph{n}, \emph{dataset}, \emph{pexact=None}, \emph{rescale=1.0}}{}
Create iterator that returns simulated fit data from \code{dataset}.

Simulated fit data has the same covariance matrix as 
\code{data=gvar.dataset.avg\_data(dataset)}, but mean values that 
fluctuate randomly, from copy to copy, around
the value of the fitter's fit function evaluated at \code{p=pexact}. 
The fluctuations are generated from averages of bootstrap copies
of \code{dataset}.

The best-fit results from a fit to such simulated copies of \code{data}  
should agree with the numbers in \code{pexact} to within the errors specified
by the fits (to the simulated data) --- \code{pexact} gives the ``correct'' 
values for the parameters. Knowing the correct value for each 
fit parameter ahead of a fit allows us to test the reliability of
the fit's error estimates and to explore the impact of various fit 
options (\emph{e.g.}, \code{fitter.chained\_fit} versus \code{fitter.lsqfit}, 
choice of \emph{svd} cuts, omission of select models, etc.)

Typically one need examine only a few simulated fits in order 
to evaluate fit reliability, since we know the correct values
for the parameters ahead of time. Consequently this method is
much faster than traditional bootstrap analyses. More 
thorough testing would involve running many simulations and
examining the distribution of fit parameters or functions 
of fit parameters around their exact values (from \code{pexact}). 
This is overkill for most problems, however.

\code{pexact} is usually taken from the last fit done by the fitter 
(\code{self.fit.pmean}) unless overridden in the function call.
Typical usage is as follows:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{dataset} \PYG{o}{=} \PYG{n}{gvar}\PYG{o}{.}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{Dataset}\PYG{p}{(}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{)}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{gvar}\PYG{o}{.}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{avg\PYGZus{}data}\PYG{p}{(}\PYG{n}{dataset}\PYG{p}{)}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{n}{fit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{)}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{k}{for} \PYG{n}{sdata} \PYG{o+ow}{in} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{simulated\PYGZus{}bootstrap\PYGZus{}data\PYGZus{}iter}\PYG{p}{(}\PYG{n}{n}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{n}{dataset}\PYG{p}{)}\PYG{p}{:}
    \PYG{c}{\PYGZsh{} redo fit 4 times with different simulated data each time}
    \PYG{c}{\PYGZsh{} here pexact=fit.pmean is set implicitly}
    \PYG{n}{sfit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{sdata}\PYG{p}{,} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{)}
    \PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{n}{check} \PYG{n}{that} \PYG{n}{sfit}\PYG{o}{.}\PYG{n}{p} \PYG{p}{(}\PYG{o+ow}{or} \PYG{n}{functions} \PYG{n}{of} \PYG{n}{it}\PYG{p}{)} \PYG{n}{agrees} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
    \PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{k}{with} \PYG{n}{pexact}\PYG{o}{=}\PYG{n}{fit}\PYG{o}{.}\PYG{n}{pmean} \PYG{n}{to} \PYG{n}{within} \PYG{n}{sfit}\PYG{o}{.}\PYG{n}{p}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{s errors      ...}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{n} (\emph{integer}) -- Maximum number of simulated data sets made by iterator.

\item {} 
\textbf{dataset} (\emph{gvar.dataset.Dataset}) -- Dataset containing Monte Carlo copies of the correlators.

\item {} 
\textbf{pexact} (\emph{dictionary of numbers}) -- Correct parameter values for fits to the simulated 
data --- fit results should agree with \code{pexact} to within
errors. If \code{None}, uses \code{self.fit.pmean} from the last fit.

\item {} 
\textbf{rescale} (\emph{positive number}) -- Rescale errors in simulated data by \code{rescale}
(\emph{i.e.}, multiply covariance matrix by \code{rescale ** 2}).
Default is one, which implies no rescaling.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{Fast Fit Objects}
\label{corrfitter:fast-fit-objects}\index{fastfit (class in corrfitter)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:corrfitter.fastfit}\pysiglinewithargsret{\strong{class }\code{corrfitter.}\bfcode{fastfit}}{\emph{data}, \emph{prior}, \emph{model}, \emph{svdcut=None}, \emph{ratio=True}, \emph{osc=False}}{}
Fast fit for the leading component of a \code{Corr2}.

This function class estimates \code{En{[}0{]}} and \code{an{[}0{]}*bn{[}0{]}} in a two-point 
correlator:

\begin{Verbatim}[commandchars=\\\{\}]
Gab(t) = sn * sum\PYGZus{}i an[i]*bn[i] * fn(En[i], t)
       + so * sum\PYGZus{}i ao[i]*bo[i] * fo(Eo[i], t)
\end{Verbatim}

where \code{sn} and \code{so} are typically \code{-1}, \code{0}, or \code{1} and

\begin{Verbatim}[commandchars=\\\{\}]
fn(E, t) =  exp(\PYGZhy{}E*t) + exp(\PYGZhy{}E*(tp\PYGZhy{}t)) \PYGZsh{} tp\PYGZgt{}0 \PYGZhy{}\PYGZhy{} periodic
       or   exp(\PYGZhy{}E*t) \PYGZhy{} exp(\PYGZhy{}E*(\PYGZhy{}tp\PYGZhy{}t))\PYGZsh{} tp\PYGZlt{}0 \PYGZhy{}\PYGZhy{} anti\PYGZhy{}periodic
       or   exp(\PYGZhy{}E*t)                  \PYGZsh{} if tp is None (nonperiodic)

fo(E, t) = (\PYGZhy{}1)**t * fn(E, t)
\end{Verbatim}

The correlator is specified by \code{model}, and \code{prior} is used to 
remove (marginalize) all terms other than the \code{En{[}0{]}} term
from the data. This gives a \emph{corrected} correlator \code{Gc(t)} that 
includes uncertainties due to the terms removed. Estimates of \code{En{[}0{]}} 
are given by:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{Eeff}\PYG{p}{(}\PYG{n}{t}\PYG{p}{)} \PYG{o}{=} \PYG{n}{arccosh}\PYG{p}{(}\PYG{l+m+mf}{0.5}\PYG{o}{*}\PYG{p}{(}\PYG{n}{Gc}\PYG{p}{(}\PYG{n}{t}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{o}{+}\PYG{n}{Gc}\PYG{p}{(}\PYG{n}{t}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{o}{/}\PYG{n}{Gc}\PYG{p}{(}\PYG{n}{t}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}
\end{Verbatim}

The final estimate is the weighted average \code{Eeff\_avg} of the
\code{Eeff(t)}s for different \code{t}s. Similarly, an estimate for the
product of amplitutes, \code{an{[}0{]}*bn{[}0{]}} is obtained from the weighted
average of

\begin{Verbatim}[commandchars=\\\{\}]
Aeff(t) = Gc(t)/fn(Eeff\PYGZus{}avg, t).
\end{Verbatim}

If \code{osc=True}, an estimate is returned for \code{Eo{[}0{]}} rather
than \code{En{[}0{]}}, and \code{ao{[}0{]}*bo{[}0{]}} rather than \code{an{[}0{]}*bn{[}0{]}}. 
These estimates are most reliable when \code{Eo{[}0{]}} is smaller than
\code{En{[}0{]}} (and so dominates at large \code{t}).

The results of the fast fit are stored and returned in an object of type 
{\hyperref[corrfitter:corrfitter.fastfit]{\code{corrfitter.fastfit}}} with the following attributies:
\index{E (fastfit attribute)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:fastfit.E}\pysigline{\bfcode{E}}
Estimate of \code{En{[}0{]}} (or \code{Eo{[}0{]}} if \code{osc==True}) computed
from the weighted average of \code{Eeff(t)} for \code{t}s in
\code{model.tfit}. The prior is also included in the weighted average.

\end{fulllineitems}

\index{ampl (fastfit attribute)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:fastfit.ampl}\pysigline{\bfcode{ampl}}
Estimate of \code{an{[}0{]}*bn{[}0{]}} (or \code{ao{[}0{]}*bo{[}0{]}} if \code{osc==True})
computed from the weighted average of \code{Aeff(t)} for \code{t}s in
\code{model.tfit{[}1:-1{]}}. The prior is also included in the weighted 
average.

\end{fulllineitems}

\index{chi2 (fastfit attribute)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:fastfit.chi2}\pysigline{\bfcode{chi2}}
\code{chi{[}0{]}} is the \code{chi**2} for the weighted average of
\code{Eeff(t)}s; \code{chi{[}1{]}} is the same for the \code{Aeff(t)}s.

\end{fulllineitems}

\index{dof (fastfit attribute)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:fastfit.dof}\pysigline{\bfcode{dof}}
\code{dof{[}0{]}} is the effective number of degrees of freedom in the
weighted average of \code{Eeff(t)}s; \code{dof{[}1{]}} is the same for the
\code{Aeff(t)}s.

\end{fulllineitems}

\index{Q (fastfit attribute)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:fastfit.Q}\pysigline{\bfcode{Q}}
\code{Q{[}0{]}} is the quality factor \emph{Q} for the weighted average of
\code{Eeff(t)}s; \code{Q{[}1{]}} is the same for the \code{Aeff(t)}s.

\end{fulllineitems}

\index{Elist (fastfit attribute)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:fastfit.Elist}\pysigline{\bfcode{Elist}}
List of \code{Eeff(t)}s used in the weighted average to estimate
\code{E}.

\end{fulllineitems}

\index{ampllist (fastfit attribute)}

\begin{fulllineitems}
\phantomsection\label{corrfitter:fastfit.ampllist}\pysigline{\bfcode{ampllist}}
List of \code{Aeff(t)}s used in the weighted average to estimate
\code{ampl}.

\end{fulllineitems}

\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{data} (\emph{dictionary}) -- Input data. The \code{datatag} from the correlator model is
used as a data key, with \code{data{[}datatag{]}} being a 1-d array of
\code{gvar.GVar}s corresponding to the correlator values.

\item {} 
\textbf{prior} (\emph{dictionary}) -- Bayesian prior for the fit parameters in the 
correlator model.

\item {} 
\textbf{model} (\emph{Corr2}) -- Correlator model for correlator of interest. The \code{t}s
in \code{model.tfit} must be consecutive.

\item {} 
\textbf{osc} (\emph{Bool}) -- If \code{True}, extract results for the leading oscillating
term in the correlator (\code{Eo{[}0{]}}); otherwise ignore.

\end{itemize}

\end{description}\end{quote}

In addition an \emph{svd} cut can be specified, as in {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}}, using
parameter \code{svdcut}. Also the type of marginalization
use can be specified with parameter \code{ratio} (see {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}}).

\end{fulllineitems}



\section{Annotated Example}
\label{corrfitter:annotated-example}\label{corrfitter:id2}
In this section we describe a complete script that uses \code{corrfitter} to
extract energies, amplitudes, and transition matrix elements for  the
\(\eta_s\) and \(D_s\) mesons. The source code (\code{example.py}) and
data file (\code{example.data}) are included with the \code{corrfitter}
distribution, in the \code{examples/} directory.

The \code{main} method follows the pattern described in {\hyperref[corrfitter:faster-fits]{\emph{Faster Fits}}}:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{\PYGZus{}\PYGZus{}future\PYGZus{}\PYGZus{}} \PYG{k+kn}{import} \PYG{n}{print\PYGZus{}function}   \PYG{c}{\PYGZsh{} makes this work for python2 and 3}

\PYG{k+kn}{import} \PYG{n+nn}{gvar} \PYG{k+kn}{as} \PYG{n+nn}{gv}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{collections}
\PYG{k+kn}{from} \PYG{n+nn}{corrfitter} \PYG{k+kn}{import} \PYG{n}{CorrFitter}\PYG{p}{,} \PYG{n}{Corr2}\PYG{p}{,} \PYG{n}{Corr3}

\PYG{k}{def} \PYG{n+nf}{main}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{data} \PYG{o}{=} \PYG{n}{make\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{example.data}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{fitter} \PYG{o}{=} \PYG{n}{CorrFitter}\PYG{p}{(}\PYG{n}{models}\PYG{o}{=}\PYG{n}{make\PYGZus{}models}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{p0} \PYG{o}{=} \PYG{n+nb+bp}{None}
    \PYG{k}{for} \PYG{n}{N} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{]}\PYG{p}{:}
        \PYG{k}{print}\PYG{p}{(}\PYG{l+m+mi}{30} \PYG{o}{*} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{=}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{nterm =}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{N}\PYG{p}{)}
        \PYG{n}{prior} \PYG{o}{=} \PYG{n}{make\PYGZus{}prior}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}
        \PYG{n}{fit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{,} \PYG{n}{p0}\PYG{o}{=}\PYG{n}{p0}\PYG{p}{)}
        \PYG{n}{p0} \PYG{o}{=} \PYG{n}{fit}\PYG{o}{.}\PYG{n}{pmean}
    \PYG{n}{print\PYGZus{}results}\PYG{p}{(}\PYG{n}{fit}\PYG{p}{,} \PYG{n}{prior}\PYG{p}{,} \PYG{n}{data}\PYG{p}{)}
    \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{display\PYGZus{}plots}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

The raw Monte Carlo data is in a file named \code{'example.data'}. We are doing
four fits, with 1, 2, 3, and 4 terms in the fit function. Each fit starts its
minimization at point \code{p0}, which is set equal to the mean values of the
best-fit parameters from the previous fit (\code{p0 = fit.pmean}). This reduces
the  number of iterations needed for convergence in the \code{N = 4} fit, for
example, from 217 to 23. It also makes multi-term fits more stable.

The last line displays plots of the fit data divided by the fit, provided
\code{matplotlib} is installed. A plot is made for each correlator, and the
ratios should equal one to within errors. To
move from one plot to the next press ``n'' on the keyboard; to move to a
previous plot press ``p''; to quit the plots press ``q''.

We now look at each other major routine in turn.


\subsection{a) make\_data}
\label{corrfitter:id3}
Method \code{make\_data('example.data')} reads in the Monte Carlo data, averages
it, and formats it for use by {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}}. The data file (\code{'example.data'})
contains 225 lines,  each with 64 numbers on it, of the form:

\begin{Verbatim}[commandchars=\\\{\}]
etas    0.3045088594E+00    0.7846334531E\PYGZhy{}01    0.3307295938E\PYGZhy{}01 ...
etas    0.3058093438E+00    0.7949004688E\PYGZhy{}01    0.3344648906E\PYGZhy{}01 ...
...
\end{Verbatim}

Each of these lines is a single Monte Carlo estimate for the \(\eta_s\)
correlator on a lattice with 64 lattice points in the \code{t} direction;
there are 225 Monte Carlo estimates in all. The same file also contains
225 lines describing the \(D_s\) meson correlator:

\begin{Verbatim}[commandchars=\\\{\}]
Ds    0.2303351094E+00    0.4445243750E\PYGZhy{}01    0.8941437344E\PYGZhy{}02 ...
Ds    0.2306766563E+00    0.4460026875E\PYGZhy{}01    0.8991960781E\PYGZhy{}02 ...
...
\end{Verbatim}

And it contains 225 lines each giving the 3-point amplitude for
\(\eta_s \to D_s\)
where the source and sink are separated by 15 and 16 time steps on the
lattice:

\begin{Verbatim}[commandchars=\\\{\}]
3ptT15    0.4679643906E\PYGZhy{}09    0.1079643844E\PYGZhy{}08    0.2422032031E\PYGZhy{}08 ...
3ptT15    0.4927106406E\PYGZhy{}09    0.1162639109E\PYGZhy{}08    0.2596277812E\PYGZhy{}08 ...
...

3ptT16     0.1420718453E\PYGZhy{}09    0.3205214219E\PYGZhy{}09    0.7382921875E\PYGZhy{}09 ...
3ptT16     0.1501385469E\PYGZhy{}09    0.3478552344E\PYGZhy{}09    0.8107883594E\PYGZhy{}09 ...
...
\end{Verbatim}

The first, second, third, \emph{etc.} lines for each label come from the first,
second, third, \emph{etc.} Monte Carlo iterations, respectively; this allows
the code to compute correlations between different
types of data.

We use the tools in \code{gvar.dataset} designed for reading files in this
format:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{make\PYGZus{}data}\PYG{p}{(}\PYG{n}{datafile}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{} Read data from datafile and average it. \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{k}{return} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{avg\PYGZus{}data}\PYG{p}{(}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{Dataset}\PYG{p}{(}\PYG{n}{datafile}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

This routine returns a dictionary whose keys are the strings used to label the
individual lines in \code{example.data}: for example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{data} \PYG{o}{=} \PYG{n}{make\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{example.data}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{print}\PYG{p}{(}\PYG{n}{data}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{g+go}{[0.2307150(73) 0.0446523(32) 0.0089923(15) ... 0.0446527(32)]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{print}\PYG{p}{(}\PYG{n}{data}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{3ptT16}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{g+go}{[1.4583(21)e\PYGZhy{}10 3.3639(44)e\PYGZhy{}10 ... 0.000023155(30)]}
\end{Verbatim}

Here each entry in \code{data} is an array of \code{gvar.GVar}s representing the Monte
Carlo estimates (mean and covariance) for the corresponding correlator. This
is the format needed by {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}}.


\subsection{b) make\_models}
\label{corrfitter:id4}
Method \code{make\_models()} specifies the theoretical models that will be used
to fit the data:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{make\PYGZus{}models}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{} Create models to fit data. \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{tmin} \PYG{o}{=} \PYG{l+m+mi}{5}
    \PYG{n}{tp} \PYG{o}{=} \PYG{l+m+mi}{64}
    \PYG{n}{models} \PYG{o}{=} \PYG{p}{[}
        \PYG{n}{Corr2}\PYG{p}{(}
            \PYG{n}{datatag}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{etas}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
            \PYG{n}{tp}\PYG{o}{=}\PYG{n}{tp}\PYG{p}{,}  \PYG{n}{tdata}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{tp}\PYG{p}{)}\PYG{p}{,}  \PYG{n}{tfit}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{tmin}\PYG{p}{,} \PYG{n}{tp}\PYG{o}{\PYGZhy{}}\PYG{n}{tmin}\PYG{p}{)}\PYG{p}{,}
            \PYG{n}{a}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{etas:a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}  \PYG{n}{b}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{etas:a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}  \PYG{n}{dE}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{etas:dE}\PYG{l+s}{\PYGZsq{}}
            \PYG{p}{)}\PYG{p}{,}

        \PYG{n}{Corr2}\PYG{p}{(}
            \PYG{n}{datatag}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
            \PYG{n}{tp}\PYG{o}{=}\PYG{n}{tp}\PYG{p}{,}  \PYG{n}{tdata}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{tp}\PYG{p}{)}\PYG{p}{,}  \PYG{n}{tfit}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{tmin}\PYG{p}{,} \PYG{n}{tp}\PYG{o}{\PYGZhy{}}\PYG{n}{tmin}\PYG{p}{)}\PYG{p}{,}
            \PYG{n}{a}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:ao}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{b}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:ao}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
            \PYG{n}{dE}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:dEo}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{s}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.}\PYG{p}{)}
            \PYG{p}{)}\PYG{p}{,}

        \PYG{n}{Corr3}\PYG{p}{(}
            \PYG{n}{datatag}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{3ptT15}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
            \PYG{n}{tdata}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{)}\PYG{p}{,} \PYG{n}{T}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,} \PYG{n}{tfit}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{tmin}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{o}{\PYGZhy{}}\PYG{n}{tmin}\PYG{p}{)}\PYG{p}{,}
            \PYG{n}{a}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{etas:a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dEa}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{etas:dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{tpa}\PYG{o}{=}\PYG{n}{tp}\PYG{p}{,}
            \PYG{n}{b}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:ao}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dEb}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:dEo}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tpb}\PYG{o}{=}\PYG{n}{tp}\PYG{p}{,} \PYG{n}{sb}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.}\PYG{p}{)}\PYG{p}{,}
            \PYG{n}{Vnn}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Vnn}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{Vno}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Vno}\PYG{l+s}{\PYGZsq{}}
            \PYG{p}{)}\PYG{p}{,}

        \PYG{n}{Corr3}\PYG{p}{(}
            \PYG{n}{datatag}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{3ptT16}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
            \PYG{n}{tdata}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{17}\PYG{p}{)}\PYG{p}{,} \PYG{n}{T}\PYG{o}{=}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{n}{tfit}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{tmin}\PYG{p}{,} \PYG{l+m+mi}{17}\PYG{o}{\PYGZhy{}}\PYG{n}{tmin}\PYG{p}{)}\PYG{p}{,}
            \PYG{n}{a}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{etas:a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dEa}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{etas:dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{tpa}\PYG{o}{=}\PYG{n}{tp}\PYG{p}{,}
            \PYG{n}{b}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:a}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:ao}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dEb}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:dE}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Ds:dEo}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tpb}\PYG{o}{=}\PYG{n}{tp}\PYG{p}{,} \PYG{n}{sb}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.}\PYG{p}{)}\PYG{p}{,}
            \PYG{n}{Vnn}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Vnn}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{Vno}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Vno}\PYG{l+s}{\PYGZsq{}}
            \PYG{p}{)}
        \PYG{p}{]}
    \PYG{k}{return} \PYG{n}{models}
\end{Verbatim}

Four models are specified, one for each correlator to be fit. The first two
are for the \(\eta_s\) and \(D_s\) two-point correlators, corresponding to
entries in the data dictionary with keys \code{'etas'} and \code{'Ds'},
respectively. These are periodic propagators, with period 64 (\code{tp}), and we want to
omit the first and last 5 (\code{tmin}) time steps in the correlator. The
\code{t}s to be fit are listed in \code{tfit}, while the \code{t}s contained in the
data are in \code{tdata}. Labels for the fit parameters corresponding to the
sources (and sinks) are specified for each, \code{'etas:a'} and \code{'Ds:a'}, as
are labels for the energy differences, \code{'etas:dE'} and \code{'Ds:dE'}.  The
\(D_s\) propagator also has an oscillating piece because this data comes from
a staggered-quark analysis. Sources/sinks and energy differences are
specified for these as well: \code{'Ds:ao'} and \code{'Ds:dEo'}.

Finally three-point models are specifies for the data corresponding to
data-dictionary keys \code{'3ptT15'} and \code{'3ptT16'}. These share several
parameters with the two-point correlators, but introduce new parameters
for the transition elements: \code{'Vnn'} connecting normal states, and
\code{'Vno'} connecting normal states with oscillating states.


\subsection{c) make\_prior}
\label{corrfitter:id5}
Method \code{make\_prior(N)} creates \emph{a priori} estimates for each fit
parameter, to be used as priors in the fitter:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{make\PYGZus{}prior}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{} Create priors for fit parameters. \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{prior} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{BufferDict}\PYG{p}{(}\PYG{p}{)}
    \PYG{c}{\PYGZsh{} etas}
    \PYG{n}{metas} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{0.4(2)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{log(etas:a)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{0.3(3)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{log(etas:dE)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{0.5(5)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{log(etas:dE)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{metas}\PYG{p}{)}

    \PYG{c}{\PYGZsh{} Ds}
    \PYG{n}{mDs} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{1.2(2)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{log(Ds:a)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{0.3(3)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{log(Ds:dE)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{0.5(5)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{log(Ds:dE)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{mDs}\PYG{p}{)}

    \PYG{c}{\PYGZsh{} Ds \PYGZhy{}\PYGZhy{} oscillating part}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{log(Ds:ao)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{0.1(1)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{log(Ds:dEo)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{0.5(5)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{log(Ds:dEo)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{mDs} \PYG{o}{+} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{0.3(3)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}

    \PYG{c}{\PYGZsh{} V}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Vnn}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{0(1)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}
    \PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Vno}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{0(1)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}

    \PYG{k}{return} \PYG{n}{prior}
\end{Verbatim}

Parameter \code{N} specifies how many terms are kept in the fit functions. The
priors are specified in a dictionary \code{prior}. Each entry is an array, of
length \code{N}, with one entry for each term. Each entry is a Gaussian random
variable, specified by an object of type  \code{gvar.GVar}. Here we use the fact that
\code{gvar.gvar()} can make a list of \code{gvar.GVar}s from a list of strings of the form
\code{'0.1(1)'}: for example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{print}\PYG{p}{(}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{1(2)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{3(2)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{[1.0(2.0) 3.0(2.0)]}
\end{Verbatim}

In this particular fit, we can assume that all the sinks/sources
are positive, and we can require that the energy differences be positive. To
force positivity, we use log-normal distributions for these parameters by
defining priors for \code{'log(etas:a)'}, \code{'log(etas:dE)'},... rather than
\code{'etas:a'},  \code{'etas:dE'},... (see {\hyperref[corrfitter:positive-parameters]{\emph{Faster Fits --- Postive Parameters}}}). The \emph{a
priori} values for these fit parameters are the logarithms of the values for
the parameters themselves: for example, each \code{etas:a'} has prior \code{0.3(3)},
while the actual fit parameters, \code{log(etas:a)}, have priors
\code{log(0.3(3)) = -1.2(1.0)}.

We override the default priors for the ground-state energies in each case.
This is not unusual since \code{dE{[}0{]}}, unlike the other \code{dE}s,  is an energy,
not an energy difference. For the oscillating \(D_s\) state, we require
that its mass be \code{0.3(3)} larger than the \(D_s\) mass. One could  put
more precise information into the priors if that made sense given the goals
of the simulation. For example, if the main objective is a value for \code{Vnn},
one might include fairly exact information about the \(D_s\) and
\(\eta_s\) masses in the prior, using results from experiment or from
earlier simulations. This would make no sense, however, if the goal is to
verify that simulations gives correct masses.

Note, finally, that a statement like

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Vnn}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{n}{N}\PYG{o}{*} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{0(1)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}       \PYG{c}{\PYGZsh{} correct}
\end{Verbatim}

is \emph{not} the same as

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{prior}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Vnn}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{n}{N} \PYG{o}{*} \PYG{p}{[}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{gvar}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{0(1)}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{]}      \PYG{c}{\PYGZsh{} wrong}
\end{Verbatim}

The former creates \code{N ** 2} independent \code{gvar.GVar}s, with one for each element
of \code{Vnn}; it is one of the most succinct ways of creating a large number of
\code{gvar.GVar}s. The latter creates only a single \code{gvar.GVar} and uses it repeatedly for
every element \code{Vnn}, thereby forcing every element of \code{Vnn}  to be equal
to every other element when fitting (since the difference between any two of
their priors is \code{0\(\pm\)0}); it is almost certainly not what is desired.
Usually one wants to create the array of strings first, and then convert it to
\code{gvar.GVar}s using \code{gvar.gvar()}.


\subsection{d) print\_results}
\label{corrfitter:id6}
Method \code{print\_results(fit, prior, data)} reports on the best-fit values
for the fit parameters from the last fit:

\begin{Verbatim}[commandchars=\\\{\}]
def print\PYGZus{}results(fit, prior, data):
    print(\PYGZsq{}Fit results:\PYGZsq{})
    p = fit.transformed\PYGZus{}p                   \PYGZsh{} best\PYGZhy{}fit parameterss

    \PYGZsh{} etas
    E\PYGZus{}etas = np.cumsum(p[\PYGZsq{}etas:dE\PYGZsq{}])
    a\PYGZus{}etas = p[\PYGZsq{}etas:a\PYGZsq{}])
    print(\PYGZsq{}  Eetas:\PYGZsq{}, E\PYGZus{}etas[:3])
    print(\PYGZsq{}  aetas:\PYGZsq{}, a\PYGZus{}etas[:3])

    \PYGZsh{} Ds
    E\PYGZus{}Ds = np.cumsum(p[\PYGZsq{}Ds:dE\PYGZsq{}])
    a\PYGZus{}Ds = p[\PYGZsq{}Ds:a\PYGZsq{}])
    print(\PYGZsq{}\PYGZbs{}n  EDs:\PYGZsq{}, E\PYGZus{}Ds[:3])
    print(  \PYGZsq{}  aDs:\PYGZsq{}, a\PYGZus{}Ds[:3])

    \PYGZsh{} Dso \PYGZhy{}\PYGZhy{} oscillating piece
    E\PYGZus{}Dso = np.cumsum(p[\PYGZsq{}Ds:dEo\PYGZsq{}])
    a\PYGZus{}Dso = p[\PYGZsq{}Ds:ao\PYGZsq{}]
    print(\PYGZsq{}\PYGZbs{}n  EDso:\PYGZsq{}, E\PYGZus{}Dso[:3])
    print(  \PYGZsq{}  aDso:\PYGZsq{}, a\PYGZus{}Dso[:3])

    \PYGZsh{} V
    Vnn = p[\PYGZsq{}Vnn\PYGZsq{}]
    Vno = p[\PYGZsq{}Vno\PYGZsq{}]
    print(\PYGZsq{}\PYGZbs{}n  etas\PYGZhy{}\PYGZgt{}V\PYGZhy{}\PYGZgt{}Ds:\PYGZsq{}, Vnn[0, 0])
    print(\PYGZsq{}  etas\PYGZhy{}\PYGZgt{}V\PYGZhy{}\PYGZgt{}Dso:\PYGZsq{}, Vno[0, 0])

    \PYGZsh{} error budget
    outputs = gv.BufferDict()
    outputs[\PYGZsq{}metas\PYGZsq{}] = E\PYGZus{}etas[0]
    outputs[\PYGZsq{}mDs\PYGZsq{}] = E\PYGZus{}Ds[0]
    outputs[\PYGZsq{}mDso\PYGZhy{}mDs\PYGZsq{}] = E\PYGZus{}Dso[0] \PYGZhy{} E\PYGZus{}Ds[0]
    outputs[\PYGZsq{}Vnn\PYGZsq{}] = Vnn[0, 0]
    outputs[\PYGZsq{}Vno\PYGZsq{}] = Vno[0, 0]

    inputs = collections.OrderedDict()      \PYGZsh{} can use dict() instead
    inputs[\PYGZsq{}statistics\PYGZsq{}] = data             \PYGZsh{} statistical errors in data
    inputs.update(prior)                    \PYGZsh{} all entries in prior
    inputs[\PYGZsq{}svd\PYGZsq{}] = fit.svdcorrection       \PYGZsh{} svd cut (if present)

    print(\PYGZsq{}\PYGZbs{}n\PYGZsq{} + gv.fmt\PYGZus{}values(outputs))
    print(gv.fmt\PYGZus{}errorbudget(outputs, inputs))

    print(\PYGZsq{}\PYGZbs{}n\PYGZsq{})
\end{Verbatim}

The best-fit parameter values are stored in dictionary \code{p=fit.transformed\_p},
as are the exponentials of the log-normal parameters.
We also turn energy differences into energies using \code{numpy}`s cummulative
sum function \code{numpy.cumsum()}. The final output is:

\begin{Verbatim}[commandchars=\\\{\}]
Fit results:
  Eetas: [0.41619(12) 1.007(89) 1.43(34)]
  aetas: [0.21834(16) 0.170(74) 0.30(12)]

  EDs: [1.20166(16) 1.704(17) 2.29(20)]
  aDs: [0.21466(20) 0.275(20) 0.52(20)]

  EDso: [1.442(16) 1.65(11) 2.17(44)]
  aDso: [0.0634(90) 0.080(26) 0.116(93)]

  etas\PYGZhy{}\PYGZgt{}V\PYGZhy{}\PYGZgt{}Ds  = 0.76725(76)
  etas\PYGZhy{}\PYGZgt{}V\PYGZhy{}\PYGZgt{}Dso = \PYGZhy{}0.793(92)
\end{Verbatim}

Finally we  create an error budget for the \(\eta_s\)
and \(D_s\) masses, for the mass difference between the \(D_s\) and its
opposite-parity partner, and for the ground-state transition amplitudes
\code{Vnn} and \code{Vno}. The quantities of interest are specified in dictionary
\code{outputs}. For the error budget, we need another dictionary, \code{inputs},
specifying various inputs to the calculation: the Monte Carlo data, the
priors, and the results from any \emph{svd} cuts (none here). Each of these inputs
contributes to the errors in the final results, as detailed in the
error budget:

\begin{Verbatim}[commandchars=\\\{\}]
Values:
              metas: 0.41619(12)
                mDs: 1.20166(16)
           mDso\PYGZhy{}mDs: 0.240(16)
                Vnn: 0.76725(76)
                Vno: \PYGZhy{}0.793(92)

Partial \PYGZpc{} Errors:
                         metas       mDs  mDso\PYGZhy{}mDs       Vnn       Vno
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
         statistics:      0.03      0.01      4.51      0.09      8.60
        log(etas:a):      0.00      0.00      0.11      0.01      0.39
       log(etas:dE):      0.00      0.00      0.06      0.01      0.38
          log(Ds:a):      0.00      0.00      0.53      0.02      0.96
         log(Ds:dE):      0.00      0.00      0.44      0.02      0.59
         log(Ds:ao):      0.00      0.00      1.10      0.01      3.85
        log(Ds:dEo):      0.00      0.00      1.14      0.01      5.66
                Vnn:      0.00      0.00      0.58      0.03      1.03
                Vno:      0.00      0.00      4.25      0.01      3.39
                svd:      0.00      0.00      0.00      0.00      0.00
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
              total:      0.03      0.01      6.46      0.10     11.61
\end{Verbatim}

The error budget shows, for example, that the largest sources of uncertainty
in every quantity are the statistical errors in the input data.


\subsection{e) Final Results}
\label{corrfitter:e-final-results}
The output from running this code is as follows:

\begin{Verbatim}[commandchars=\\\{\}]
============================== nterm = 1
Least Square Fit:
  chi2/dof [dof] = 7.4e+03 [69]    Q = 0    logGBF = \PYGZhy{}2.5405e+05

Parameters:
  log(etas:a) 0   \PYGZhy{}1.38766 (30)      [ \PYGZhy{}1.2 (1.0) ]  
 log(etas:dE) 0   \PYGZhy{}0.80364 (14)      [ \PYGZhy{}0.92 (50) ]  
    log(Ds:a) 0   \PYGZhy{}1.35559 (20)      [ \PYGZhy{}1.2 (1.0) ]  
   log(Ds:dE) 0   0.220836 (54)      [  0.18 (17) ]  
   log(Ds:ao) 0    \PYGZhy{}1.7014 (16)      [ \PYGZhy{}2.3 (1.0) ]  
  log(Ds:dEo) 0    0.54320 (39)      [  0.41 (24) ]  
        Vnn 0,0    0.74220 (23)      [  0.0 (1.0) ]  
        Vno 0,0    \PYGZhy{}1.0474 (21)      [  0.0 (1.0) ]  *

Settings:
  svdcut/n = 1e\PYGZhy{}15/0    reltol/abstol = 1e\PYGZhy{}10/1e\PYGZhy{}10    (itns/time = 24/0.2)

============================== nterm = 2
Least Square Fit:
  chi2/dof [dof] = 3 [69]    Q = 6e\PYGZhy{}16    logGBF = 1531.1

Parameters:
  log(etas:a) 0   \PYGZhy{}1.52065 (64)      [ \PYGZhy{}1.2 (1.0) ]  
              1     \PYGZhy{}1.300 (15)      [ \PYGZhy{}1.2 (1.0) ]  
 log(etas:dE) 0   \PYGZhy{}0.87643 (26)      [ \PYGZhy{}0.92 (50) ]  
              1     \PYGZhy{}0.331 (10)      [ \PYGZhy{}0.7 (1.0) ]  
    log(Ds:a) 0   \PYGZhy{}1.53878 (66)      [ \PYGZhy{}1.2 (1.0) ]  
              1    \PYGZhy{}1.0798 (68)      [ \PYGZhy{}1.2 (1.0) ]  
   log(Ds:dE) 0    0.18357 (11)      [  0.18 (17) ]  
              1    \PYGZhy{}0.5880 (55)      [ \PYGZhy{}0.7 (1.0) ]  
   log(Ds:ao) 0    \PYGZhy{}2.6014 (75)      [ \PYGZhy{}2.3 (1.0) ]  
              1     \PYGZhy{}1.266 (76)      [ \PYGZhy{}2.3 (1.0) ]  *
  log(Ds:dEo) 0     0.3735 (14)      [  0.41 (24) ]  
              1     \PYGZhy{}0.323 (41)      [ \PYGZhy{}0.7 (1.0) ]  
        Vnn 0,0    0.76314 (30)      [  0.0 (1.0) ]  
            0,1    \PYGZhy{}0.4536 (52)      [  0.0 (1.0) ]  
            1,0     0.0799 (73)      [  0.0 (1.0) ]  
            1,1      \PYGZhy{}0.25 (76)      [  0.0 (1.0) ]  
        Vno 0,0    \PYGZhy{}0.6796 (76)      [  0.0 (1.0) ]  
            0,1      0.946 (66)      [  0.0 (1.0) ]  
            1,0      \PYGZhy{}1.00 (13)      [  0.0 (1.0) ]  
            1,1     0.06 (1.00)      [  0.0 (1.0) ]  

Settings:
  svdcut/n = 1e\PYGZhy{}15/0    reltol/abstol = 1e\PYGZhy{}10/1e\PYGZhy{}10    (itns/time = 75/0.8)

============================== nterm = 3
Least Square Fit:
  chi2/dof [dof] = 0.7 [69]    Q = 0.97    logGBF = 1601.6

Parameters:
  log(etas:a) 0     \PYGZhy{}1.52172 (73)       [ \PYGZhy{}1.2 (1.0) ]  
              1        \PYGZhy{}1.81 (47)       [ \PYGZhy{}1.2 (1.0) ]  
              2        \PYGZhy{}1.13 (20)       [ \PYGZhy{}1.2 (1.0) ]  
 log(etas:dE) 0     \PYGZhy{}0.87662 (28)       [ \PYGZhy{}0.92 (50) ]  
              1        \PYGZhy{}0.54 (17)       [ \PYGZhy{}0.7 (1.0) ]  
              2        \PYGZhy{}0.82 (44)       [ \PYGZhy{}0.7 (1.0) ]  
    log(Ds:a) 0     \PYGZhy{}1.53871 (91)       [ \PYGZhy{}1.2 (1.0) ]  
              1       \PYGZhy{}1.290 (73)       [ \PYGZhy{}1.2 (1.0) ]  
              2        \PYGZhy{}0.58 (33)       [ \PYGZhy{}1.2 (1.0) ]  
   log(Ds:dE) 0      0.18370 (13)       [  0.18 (17) ]  
              1       \PYGZhy{}0.690 (34)       [ \PYGZhy{}0.7 (1.0) ]  
              2        \PYGZhy{}0.49 (29)       [ \PYGZhy{}0.7 (1.0) ]  
   log(Ds:ao) 0        \PYGZhy{}2.76 (14)       [ \PYGZhy{}2.3 (1.0) ]  
              1        \PYGZhy{}2.53 (34)       [ \PYGZhy{}2.3 (1.0) ]  
              2        \PYGZhy{}2.11 (77)       [ \PYGZhy{}2.3 (1.0) ]  
  log(Ds:dEo) 0        0.366 (11)       [  0.41 (24) ]  
              1        \PYGZhy{}1.59 (54)       [ \PYGZhy{}0.7 (1.0) ]  
              2        \PYGZhy{}0.64 (76)       [ \PYGZhy{}0.7 (1.0) ]  
        Vnn 0,0      0.76725 (76)       [  0.0 (1.0) ]  
            0,1       \PYGZhy{}0.490 (32)       [  0.0 (1.0) ]  
            0,2         0.51 (51)       [  0.0 (1.0) ]  
            1,0        0.049 (37)       [  0.0 (1.0) ]  
            1,1         0.24 (68)       [  0.0 (1.0) ]  
            1,2    \PYGZhy{}0.005 (0.995)       [  0.0 (1.0) ]  
            2,0        \PYGZhy{}0.06 (14)       [  0.0 (1.0) ]  
            2,1       0.05 (1.00)       [  0.0 (1.0) ]  
            2,2   0.0004 (1.0000)       [  0.0 (1.0) ]  
        Vno 0,0       \PYGZhy{}0.793 (93)       [  0.0 (1.0) ]  
            0,1         0.26 (33)       [  0.0 (1.0) ]  
            0,2      \PYGZhy{}0.006 (841)       [  0.0 (1.0) ]  
            1,0         0.39 (45)       [  0.0 (1.0) ]  
            1,1         0.20 (95)       [  0.0 (1.0) ]  
            1,2    \PYGZhy{}0.006 (0.999)       [  0.0 (1.0) ]  
            2,0        \PYGZhy{}0.17 (92)       [  0.0 (1.0) ]  
            2,1     0.006 (0.999)       [  0.0 (1.0) ]  
            2,2   0.0007 (1.0000)       [  0.0 (1.0) ]  

Settings:
  svdcut/n = 1e\PYGZhy{}15/0    reltol/abstol = 1e\PYGZhy{}10/1e\PYGZhy{}10    (itns/time = 73/0.8)

============================== nterm = 4
Least Square Fit:
  chi2/dof [dof] = 0.7 [69]    Q = 0.97    logGBF = 1602.1

Parameters:
  log(etas:a) 0       \PYGZhy{}1.52170 (73)        [ \PYGZhy{}1.2 (1.0) ]  
              1          \PYGZhy{}1.77 (43)        [ \PYGZhy{}1.2 (1.0) ]  
              2          \PYGZhy{}1.22 (42)        [ \PYGZhy{}1.2 (1.0) ]  
              3          \PYGZhy{}1.31 (95)        [ \PYGZhy{}1.2 (1.0) ]  
 log(etas:dE) 0       \PYGZhy{}0.87661 (28)        [ \PYGZhy{}0.92 (50) ]  
              1          \PYGZhy{}0.53 (15)        [ \PYGZhy{}0.7 (1.0) ]  
              2          \PYGZhy{}0.85 (62)        [ \PYGZhy{}0.7 (1.0) ]  
              3          \PYGZhy{}0.62 (97)        [ \PYGZhy{}0.7 (1.0) ]  
    log(Ds:a) 0       \PYGZhy{}1.53869 (91)        [ \PYGZhy{}1.2 (1.0) ]  
              1         \PYGZhy{}1.290 (74)        [ \PYGZhy{}1.2 (1.0) ]  
              2          \PYGZhy{}0.65 (39)        [ \PYGZhy{}1.2 (1.0) ]  
              3          \PYGZhy{}1.11 (99)        [ \PYGZhy{}1.2 (1.0) ]  
   log(Ds:dE) 0        0.18370 (13)        [  0.18 (17) ]  
              1         \PYGZhy{}0.689 (35)        [ \PYGZhy{}0.7 (1.0) ]  
              2          \PYGZhy{}0.53 (32)        [ \PYGZhy{}0.7 (1.0) ]  
              3          \PYGZhy{}0.77 (99)        [ \PYGZhy{}0.7 (1.0) ]  
   log(Ds:ao) 0          \PYGZhy{}2.76 (14)        [ \PYGZhy{}2.3 (1.0) ]  
              1          \PYGZhy{}2.53 (33)        [ \PYGZhy{}2.3 (1.0) ]  
              2          \PYGZhy{}2.15 (80)        [ \PYGZhy{}2.3 (1.0) ]  
              3          \PYGZhy{}2.3 (1.0)        [ \PYGZhy{}2.3 (1.0) ]  
  log(Ds:dEo) 0          0.366 (11)        [  0.41 (24) ]  
              1          \PYGZhy{}1.59 (53)        [ \PYGZhy{}0.7 (1.0) ]  
              2          \PYGZhy{}0.65 (74)        [ \PYGZhy{}0.7 (1.0) ]  
              3          \PYGZhy{}0.7 (1.0)        [ \PYGZhy{}0.7 (1.0) ]  
        Vnn 0,0        0.76725 (76)        [  0.0 (1.0) ]  
            0,1         \PYGZhy{}0.492 (33)        [  0.0 (1.0) ]  
            0,2           0.50 (51)        [  0.0 (1.0) ]  
            0,3         0.06 (1.00)        [  0.0 (1.0) ]  
            1,0          0.050 (42)        [  0.0 (1.0) ]  
            1,1           0.25 (70)        [  0.0 (1.0) ]  
            1,2      \PYGZhy{}0.005 (0.995)        [  0.0 (1.0) ]  
            1,3    \PYGZhy{}0.0007 (1.0000)        [  0.0 (1.0) ]  
            2,0          \PYGZhy{}0.07 (19)        [  0.0 (1.0) ]  
            2,1         0.05 (1.00)        [  0.0 (1.0) ]  
            2,2     0.0004 (1.0000)        [  0.0 (1.0) ]  
            2,3   \PYGZhy{}1.22862e\PYGZhy{}05 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            3,0         0.002 (977)        [  0.0 (1.0) ]  
            3,1       0.003 (1.000)        [  0.0 (1.0) ]  
            3,2    2.80928e\PYGZhy{}05 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            3,3    1.86812e\PYGZhy{}07 +\PYGZhy{} 1        [  0.0 (1.0) ]  
        Vno 0,0         \PYGZhy{}0.793 (92)        [  0.0 (1.0) ]  
            0,1           0.25 (33)        [  0.0 (1.0) ]  
            0,2         0.005 (845)        [  0.0 (1.0) ]  
            0,3         0.01 (1.00)        [  0.0 (1.0) ]  
            1,0           0.38 (45)        [  0.0 (1.0) ]  
            1,1           0.22 (95)        [  0.0 (1.0) ]  
            1,2      \PYGZhy{}0.004 (0.999)        [  0.0 (1.0) ]  
            1,3    \PYGZhy{}0.0009 (1.0000)        [  0.0 (1.0) ]  
            2,0          \PYGZhy{}0.17 (93)        [  0.0 (1.0) ]  
            2,1       0.005 (0.999)        [  0.0 (1.0) ]  
            2,2     0.0007 (1.0000)        [  0.0 (1.0) ]  
            2,3   \PYGZhy{}1.45695e\PYGZhy{}05 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            3,0        \PYGZhy{}0.03 (1.00)        [  0.0 (1.0) ]  
            3,1      \PYGZhy{}0.003 (1.000)        [  0.0 (1.0) ]  
            3,2    1.25677e\PYGZhy{}05 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            3,3    3.95644e\PYGZhy{}07 +\PYGZhy{} 1        [  0.0 (1.0) ]  

Settings:
  svdcut/n = 1e\PYGZhy{}15/0    reltol/abstol = 1e\PYGZhy{}10/1e\PYGZhy{}10    (itns/time = 20/0.4)

Fit results:
  Eetas: [0.41619(12) 1.007(89) 1.43(34)]
  aetas: [0.21834(16) 0.170(74) 0.30(12)]

  EDs: [1.20166(16) 1.704(17) 2.29(20)]
  aDs: [0.21466(20) 0.275(20) 0.52(20)]

  EDso: [1.442(16) 1.65(11) 2.17(44)]
  aDso: [0.0634(90) 0.080(26) 0.116(93)]

  etas\PYGZhy{}\PYGZgt{}V\PYGZhy{}\PYGZgt{}Ds  = 0.76725(76)
  etas\PYGZhy{}\PYGZgt{}V\PYGZhy{}\PYGZgt{}Dso = \PYGZhy{}0.793(92)

Values:
              metas: 0.41619(12)         
                mDs: 1.20166(16)         
           mDso\PYGZhy{}mDs: 0.240(16)           
                Vnn: 0.76725(76)         
                Vno: \PYGZhy{}0.793(92)          

Partial \PYGZpc{} Errors:
                         metas       mDs  mDso\PYGZhy{}mDs       Vnn       Vno
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
         statistics:      0.03      0.01      4.51      0.09      8.60
        log(etas:a):      0.00      0.00      0.11      0.01      0.39
       log(etas:dE):      0.00      0.00      0.06      0.01      0.38
          log(Ds:a):      0.00      0.00      0.53      0.02      0.96
         log(Ds:dE):      0.00      0.00      0.44      0.02      0.59
         log(Ds:ao):      0.00      0.00      1.10      0.01      3.85
        log(Ds:dEo):      0.00      0.00      1.14      0.01      5.66
                Vnn:      0.00      0.00      0.58      0.03      1.03
                Vno:      0.00      0.00      4.25      0.01      3.39
                svd:      0.00      0.00      0.00      0.00      0.00
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
              total:      0.03      0.01      6.46      0.10     11.61




Random seed: (5339893179535759510, 4088224360017966188, 7597275990505476522)

============================== simulation
Least Square Fit:
  chi2/dof [dof] = 0.7 [69]    Q = 0.97    logGBF = 1602.4

Parameters:
  log(etas:a) 0   \PYGZhy{}1.52098 (72)      [ \PYGZhy{}1.2 (1.0) ]  
              1      \PYGZhy{}1.71 (49)      [ \PYGZhy{}1.2 (1.0) ]  
 log(etas:dE) 0   \PYGZhy{}0.87634 (28)      [ \PYGZhy{}0.92 (50) ]  
              1      \PYGZhy{}0.52 (16)      [ \PYGZhy{}0.7 (1.0) ]  
    log(Ds:a) 0   \PYGZhy{}1.53883 (91)      [ \PYGZhy{}1.2 (1.0) ]  
              1     \PYGZhy{}1.390 (78)      [ \PYGZhy{}1.2 (1.0) ]  
   log(Ds:dE) 0    0.18377 (13)      [  0.18 (17) ]  
              1     \PYGZhy{}0.735 (37)      [ \PYGZhy{}0.7 (1.0) ]  
   log(Ds:ao) 0     \PYGZhy{}2.670 (58)      [ \PYGZhy{}2.3 (1.0) ]  
              1      \PYGZhy{}2.34 (14)      [ \PYGZhy{}2.3 (1.0) ]  
  log(Ds:dEo) 0     0.3719 (55)      [  0.41 (24) ]  
              1      \PYGZhy{}1.20 (21)      [ \PYGZhy{}0.7 (1.0) ]  
        Vnn 0,0    0.76751 (76)      [  0.0 (1.0) ]  
            0,1     \PYGZhy{}0.459 (35)      [  0.0 (1.0) ]  
            1,0      0.080 (53)      [  0.0 (1.0) ]  
            1,1       0.72 (73)      [  0.0 (1.0) ]  
        Vno 0,0     \PYGZhy{}0.755 (29)      [  0.0 (1.0) ]  
            0,1       0.37 (16)      [  0.0 (1.0) ]  
            1,0      \PYGZhy{}0.07 (40)      [  0.0 (1.0) ]  
            1,1       0.27 (96)      [  0.0 (1.0) ]  

Settings:
  svdcut/n = 1e\PYGZhy{}15/0    reltol/abstol = 1e\PYGZhy{}10/1e\PYGZhy{}10    (itns/time = 22/0.2)

Leading parameter chi2/dof [dof] = 0.82 [8]   Q = 0.6

============================== simulation
Least Square Fit:
  chi2/dof [dof] = 0.63 [69]    Q = 0.99    logGBF = 1604.6

Parameters:
  log(etas:a) 0   \PYGZhy{}1.52243 (70)      [ \PYGZhy{}1.2 (1.0) ]  
              1      \PYGZhy{}1.34 (50)      [ \PYGZhy{}1.2 (1.0) ]  
 log(etas:dE) 0   \PYGZhy{}0.87680 (27)      [ \PYGZhy{}0.92 (50) ]  
              1      \PYGZhy{}0.41 (13)      [ \PYGZhy{}0.7 (1.0) ]  
    log(Ds:a) 0   \PYGZhy{}1.53999 (93)      [ \PYGZhy{}1.2 (1.0) ]  
              1     \PYGZhy{}1.455 (75)      [ \PYGZhy{}1.2 (1.0) ]  
   log(Ds:dE) 0    0.18355 (13)      [  0.18 (17) ]  
              1     \PYGZhy{}0.771 (38)      [ \PYGZhy{}0.7 (1.0) ]  
   log(Ds:ao) 0     \PYGZhy{}2.700 (72)      [ \PYGZhy{}2.3 (1.0) ]  
              1      \PYGZhy{}2.39 (12)      [ \PYGZhy{}2.3 (1.0) ]  
  log(Ds:dEo) 0     0.3688 (64)      [  0.41 (24) ]  
              1      \PYGZhy{}1.32 (22)      [ \PYGZhy{}0.7 (1.0) ]  
        Vnn 0,0    0.76780 (76)      [  0.0 (1.0) ]  
            0,1     \PYGZhy{}0.437 (33)      [  0.0 (1.0) ]  
            1,0      0.065 (62)      [  0.0 (1.0) ]  
            1,1       0.15 (77)      [  0.0 (1.0) ]  
        Vno 0,0     \PYGZhy{}0.761 (34)      [  0.0 (1.0) ]  
            0,1       0.33 (17)      [  0.0 (1.0) ]  
            1,0       0.07 (40)      [  0.0 (1.0) ]  
            1,1      \PYGZhy{}0.14 (97)      [  0.0 (1.0) ]  

Settings:
  svdcut/n = 1e\PYGZhy{}15/0    reltol/abstol = 1e\PYGZhy{}10/1e\PYGZhy{}10    (itns/time = 11/0.2)

Leading parameter chi2/dof [dof] = 0.56 [8]   Q = 0.8
\end{Verbatim}

Note:
\begin{itemize}
\item {} 
This is a relatively simple fit, taking only a couple of seconds on a
laptop.

\item {} 
Fits with only one or two terms in the fit function are poor, with
\code{chi2/dof}s that are significantly larger than one.

\item {} 
Fits with three terms work well, and adding futher terms has almost no
impact. The \code{chi**2} does not improve and parameters for the
added terms differ little from their prior values (since the data are
not sufficiently accurate to add new information).

\item {} 
Chained fits (see {\hyperref[corrfitter:chained-fits]{\emph{Faster Fits --- Chained Fits}}}) are used if \code{fitter.lsqfit(...)}
is replaced by \code{fitter.chained\_lsqfit(...)} in \code{main()}. The results
are about the same: for example,

\begin{Verbatim}[commandchars=\\\{\}]
Values:
              metas: 0.41619(12)
                mDs: 1.20156(17)
           mDso\PYGZhy{}mDs: 0.2554(41)
                Vnn: 0.7676(12)
                Vno: \PYGZhy{}0.754(26)
\end{Verbatim}

We obtain more or less the same results,

\begin{Verbatim}[commandchars=\\\{\}]
Values:
              metas: 0.41619(11)
                mDs: 1.20156(15)
           mDso\PYGZhy{}mDs: 0.2576(27)
                Vnn: 0.76666(67)
                Vno: \PYGZhy{}0.747(15)
\end{Verbatim}

if we polish the final results from the chained fit using
a final call to \code{fitter.lsqfit} (see {\hyperref[corrfitter:chained-fits]{\emph{Faster Fits --- Chained Fits}}}):

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{fit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{chained\PYGZus{}lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{,} \PYG{n}{p0}\PYG{o}{=}\PYG{n}{p0}\PYG{p}{)}
\PYG{n}{fit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{fit}\PYG{o}{.}\PYG{n}{p}\PYG{p}{,} \PYG{n}{svdcut}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}4}\PYG{p}{)}
\end{Verbatim}

Another variation is to replace the last line (\code{return models})
in \code{make\_models()} by:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k}{return} \PYG{p}{[}\PYG{n}{models}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{]} \PYG{o}{+} \PYG{n}{models}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{:}\PYG{p}{]}
\end{Verbatim}

This causes the two 2-point correlators (\code{models{[}:2{]}}) to be fit
in parallel, which makes sense since they share no parameters.
The result of the (parallel) fit of the 2-point correlators is used
as a prior for the chained fits of the 3-point correlators (\code{models{[}2:{]}}).
The fit results are mostly unchanged, although the polishing fit
is significantly faster (more than 2x) in this case:

\begin{Verbatim}[commandchars=\\\{\}]
Values:
              metas: 0.41620(11)
                mDs: 1.20154(15)
           mDso\PYGZhy{}mDs: 0.2557(29)
                Vnn: 0.76718(60)
                Vno: \PYGZhy{}0.746(15)
\end{Verbatim}

\item {} 
Marginalization (see {\hyperref[corrfitter:marginalized-fits]{\emph{Faster Fits --- Marginalization}}}) can speed up fits like
this one. To use an 8-term fit function, while tuning parameters for only
\code{N} terms, we change only four lines in the main program:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{main}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{data} \PYG{o}{=} \PYG{n}{make\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{example.data}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{models} \PYG{o}{=} \PYG{n}{make\PYGZus{}models}\PYG{p}{(}\PYG{p}{)}
    \PYG{n}{fitter} \PYG{o}{=} \PYG{n}{CorrFitter}\PYG{p}{(}\PYG{n}{models}\PYG{o}{=}\PYG{n}{make\PYGZus{}models}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{ratio}\PYG{o}{=}\PYG{n+nb+bp}{False}\PYG{p}{)}                  \PYG{c}{\PYGZsh{}1}
    \PYG{n}{p0} \PYG{o}{=} \PYG{n+nb+bp}{None}
    \PYG{k}{for} \PYG{n}{N} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{:}                                                        \PYG{c}{\PYGZsh{}2}
        \PYG{k}{print}\PYG{p}{(}\PYG{l+m+mi}{30} \PYG{o}{*} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{=}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{nterm =}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{N}\PYG{p}{)}
        \PYG{n}{prior} \PYG{o}{=} \PYG{n}{make\PYGZus{}prior}\PYG{p}{(}\PYG{l+m+mi}{8}\PYG{p}{)}                                               \PYG{c}{\PYGZsh{}3}
        \PYG{n}{fit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{,} \PYG{n}{p0}\PYG{o}{=}\PYG{n}{p0}\PYG{p}{,} \PYG{n}{nterm}\PYG{o}{=}\PYG{p}{(}\PYG{n}{N}\PYG{p}{,} \PYG{n}{N}\PYG{p}{)}\PYG{p}{)}    \PYG{c}{\PYGZsh{}4}
        \PYG{n}{p0} \PYG{o}{=} \PYG{n}{fit}\PYG{o}{.}\PYG{n}{pmean}
    \PYG{n}{print\PYGZus{}results}\PYG{p}{(}\PYG{n}{fit}\PYG{p}{,} \PYG{n}{prior}\PYG{p}{,} \PYG{n}{data}\PYG{p}{)}
    \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{display\PYGZus{}plots}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

The first modification (\code{\#1}) is in the definition of \code{fitter}, where we add
an extra argument to tell {\hyperref[corrfitter:corrfitter.CorrFitter]{\code{corrfitter.CorrFitter}}} what kind of marginalization
to use (that is, not the ratio method). The second modification (\code{\#2})
limits the
fits to \code{N=1,2}, because that is all that will be needed to get good
values for the leading term.
The third modification (\code{\#3}) sets the prior to eight terms, no matter what value
\code{N} has. The last (\code{\#4}) tells \code{fitter.lsqfit} to fit parameters from
only the first \code{N} terms in the fit function; parts of the prior that are
not being fit are incorporated (\emph{marginalized}) into the fit data. The output
shows that
results for the leading term have converged by \code{N=2} (and even \code{N=1} isn't
so bad):

\begin{Verbatim}[commandchars=\\\{\}]
============================== nterm = 1
Least Square Fit:
  chi2/dof [dof] = 0.98 [69]    Q = 0.53    logGBF = 1586.4

Parameters:
  log(etas:a) 0   \PYGZhy{}1.52151 (78)      [ \PYGZhy{}1.2 (1.0) ]  
 log(etas:dE) 0   \PYGZhy{}0.87662 (29)      [ \PYGZhy{}0.92 (50) ]  
    log(Ds:a) 0    \PYGZhy{}1.5387 (10)      [ \PYGZhy{}1.2 (1.0) ]  
   log(Ds:dE) 0    0.18372 (14)      [  0.18 (17) ]  
   log(Ds:ao) 0     \PYGZhy{}2.628 (25)      [ \PYGZhy{}2.3 (1.0) ]  
  log(Ds:dEo) 0     0.3738 (32)      [  0.41 (24) ]  
        Vnn 0,0    0.76533 (60)      [  0.0 (1.0) ]  
        Vno 0,0     \PYGZhy{}0.710 (11)      [  0.0 (1.0) ]  

Settings:
  svdcut/n = 1e\PYGZhy{}15/0    reltol/abstol = 1e\PYGZhy{}10/1e\PYGZhy{}10    (itns/time = 10/0.1)

============================== nterm = 2
Least Square Fit:
  chi2/dof [dof] = 0.71 [69]    Q = 0.97    logGBF = 1602.3

Parameters:
  log(etas:a) 0   \PYGZhy{}1.52169 (72)      [ \PYGZhy{}1.2 (1.0) ]  
              1      \PYGZhy{}1.81 (52)      [ \PYGZhy{}1.2 (1.0) ]  
 log(etas:dE) 0   \PYGZhy{}0.87660 (28)      [ \PYGZhy{}0.92 (50) ]  
              1      \PYGZhy{}0.54 (17)      [ \PYGZhy{}0.7 (1.0) ]  
    log(Ds:a) 0   \PYGZhy{}1.53882 (88)      [ \PYGZhy{}1.2 (1.0) ]  
              1     \PYGZhy{}1.339 (75)      [ \PYGZhy{}1.2 (1.0) ]  
   log(Ds:dE) 0    0.18370 (13)      [  0.18 (17) ]  
              1     \PYGZhy{}0.711 (34)      [ \PYGZhy{}0.7 (1.0) ]  
   log(Ds:ao) 0     \PYGZhy{}2.746 (92)      [ \PYGZhy{}2.3 (1.0) ]  
              1      \PYGZhy{}2.44 (10)      [ \PYGZhy{}2.3 (1.0) ]  
  log(Ds:dEo) 0     0.3661 (74)      [  0.41 (24) ]  
              1      \PYGZhy{}1.45 (24)      [ \PYGZhy{}0.7 (1.0) ]  
        Vnn 0,0    0.76759 (74)      [  0.0 (1.0) ]  
            0,1     \PYGZhy{}0.488 (35)      [  0.0 (1.0) ]  
            1,0      0.039 (51)      [  0.0 (1.0) ]  
            1,1       0.63 (74)      [  0.0 (1.0) ]  
        Vno 0,0     \PYGZhy{}0.774 (42)      [  0.0 (1.0) ]  
            0,1       0.25 (16)      [  0.0 (1.0) ]  
            1,0       0.34 (43)      [  0.0 (1.0) ]  
            1,1       0.29 (95)      [  0.0 (1.0) ]  

Settings:
  svdcut/n = 1e\PYGZhy{}15/0    reltol/abstol = 1e\PYGZhy{}10/1e\PYGZhy{}10    (itns/time = 17/0.2)

Fit results:
  Eetas: [0.41619(12) 1.00(10)]
  aetas: [0.21834(16) 0.164(85)]

  EDs: [1.20165(15) 1.693(17)]
  aDs: [0.21463(19) 0.262(20)]

  EDso: [1.442(11) 1.676(61)]
  aDso: [0.0642(59) 0.0872(90)]

  etas\PYGZhy{}\PYGZgt{}V\PYGZhy{}\PYGZgt{}Ds  = 0.76759(74)
  etas\PYGZhy{}\PYGZgt{}V\PYGZhy{}\PYGZgt{}Dso = \PYGZhy{}0.774(42)

Values:
              metas: 0.41619(12)         
                mDs: 1.20165(15)         
           mDso\PYGZhy{}mDs: 0.241(11)           
                Vnn: 0.76759(74)         
                Vno: \PYGZhy{}0.774(42)          

Partial \PYGZpc{} Errors:
                         metas       mDs  mDso\PYGZhy{}mDs       Vnn       Vno
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
         statistics:      0.03      0.01      3.69      0.09      4.53
        log(etas:a):      0.00      0.00      0.10      0.01      0.54
       log(etas:dE):      0.00      0.00      0.06      0.00      0.42
          log(Ds:a):      0.00      0.00      0.34      0.01      0.47
         log(Ds:dE):      0.00      0.00      0.52      0.02      0.47
         log(Ds:ao):      0.00      0.00      0.40      0.00      1.37
        log(Ds:dEo):      0.00      0.00      0.54      0.00      1.94
                Vnn:      0.00      0.00      1.03      0.03      0.25
                Vno:      0.00      0.00      2.10      0.02      1.28
                svd:      0.00      0.00      0.00      0.00      0.00
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
              total:      0.03      0.01      4.47      0.10      5.37
\end{Verbatim}

\item {} 
Test the code by adding \code{test\_fit(fitter, 'example.data')} to the \code{main}
program, where:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{test\PYGZus{}fit}\PYG{p}{(}\PYG{n}{fitter}\PYG{p}{,} \PYG{n}{datafile}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{gv}\PYG{o}{.}\PYG{n}{ranseed}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{5339893179535759510}\PYG{p}{,} \PYG{l+m+mi}{4088224360017966188}\PYG{p}{,} \PYG{l+m+mi}{7597275990505476522}\PYG{p}{)}\PYG{p}{)}
    \PYG{k}{print}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s}{Random seed:}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{ranseed}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{)}
    \PYG{n}{dataset} \PYG{o}{=} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{Dataset}\PYG{p}{(}\PYG{n}{datafile}\PYG{p}{)}
    \PYG{n}{pexact} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{fit}\PYG{o}{.}\PYG{n}{pmean}
    \PYG{n}{prior} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{fit}\PYG{o}{.}\PYG{n}{prior}
    \PYG{k}{for} \PYG{n}{sdata} \PYG{o+ow}{in} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{simulated\PYGZus{}data\PYGZus{}iter}\PYG{p}{(}\PYG{n}{n}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{dataset}\PYG{o}{=}\PYG{n}{dataset}\PYG{p}{,} \PYG{n}{pexact}\PYG{o}{=}\PYG{n}{pexact}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{print}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s}{============================== simulation}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
        \PYG{n}{sfit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{sdata}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{,} \PYG{n}{p0}\PYG{o}{=}\PYG{n}{pexact}\PYG{p}{)}
        \PYG{n}{diff} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
        \PYG{c}{\PYGZsh{} check chi**2 for leading parameters}
        \PYG{k}{for} \PYG{n}{k} \PYG{o+ow}{in} \PYG{n}{sfit}\PYG{o}{.}\PYG{n}{p}\PYG{p}{:}
            \PYG{n}{diff}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{sfit}\PYG{o}{.}\PYG{n}{p}\PYG{p}{[}\PYG{n}{k}\PYG{p}{]}\PYG{o}{.}\PYG{n}{flat}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{\PYGZhy{}} \PYG{n}{pexact}\PYG{p}{[}\PYG{n}{k}\PYG{p}{]}\PYG{o}{.}\PYG{n}{flat}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}
        \PYG{k}{print}\PYG{p}{(}
            \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Leading parameter chi2/dof [dof] = }\PYG{l+s+si}{\PYGZpc{}.2f}\PYG{l+s}{\PYGZsq{}} \PYG{o}{\PYGZpc{}}
            \PYG{p}{(}\PYG{n}{gv}\PYG{o}{.}\PYG{n}{chi2}\PYG{p}{(}\PYG{n}{diff}\PYG{p}{)} \PYG{o}{/} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{chi2}\PYG{o}{.}\PYG{n}{dof}\PYG{p}{)}\PYG{p}{,}
            \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{[}\PYG{l+s+si}{\PYGZpc{}d}\PYG{l+s}{]}\PYG{l+s}{\PYGZsq{}} \PYG{o}{\PYGZpc{}} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{chi2}\PYG{o}{.}\PYG{n}{dof}\PYG{p}{,}
            \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{  Q = }\PYG{l+s+si}{\PYGZpc{}.1f}\PYG{l+s}{\PYGZsq{}} \PYG{o}{\PYGZpc{}} \PYG{n}{gv}\PYG{o}{.}\PYG{n}{chi2}\PYG{o}{.}\PYG{n}{Q}
            \PYG{p}{)}
\end{Verbatim}

This code does \code{n=2} simulations of the full fit, using the means of fit
results from the last fit done by \code{fitter} as \code{pexact}.
The code prints out each fit,
and for each it computes the \code{chi**2} of the difference between the leading
parameters and \code{pexact}. The output is:

\begin{Verbatim}[commandchars=\\\{\}]
Random seed: (5339893179535759510, 4088224360017966188, 7597275990505476522)

============================== simulation
Least Square Fit:
  chi2/dof [dof] = 0.68 [69]    Q = 0.98    logGBF = 1602.5

Parameters:
  log(etas:a) 0      \PYGZhy{}1.52103 (72)        [ \PYGZhy{}1.2 (1.0) ]  
              1         \PYGZhy{}1.76 (32)        [ \PYGZhy{}1.2 (1.0) ]  
              2         \PYGZhy{}1.13 (48)        [ \PYGZhy{}1.2 (1.0) ]  
              3         \PYGZhy{}1.22 (95)        [ \PYGZhy{}1.2 (1.0) ]  
 log(etas:dE) 0      \PYGZhy{}0.87635 (28)        [ \PYGZhy{}0.92 (50) ]  
              1         \PYGZhy{}0.54 (12)        [ \PYGZhy{}0.7 (1.0) ]  
              2         \PYGZhy{}0.72 (53)        [ \PYGZhy{}0.7 (1.0) ]  
              3         \PYGZhy{}0.70 (97)        [ \PYGZhy{}0.7 (1.0) ]  
    log(Ds:a) 0      \PYGZhy{}1.53847 (93)        [ \PYGZhy{}1.2 (1.0) ]  
              1         \PYGZhy{}1.32 (10)        [ \PYGZhy{}1.2 (1.0) ]  
              2         \PYGZhy{}0.83 (38)        [ \PYGZhy{}1.2 (1.0) ]  
              3         \PYGZhy{}1.13 (98)        [ \PYGZhy{}1.2 (1.0) ]  
   log(Ds:dE) 0       0.18379 (13)        [  0.18 (17) ]  
              1        \PYGZhy{}0.701 (45)        [ \PYGZhy{}0.7 (1.0) ]  
              2         \PYGZhy{}0.69 (39)        [ \PYGZhy{}0.7 (1.0) ]  
              3         \PYGZhy{}0.75 (99)        [ \PYGZhy{}0.7 (1.0) ]  
   log(Ds:ao) 0        \PYGZhy{}2.709 (97)        [ \PYGZhy{}2.3 (1.0) ]  
              1         \PYGZhy{}2.46 (38)        [ \PYGZhy{}2.3 (1.0) ]  
              2         \PYGZhy{}2.16 (82)        [ \PYGZhy{}2.3 (1.0) ]  
              3         \PYGZhy{}2.3 (1.0)        [ \PYGZhy{}2.3 (1.0) ]  
  log(Ds:dEo) 0        0.3691 (82)        [  0.41 (24) ]  
              1         \PYGZhy{}1.40 (48)        [ \PYGZhy{}0.7 (1.0) ]  
              2         \PYGZhy{}0.69 (80)        [ \PYGZhy{}0.7 (1.0) ]  
              3         \PYGZhy{}0.7 (1.0)        [ \PYGZhy{}0.7 (1.0) ]  
        Vnn 0,0       0.76731 (83)        [  0.0 (1.0) ]  
            0,1        \PYGZhy{}0.487 (38)        [  0.0 (1.0) ]  
            0,2          0.32 (43)        [  0.0 (1.0) ]  
            0,3          0.07 (99)        [  0.0 (1.0) ]  
            1,0         0.077 (41)        [  0.0 (1.0) ]  
            1,1          0.60 (70)        [  0.0 (1.0) ]  
            1,2          0.12 (99)        [  0.0 (1.0) ]  
            1,3        0.01 (1.00)        [  0.0 (1.0) ]  
            2,0         \PYGZhy{}0.24 (30)        [  0.0 (1.0) ]  
            2,1        0.05 (1.00)        [  0.0 (1.0) ]  
            2,2      0.002 (1.000)        [  0.0 (1.0) ]  
            2,3    0.0002 (1.0000)        [  0.0 (1.0) ]  
            3,0         \PYGZhy{}0.13 (98)        [  0.0 (1.0) ]  
            3,1      0.003 (1.000)        [  0.0 (1.0) ]  
            3,2   5.99212e\PYGZhy{}05 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            3,3   9.39906e\PYGZhy{}07 +\PYGZhy{} 1        [  0.0 (1.0) ]  
        Vno 0,0        \PYGZhy{}0.766 (61)        [  0.0 (1.0) ]  
            0,1          0.29 (28)        [  0.0 (1.0) ]  
            0,2          0.11 (89)        [  0.0 (1.0) ]  
            0,3        0.02 (1.00)        [  0.0 (1.0) ]  
            1,0          0.08 (40)        [  0.0 (1.0) ]  
            1,1          0.21 (96)        [  0.0 (1.0) ]  
            1,2        0.03 (1.00)        [  0.0 (1.0) ]  
            1,3      0.003 (1.000)        [  0.0 (1.0) ]  
            2,0         \PYGZhy{}0.07 (94)        [  0.0 (1.0) ]  
            2,1      0.002 (1.000)        [  0.0 (1.0) ]  
            2,2    0.0005 (1.0000)        [  0.0 (1.0) ]  
            2,3   5.78915e\PYGZhy{}05 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            3,0       \PYGZhy{}0.01 (1.00)        [  0.0 (1.0) ]  
            3,1   \PYGZhy{}0.0004 (1.0000)        [  0.0 (1.0) ]  
            3,2   7.74325e\PYGZhy{}06 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            3,3   3.34355e\PYGZhy{}07 +\PYGZhy{} 1        [  0.0 (1.0) ]  

Settings:
  svdcut/n = 1e\PYGZhy{}15/0    reltol/abstol = 1e\PYGZhy{}10/1e\PYGZhy{}10    (itns/time = 25/0.5)

Leading parameter chi2/dof [dof] = 0.27 [8]   Q = 1.0

============================== simulation
Least Square Fit:
  chi2/dof [dof] = 0.63 [69]    Q = 0.99    logGBF = 1604.2

Parameters:
  log(etas:a) 0       \PYGZhy{}1.52248 (71)        [ \PYGZhy{}1.2 (1.0) ]  
              1          \PYGZhy{}1.60 (18)        [ \PYGZhy{}1.2 (1.0) ]  
              2          \PYGZhy{}1.03 (69)        [ \PYGZhy{}1.2 (1.0) ]  
              3          \PYGZhy{}1.05 (97)        [ \PYGZhy{}1.2 (1.0) ]  
 log(etas:dE) 0       \PYGZhy{}0.87681 (28)        [ \PYGZhy{}0.92 (50) ]  
              1         \PYGZhy{}0.474 (72)        [ \PYGZhy{}0.7 (1.0) ]  
              2          \PYGZhy{}0.48 (59)        [ \PYGZhy{}0.7 (1.0) ]  
              3          \PYGZhy{}0.78 (98)        [ \PYGZhy{}0.7 (1.0) ]  
    log(Ds:a) 0       \PYGZhy{}1.53993 (98)        [ \PYGZhy{}1.2 (1.0) ]  
              1          \PYGZhy{}1.45 (15)        [ \PYGZhy{}1.2 (1.0) ]  
              2          \PYGZhy{}0.81 (28)        [ \PYGZhy{}1.2 (1.0) ]  
              3          \PYGZhy{}1.18 (98)        [ \PYGZhy{}1.2 (1.0) ]  
   log(Ds:dE) 0        0.18356 (13)        [  0.18 (17) ]  
              1         \PYGZhy{}0.769 (64)        [ \PYGZhy{}0.7 (1.0) ]  
              2          \PYGZhy{}0.78 (30)        [ \PYGZhy{}0.7 (1.0) ]  
              3          \PYGZhy{}0.74 (99)        [ \PYGZhy{}0.7 (1.0) ]  
   log(Ds:ao) 0         \PYGZhy{}2.709 (76)        [ \PYGZhy{}2.3 (1.0) ]  
              1          \PYGZhy{}2.38 (16)        [ \PYGZhy{}2.3 (1.0) ]  
              2          \PYGZhy{}2.46 (98)        [ \PYGZhy{}2.3 (1.0) ]  
              3          \PYGZhy{}2.3 (1.0)        [ \PYGZhy{}2.3 (1.0) ]  
  log(Ds:dEo) 0         0.3681 (66)        [  0.41 (24) ]  
              1          \PYGZhy{}1.33 (25)        [ \PYGZhy{}0.7 (1.0) ]  
              2          \PYGZhy{}0.43 (94)        [ \PYGZhy{}0.7 (1.0) ]  
              3          \PYGZhy{}0.7 (1.0)        [ \PYGZhy{}0.7 (1.0) ]  
        Vnn 0,0        0.76785 (82)        [  0.0 (1.0) ]  
            0,1         \PYGZhy{}0.443 (44)        [  0.0 (1.0) ]  
            0,2           0.02 (26)        [  0.0 (1.0) ]  
            0,3          \PYGZhy{}0.02 (99)        [  0.0 (1.0) ]  
            1,0          0.047 (32)        [  0.0 (1.0) ]  
            1,1           0.23 (70)        [  0.0 (1.0) ]  
            1,2           0.09 (99)        [  0.0 (1.0) ]  
            1,3       0.006 (1.000)        [  0.0 (1.0) ]  
            2,0          \PYGZhy{}0.21 (36)        [  0.0 (1.0) ]  
            2,1        \PYGZhy{}0.01 (1.00)        [  0.0 (1.0) ]  
            2,2   \PYGZhy{}6.34043e\PYGZhy{}05 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            2,3    3.02345e\PYGZhy{}05 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            3,0          \PYGZhy{}0.04 (99)        [  0.0 (1.0) ]  
            3,1      \PYGZhy{}0.001 (1.000)        [  0.0 (1.0) ]  
            3,2   \PYGZhy{}3.89259e\PYGZhy{}05 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            3,3   \PYGZhy{}3.02296e\PYGZhy{}08 +\PYGZhy{} 1        [  0.0 (1.0) ]  
        Vno 0,0         \PYGZhy{}0.760 (37)        [  0.0 (1.0) ]  
            0,1           0.31 (17)        [  0.0 (1.0) ]  
            0,2         0.008 (981)        [  0.0 (1.0) ]  
            0,3      \PYGZhy{}0.001 (1.000)        [  0.0 (1.0) ]  
            1,0           0.15 (38)        [  0.0 (1.0) ]  
            1,1          \PYGZhy{}0.18 (96)        [  0.0 (1.0) ]  
            1,2      \PYGZhy{}0.003 (1.000)        [  0.0 (1.0) ]  
            1,3   \PYGZhy{}2.38349e\PYGZhy{}07 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            2,0           0.14 (98)        [  0.0 (1.0) ]  
            2,1         0.01 (1.00)        [  0.0 (1.0) ]  
            2,2   \PYGZhy{}3.75964e\PYGZhy{}05 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            2,3   \PYGZhy{}1.75035e\PYGZhy{}06 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            3,0         0.02 (1.00)        [  0.0 (1.0) ]  
            3,1       0.001 (1.000)        [  0.0 (1.0) ]  
            3,2    7.12009e\PYGZhy{}07 +\PYGZhy{} 1        [  0.0 (1.0) ]  
            3,3   \PYGZhy{}3.92305e\PYGZhy{}08 +\PYGZhy{} 1        [  0.0 (1.0) ]  

Settings:
  svdcut/n = 1e\PYGZhy{}15/0    reltol/abstol = 1e\PYGZhy{}10/1e\PYGZhy{}10    (itns/time = 43/0.7)

Leading parameter chi2/dof [dof] = 0.46 [8]   Q = 0.9
\end{Verbatim}

This shows that the fit is working well, at least for the leading
parameter for each key.

Other options are easily checked. For example,
only one line need be changed in \code{test\_fit} in order to test
a marginalized fit:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{sfit} \PYG{o}{=} \PYG{n}{fitter}\PYG{o}{.}\PYG{n}{lsqfit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n}{sdata}\PYG{p}{,} \PYG{n}{prior}\PYG{o}{=}\PYG{n}{prior}\PYG{p}{,} \PYG{n}{p0}\PYG{o}{=}\PYG{n}{pexact}\PYG{p}{,} \PYG{n}{nterm}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

Running this code gives:

\begin{Verbatim}[commandchars=\\\{\}]
Random seed: (5339893179535759510, 4088224360017966188, 7597275990505476522)

============================== simulation
Least Square Fit:
  chi2/dof [dof] = 0.7 [69]    Q = 0.97    logGBF = 1602.4

Parameters:
  log(etas:a) 0   \PYGZhy{}1.52098 (72)      [ \PYGZhy{}1.2 (1.0) ]  
              1      \PYGZhy{}1.71 (49)      [ \PYGZhy{}1.2 (1.0) ]  
 log(etas:dE) 0   \PYGZhy{}0.87634 (28)      [ \PYGZhy{}0.92 (50) ]  
              1      \PYGZhy{}0.52 (16)      [ \PYGZhy{}0.7 (1.0) ]  
    log(Ds:a) 0   \PYGZhy{}1.53883 (91)      [ \PYGZhy{}1.2 (1.0) ]  
              1     \PYGZhy{}1.390 (78)      [ \PYGZhy{}1.2 (1.0) ]  
   log(Ds:dE) 0    0.18377 (13)      [  0.18 (17) ]  
              1     \PYGZhy{}0.735 (37)      [ \PYGZhy{}0.7 (1.0) ]  
   log(Ds:ao) 0     \PYGZhy{}2.670 (58)      [ \PYGZhy{}2.3 (1.0) ]  
              1      \PYGZhy{}2.34 (14)      [ \PYGZhy{}2.3 (1.0) ]  
  log(Ds:dEo) 0     0.3719 (55)      [  0.41 (24) ]  
              1      \PYGZhy{}1.20 (21)      [ \PYGZhy{}0.7 (1.0) ]  
        Vnn 0,0    0.76751 (76)      [  0.0 (1.0) ]  
            0,1     \PYGZhy{}0.459 (35)      [  0.0 (1.0) ]  
            1,0      0.080 (53)      [  0.0 (1.0) ]  
            1,1       0.72 (73)      [  0.0 (1.0) ]  
        Vno 0,0     \PYGZhy{}0.755 (29)      [  0.0 (1.0) ]  
            0,1       0.37 (16)      [  0.0 (1.0) ]  
            1,0      \PYGZhy{}0.07 (40)      [  0.0 (1.0) ]  
            1,1       0.27 (96)      [  0.0 (1.0) ]  

Settings:
  svdcut/n = 1e\PYGZhy{}15/0    reltol/abstol = 1e\PYGZhy{}10/1e\PYGZhy{}10    (itns/time = 22/0.2)

Leading parameter chi2/dof [dof] = 0.82 [8]   Q = 0.6

============================== simulation
Least Square Fit:
  chi2/dof [dof] = 0.63 [69]    Q = 0.99    logGBF = 1604.6

Parameters:
  log(etas:a) 0   \PYGZhy{}1.52243 (70)      [ \PYGZhy{}1.2 (1.0) ]  
              1      \PYGZhy{}1.34 (50)      [ \PYGZhy{}1.2 (1.0) ]  
 log(etas:dE) 0   \PYGZhy{}0.87680 (27)      [ \PYGZhy{}0.92 (50) ]  
              1      \PYGZhy{}0.41 (13)      [ \PYGZhy{}0.7 (1.0) ]  
    log(Ds:a) 0   \PYGZhy{}1.53999 (93)      [ \PYGZhy{}1.2 (1.0) ]  
              1     \PYGZhy{}1.455 (75)      [ \PYGZhy{}1.2 (1.0) ]  
   log(Ds:dE) 0    0.18355 (13)      [  0.18 (17) ]  
              1     \PYGZhy{}0.771 (38)      [ \PYGZhy{}0.7 (1.0) ]  
   log(Ds:ao) 0     \PYGZhy{}2.700 (72)      [ \PYGZhy{}2.3 (1.0) ]  
              1      \PYGZhy{}2.39 (12)      [ \PYGZhy{}2.3 (1.0) ]  
  log(Ds:dEo) 0     0.3688 (64)      [  0.41 (24) ]  
              1      \PYGZhy{}1.32 (22)      [ \PYGZhy{}0.7 (1.0) ]  
        Vnn 0,0    0.76780 (76)      [  0.0 (1.0) ]  
            0,1     \PYGZhy{}0.437 (33)      [  0.0 (1.0) ]  
            1,0      0.065 (62)      [  0.0 (1.0) ]  
            1,1       0.15 (77)      [  0.0 (1.0) ]  
        Vno 0,0     \PYGZhy{}0.761 (34)      [  0.0 (1.0) ]  
            0,1       0.33 (17)      [  0.0 (1.0) ]  
            1,0       0.07 (40)      [  0.0 (1.0) ]  
            1,1      \PYGZhy{}0.14 (97)      [  0.0 (1.0) ]  

Settings:
  svdcut/n = 1e\PYGZhy{}15/0    reltol/abstol = 1e\PYGZhy{}10/1e\PYGZhy{}10    (itns/time = 11/0.2)

Leading parameter chi2/dof [dof] = 0.56 [8]   Q = 0.8
\end{Verbatim}

This is also fine and confirms that \code{nterm=(2,2)} marginalized fits
are a useful, faster substitute for full fits. Indeed the simulation
suggests that the marginalized fit is somewhat more accurate
than the original fit for the oscillating-state parameters (\code{Vno},
\code{log(Ds:ao)}, \code{log(Ds:dEo)} --- compare the simulated results with
the \code{nterm=4} results from the original fit, as these were used to
define \code{pexact}).

\end{itemize}


\chapter{Indices and tables}
\label{index:indices-and-tables}\begin{itemize}
\item {} 
\emph{genindex}

\item {} 
\emph{modindex}

\item {} 
\emph{search}

\end{itemize}



\renewcommand{\indexname}{Index}
\printindex
\end{document}

#This is a sample configuration file, lines starting with '#' are comments. Lines not starting with a '#' are structured like so -> parameter = value, you will need to alter the values to match your needs. Please see the 'Hdfs_load Documentation.docx' file for more information

[RemotePaths]
#The server to connect to
server= pl1rhd402.internal.edmunds.com
username=sshuster
password=

#Do not change ANY of the following
base_remote=/misc/%(username)s
config_path = %(base_remote)s/tmp_config
preprocessed_path = %(base_remote)s/tmp_hive_creation
processed_path = %(base_remote)s/tmp_hive_creation_processed
sql_path = %(base_remote)s/tmp_hive_creation_sql


[HDFSLocation]
#This is the folder on HDFS where your hive tables will reside. NOTE you will need to contact the DWH team to have a folder created for your team as otherwise you will not have permission to write to a folder
hdfs_base_folder= /modeled-data

#WILL NEED TO EDIT THE FOLLOWING
[Hive]
#The Delimiter of your csv files
delimiter = ^

#The string denoting missing values (will be replaced with "")
missing_value = NA

#The prefix to go in front of your tables
table_prefix = m_

#Drop all tables and partitions, only change to True if table changes such that it is backwards incompatible.
drop_table = false
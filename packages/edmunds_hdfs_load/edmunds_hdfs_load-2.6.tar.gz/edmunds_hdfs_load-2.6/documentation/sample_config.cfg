#This is a sample configuration file, lines starting with '#' are comments. Lines not starting with a '#' are structured like so -> parameter = value, you will need to alter the values to match your needs. Please see the 'Hdfs_load Documentation.docx' file for more information

[LocalPaths]
#This is the parent directory containing all of your .csv files on your local machine, for windows much be C: drive but leave out C: in front of the path
local_dir: /Users/sshuster/Documents/Common_Data_Platform_Challenge_Team/transaction_temp

[RemotePaths]
#The server to connect to
server: pl1rhd402.internal.edmunds.com
username=sshuster
password=

#Do not change
base_remote=/misc/%(username)s

[HDFSLocation]
#This is the folder on HDFS where your hive tables will reside. NOTE you will need to contact the DWH team to have a folder created for your team as otherwise you will not have permission to write to a folder
hdfs_base_folder: /modeled-data

[Hive]
#Set equal to True if you want to create the hive tables, otherwise False
create_tables: True

#Set equal to True if you want to overwrite existing tables, otherwise False (ONLY SET TO TRUE IF YOU WANT TO DELETE ALL EXISTING DATA!!)
overwrite_existing_hive: False

#The Delimiter of your csv files
delimiter = ^

#The string denoting missing values (will be replaced with "")
missing_value = NA

#The prefix to go in front of your tables
table_prefix = m_
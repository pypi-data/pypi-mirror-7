<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Installation &mdash; Pydoop 0.12.0 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.12.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Pydoop 0.12.0 documentation" href="index.html" />
    <link rel="next" title="Pydoop Script User Guide" href="pydoop_script.html" />
    <link rel="prev" title="Writing Full-Featured Applications" href="tutorial/mapred_api.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pydoop_script.html" title="Pydoop Script User Guide"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tutorial/mapred_api.html" title="Writing Full-Featured Applications"
             accesskey="P">previous</a> |</li>
	<li><a href="index.html">Home</a>|&nbsp;</li>
	<li><a href="#">Download & Install</a>|&nbsp;</li>
	<li><a href="https://sourceforge.net/projects/pydoop/forums/forum/990018">Support</a>|&nbsp;</li>
	<li><a href="http://sourceforge.net/projects/pydoop/">Pydoop on SF</a></li>
 
      </ul>
    </div>

      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.png" alt="Logo"/>
            </a></p>
            <h3><a href="index.html">Table Of Contents</a></h3>
            <ul>
<li><a class="reference internal" href="#">Installation</a><ul>
<li><a class="reference internal" href="#supported-platforms">Supported Platforms</a></li>
<li><a class="reference internal" href="#get-pydoop">Get Pydoop</a><ul>
<li><a class="reference internal" href="#source-distribution">Source Distribution</a></li>
<li><a class="reference internal" href="#debian-ubuntu-package">Debian/Ubuntu Package</a></li>
</ul>
</li>
<li><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li><a class="reference internal" href="#id4">Installation</a><ul>
<li><a class="reference internal" href="#id5">Ubuntu</a></li>
<li><a class="reference internal" href="#installation-from-source">Installation from Source</a></li>
</ul>
</li>
<li><a class="reference internal" href="#installation-on-apple-os-x-mountain-lion">Installation on Apple OS X Mountain Lion</a></li>
<li><a class="reference internal" href="#multiple-hadoop-versions">Multiple Hadoop Versions</a></li>
<li><a class="reference internal" href="#troubleshooting">Troubleshooting</a></li>
<li><a class="reference internal" href="#testing-your-installation">Testing your Installation</a><ul>
<li><a class="reference internal" href="#superuser-privileges">Superuser Privileges</a></li>
<li><a class="reference internal" href="#hadoop-2-2-0">Hadoop 2.2.0</a></li>
<li><a class="reference internal" href="#using-pydoop-with-yarn">Using Pydoop with YARN</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            <h4>Previous topic</h4>
            <p class="topless"><a href="tutorial/mapred_api.html"
                                  title="previous chapter">Writing Full-Featured Applications</a></p>
            <h4>Next topic</h4>
            <p class="topless"><a href="pydoop_script.html"
                                  title="next chapter">Pydoop Script User Guide</a></p>

					<h4>Get Pydoop</h4>
					<ul>
						<li> <a href="http://sourceforge.net/projects/pydoop/files/">Download page</a> </li>
						<li> <a href="#"> Installation Instructions </a> </li>
					</ul>

					<h4>Contributors</h4>
					<p class="topless">
					Pydoop is developed by:
					<a href="http://www.crs4.it">
						<img src="_static/crs4.png" alt="CRS4" width="200" height="60" />
					</a>
					</p>

					And generously hosted by:
					<a href="http://sourceforge.net/projects/pydoop">
						<img src="http://sflogo.sourceforge.net/sflogo.php?group_id=536922&amp;type=13" width="120" height="30" 
						alt="Get Pydoop at SourceForge.net. Fast, secure and Free Open Source software downloads" />
					</a>
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms or a module, class or function name.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>


    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="installation">
<span id="id1"></span><h1>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h1>
<div class="section" id="supported-platforms">
<h2>Supported Platforms<a class="headerlink" href="#supported-platforms" title="Permalink to this headline">¶</a></h2>
<p>Pydoop has been tested on <a class="reference external" href="http://www.gentoo.org">Gentoo</a>, <a class="reference external" href="http://www.ubuntu.com">Ubuntu</a> and <a class="reference external" href="http://www.centos.org">CentOS</a>. Although we currently have no information
regarding other Linux distributions, we expect Pydoop to work
(possibly with some tweaking) on them as well.</p>
<p>We also have a <a class="reference internal" href="#osx"><em>walkthrough</em></a> for compiling and installing
on <a class="reference external" href="http://www.apple.com/osx">Apple OS X Mountain Lion</a>.</p>
<p>Other platforms are not supported.</p>
</div>
<div class="section" id="get-pydoop">
<span id="id2"></span><h2>Get Pydoop<a class="headerlink" href="#get-pydoop" title="Permalink to this headline">¶</a></h2>
<div class="section" id="source-distribution">
<h3>Source Distribution<a class="headerlink" href="#source-distribution" title="Permalink to this headline">¶</a></h3>
<p>We recommend downloading the latest release from
<a class="reference external" href="https://sourceforge.net/projects/pydoop/files">https://sourceforge.net/projects/pydoop/files</a>.</p>
<p>You can also get the latest code from the <a class="reference external" href="http://git-scm.com/">Git</a>
repository:</p>
<div class="highlight-python"><div class="highlight"><pre>git clone https://github.com/crs4/pydoop.git
</pre></div>
</div>
<p>We also upload our releases to <a class="reference external" href="http://pypi.python.org">PyPI</a>.
After configuring your environment (see below), you should be able to
automatically download and install Pydoop from PyPI using <a class="reference external" href="http://www.pip-installer.org">pip</a>:</p>
<div class="highlight-python"><div class="highlight"><pre>pip install pydoop
</pre></div>
</div>
</div>
<div class="section" id="debian-ubuntu-package">
<h3>Debian/Ubuntu Package<a class="headerlink" href="#debian-ubuntu-package" title="Permalink to this headline">¶</a></h3>
<p>Download the latest .deb package from
<a class="reference external" href="https://sourceforge.net/projects/pydoop/files">https://sourceforge.net/projects/pydoop/files</a>.</p>
</div>
</div>
<div class="section" id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h2>
<p>In order to build and install Pydoop, you need the following software:</p>
<ul class="simple">
<li><a class="reference external" href="http://www.python.org">Python</a> version 2.7 (or 2.6 with
backports <a class="footnote-reference" href="#id8" id="id3">[1]</a>)</li>
<li>either of the following:<ul>
<li><a class="reference external" href="http://hadoop.apache.org">Apache Hadoop</a> version 0.20.2, 1.0.4,
1.1.2, 1.2.1 or 2.2.0</li>
<li><a class="reference external" href="https://ccp.cloudera.com/display/SUPPORT/Downloads">CDH</a>
version 3u4, 3u5, 4.2.0 or 4.3.0, with the following limitations:<ul>
<li>currently, only mrv1 is supported</li>
<li>CDH4 must be installed from dist-specific packages (no tarball)</li>
</ul>
</li>
</ul>
</li>
<li><a class="reference external" href="http://www.boost.org">Boost</a> version 1.40 or later (only the Python
library)</li>
<li><a class="reference external" href="http://www.openssl.org">OpenSSL</a> (not required with Hadoop 0.20.2)</li>
</ul>
<p>These are also runtime requirements for all cluster nodes. Note that
installing Pydoop and your MapReduce application to all cluster nodes
(or to an NFS share) is <em>not</em> required: see <a class="reference internal" href="self_contained.html"><em>Installation-free Usage</em></a> for
a complete HowTo.</p>
<p>Other versions of Hadoop may or may not work depending on how
different they are from the ones listed above.</p>
</div>
<div class="section" id="id4">
<h2>Installation<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id5">
<h3>Ubuntu<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>On Ubuntu you should install the .deb package (see the <a class="reference internal" href="#get-pydoop"><em>Get
Pydoop</em></a> section) corresponding to the CDH version you are
running (if you are using Apache Hadoop, try <a class="reference internal" href="#from-source"><em>building Pydoop
from source</em></a> instead).  Our .deb packages have been
tested on 64-bit Ubuntu 12.04 LTS (Precise Pangolin) with the
following prerequisites installed:</p>
<ul class="simple">
<li>Python 2.7, with python-support</li>
<li>Boost.Python 1.46.1</li>
<li>CDH</li>
<li>Oracle JDK 6<ul>
<li>Follow <a class="reference external" href="http://superuser.com/questions/353983/how-do-i-install-the-sun-java-sdk-in-ubuntu-11-10-oneric-and-later-versions">these instructions</a>.
Another option is to create a local repository with <a class="reference external" href="https://github.com/flexiondotorg/oab-java6">oab</a>.</li>
</ul>
</li>
</ul>
<p>If the above prerequisites are satisfied, you should be able to
install Pydoop by doing:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo dpkg -i &lt;PATH_TO_PYDOOP_DEB_PKG&gt;
</pre></div>
</div>
<p>The following is a complete walkthrough for CDH4 that merges all of
the above instructions (tested on an empty box):</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="c"># install canonical dependencies</span>
sudo apt-get install libboost-python1.46.1 python-support
<span class="c"># remove openjdk if necessary</span>
sudo apt-get purge openjdk*
<span class="c"># add repositories for CDH4 and Oracle Java</span>
sudo sh -c <span class="s2">&quot;echo &#39;deb [arch=amd64] http://archive.cloudera.com/cdh4/ubuntu/precise/amd64/cdh precise-cdh4 contrib&#39; &gt; /etc/apt/sources.list.d/cloudera.list&quot;</span>
sudo sh -c <span class="s2">&quot;echo &#39;deb-src http://archive.cloudera.com/cdh4/ubuntu/precise/amd64/cdh precise-cdh4 contrib&#39; &gt;&gt; /etc/apt/sources.list.d/cloudera.list&quot;</span>
sudo apt-get install curl
curl -s http://archive.cloudera.com/cdh4/ubuntu/precise/amd64/cdh/archive.key | sudo apt-key add -
sudo apt-get install python-software-properties
sudo add-apt-repository ppa:eugenesan/java
sudo apt-get update
<span class="c"># install Oracle Java and CDH4 with mrv1</span>
sudo apt-get install oracle-java6-installer
<span class="nb">cd</span> /usr/lib/jvm <span class="o">&amp;&amp;</span> sudo ln -s java-6-oracle java-6-sun
sudo apt-get install hadoop-0.20-conf-pseudo hadoop-client
<span class="c"># install Pydoop</span>
sudo dpkg -i &lt;PATH_TO_PYDOOP_DEB_PKG&gt;
</pre></div>
</div>
</div>
<div class="section" id="installation-from-source">
<span id="from-source"></span><h3>Installation from Source<a class="headerlink" href="#installation-from-source" title="Permalink to this headline">¶</a></h3>
<p>Before compiling and installing Pydoop, install all missing dependencies.</p>
<p>On Ubuntu:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo apt-get install build-essential python-all-dev libboost-python-dev libssl-dev
</pre></div>
</div>
<p>On Gentoo:</p>
<div class="highlight-python"><div class="highlight"><pre>echo &#39;dev-libs/boost python&#39; &gt;&gt; /etc/portage/package.use
emerge boost openssl
</pre></div>
</div>
<p>If you&#8217;re using Boost version 1.48 or newer, you may need to specify the
name of your Boost.Python library in order to build Pydoop. This is
done via the <tt class="docutils literal"><span class="pre">BOOST_PYTHON</span></tt> environment variable. For instance:</p>
<div class="highlight-python"><div class="highlight"><pre>export BOOST_PYTHON=boost_python-2.7
</pre></div>
</div>
<p>Set the <tt class="docutils literal"><span class="pre">JAVA_HOME</span></tt> environment variable to your JDK installation
directory, e.g.:</p>
<div class="highlight-python"><div class="highlight"><pre>export JAVA_HOME=/usr/local/java/jdk
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If you don&#8217;t know where your Java home is, try finding the actual
path of the <tt class="docutils literal"><span class="pre">java</span></tt> executable and stripping the trailing
<tt class="docutils literal"><span class="pre">/jre/bin/java</span></tt>:</p>
<div class="last highlight-python"><div class="highlight"><pre>$ readlink -f $(which java)
/usr/lib/jvm/java-6-oracle/jre/bin/java
$ export JAVA_HOME=/usr/lib/jvm/java-6-oracle
</pre></div>
</div>
</div>
<p>If you have installed Hadoop from a tarball, set the <tt class="docutils literal"><span class="pre">HADOOP_HOME</span></tt>
environment variable so that it points to where the tarball was
extracted, e.g.:</p>
<div class="highlight-python"><div class="highlight"><pre>export HADOOP_HOME=/opt/hadoop-1.0.4
</pre></div>
</div>
<p>The above step is not necessary if you installed CDH from
dist-specific packages.  Build Pydoop with the following commands:</p>
<div class="highlight-python"><div class="highlight"><pre>tar xzf pydoop-*.tar.gz
cd pydoop-*
python setup.py build
</pre></div>
</div>
<p>For a system-wide installation, run the following:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo python setup.py install --skip-build
</pre></div>
</div>
<p>For a user-local installation:</p>
<div class="highlight-python"><div class="highlight"><pre>python setup.py install --skip-build --user
</pre></div>
</div>
<p>The latter installs Pydoop in <tt class="docutils literal"><span class="pre">~/.local/lib/python2.X/site-packages</span></tt>.
This may be a particularly handy solution if your home directory is
accessible on the entire cluster.</p>
<p>To install to an arbitrary path:</p>
<div class="highlight-python"><div class="highlight"><pre>python setup.py install --skip-build --home &lt;PATH&gt;
</pre></div>
</div>
</div>
</div>
<div class="section" id="installation-on-apple-os-x-mountain-lion">
<span id="osx"></span><h2>Installation on Apple OS X Mountain Lion<a class="headerlink" href="#installation-on-apple-os-x-mountain-lion" title="Permalink to this headline">¶</a></h2>
<p>To build Pydoop on OS X you need the following prerequisites:</p>
<ul class="simple">
<li><a class="reference external" href="http://www.oracle.com/technetwork/java/javase/overview/index.html">Oracle JDK</a>
(follow Downloads -&gt; JDK and select the .dmg package for OS X);</li>
<li>Command line tools for Xcode from the <a class="reference external" href="https://developer.apple.com/downloads">Apple Developer Tools</a>;</li>
<li><a class="reference external" href="http://mxcl.github.com/homebrew">Homebrew</a>.</li>
</ul>
<p>Install Boost:</p>
<div class="highlight-python"><div class="highlight"><pre>brew install boost --build-from-source
</pre></div>
</div>
<p>See <a class="reference external" href="https://github.com/mxcl/homebrew/wiki/Common-Issues">the common issues section of the Homebrew docs</a> for more info
on why we need the <tt class="docutils literal"><span class="pre">--build-from-source</span></tt> switch.</p>
<p>Install Hadoop:</p>
<div class="highlight-python"><div class="highlight"><pre>brew install hadoop
</pre></div>
</div>
<p>You may follow <a class="reference external" href="http://ragrawal.wordpress.com/2012/04/28/installing-hadoop-on-mac-osx-lion">this guide</a>
for Hadoop installation and configuration.</p>
<p>Set <tt class="docutils literal"><span class="pre">JAVA_HOME</span></tt> according to your JDK installation, e.g.:</p>
<div class="highlight-python"><div class="highlight"><pre>export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_17.jdk/Contents/Home
</pre></div>
</div>
<p>To install Pydoop via Homebrew:</p>
<div class="highlight-python"><div class="highlight"><pre>brew tap samueljohn/python
brew install pydoop
</pre></div>
</div>
<p>To compile and install from source, follow the instructions in the
previous section, configuring the environment as follows:</p>
<div class="highlight-python"><div class="highlight"><pre>export HADOOP_HOME=/usr/local/Cellar/hadoop/1.1.2/libexec
export BOOST_PYTHON=boost_python-mt
</pre></div>
</div>
</div>
<div class="section" id="multiple-hadoop-versions">
<span id="id6"></span><h2>Multiple Hadoop Versions<a class="headerlink" href="#multiple-hadoop-versions" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The following instructions apply to installations from
tarballs. Running a package-based Hadoop installation together with
a &#8220;from-tarball&#8221; one is neither advised not supported.</p>
</div>
<p>If you&#8217;d like to use your Pydoop installation with multiple versions of Hadoop,
you will need to rebuild the modules for each version of Hadoop.</p>
<p>After building Pydoop for the first time following the instructions above,
modify your HADOOP-related environment variables to point to the other version
of Hadoop to be supported.  Then repeat the build and installation commands
again.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre>tar xzf pydoop-*.tar.gz
cd pydoop-*

export HADOOP_HOME=/opt/hadoop-0.20.2
python setup.py install --user

python setup.py clean --all

export HADOOP_HOME=/opt/hadoop-1.0.4
python setup.py install --user
</pre></div>
</div>
<p>At run time, the appropriate version of the Pydoop modules will be
loaded for the version of Hadoop selected by your <tt class="docutils literal"><span class="pre">HADOOP_HOME</span></tt>
variable.  If Pydoop is not able to retrieve your Hadoop home
directory from the environment or by looking into standard paths, it
falls back to a default location that is hardwired at compile time:
the setup script looks for a file named <tt class="docutils literal"><span class="pre">DEFAULT_HADOOP_HOME</span></tt> in the
current working directory; if the file does not exist, it is created
and filled with the path to the current Hadoop home.</p>
</div>
<div class="section" id="troubleshooting">
<span id="id7"></span><h2>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first">&#8220;java home not found&#8221; error, with <tt class="docutils literal"><span class="pre">JAVA_HOME</span></tt> properly exported: try
setting <tt class="docutils literal"><span class="pre">JAVA_HOME</span></tt> in <tt class="docutils literal"><span class="pre">hadoop-env.sh</span></tt></p>
</li>
<li><p class="first">&#8220;libjvm.so not found&#8221; error: try the following:</p>
<div class="highlight-python"><div class="highlight"><pre>export LD_LIBRARY_PATH=&quot;${JAVA_HOME}/jre/lib/amd64/server:${LD_LIBRARY_PATH}&quot;
</pre></div>
</div>
</li>
<li><p class="first">non-standard include/lib directories: the setup script looks for
includes and libraries in standard places &#8211; read <tt class="docutils literal"><span class="pre">setup.py</span></tt> for
details. If some of the requirements are stored in different
locations, you need to add them to the search path. Example:</p>
<div class="highlight-python"><div class="highlight"><pre>python setup.py build_ext -L/my/lib/path -I/my/include/path -R/my/lib/path
python setup.py build
python setup.py install --skip-build
</pre></div>
</div>
<p>Alternatively, you can write a small <tt class="docutils literal"><span class="pre">setup.cfg</span></tt> file for distutils:</p>
<div class="highlight-cfg"><div class="highlight"><pre><span class="k">[build_ext]</span>
<span class="na">include_dirs</span><span class="o">=</span><span class="s">/my/include/path</span>
<span class="na">library_dirs</span><span class="o">=</span><span class="s">/my/lib/path</span>
<span class="na">rpath</span><span class="o">=</span><span class="s">%(library_dirs)s</span>
</pre></div>
</div>
<p>and then run <tt class="docutils literal"><span class="pre">python</span> <span class="pre">setup.py</span> <span class="pre">install</span></tt>.</p>
<p>Finally, you can achieve the same result by manipulating the
environment.  This is particularly useful in the case of automatic
download and install with pip:</p>
<div class="highlight-python"><div class="highlight"><pre>export CPATH=&quot;/my/include/path:${CPATH}&quot;
export LD_LIBRARY_PATH=&quot;/my/lib/path:${LD_LIBRARY_PATH}&quot;
pip install pydoop
</pre></div>
</div>
</li>
<li><p class="first">Hadoop version issues. The Hadoop version selected at compile time is
automatically detected based on the output of running <tt class="docutils literal"><span class="pre">hadoop</span> <span class="pre">version</span></tt>.
If this fails for any reason, you can provide the correct version string
through the <tt class="docutils literal"><span class="pre">HADOOP_VERSION</span></tt> environment variable, e.g.:</p>
<div class="highlight-python"><div class="highlight"><pre>export HADOOP_VERSION=&quot;1.0.4&quot;
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="testing-your-installation">
<h2>Testing your Installation<a class="headerlink" href="#testing-your-installation" title="Permalink to this headline">¶</a></h2>
<p>After Pydoop has been successfully installed, you might want to run
unit tests to verify that everything works fine.</p>
<p><strong>IMPORTANT NOTICE:</strong> in order to run HDFS tests you must:</p>
<ol class="arabic">
<li><p class="first">make sure that Pydoop is able to detect your Hadoop home and
configuration directories.  If auto-detection fails, try setting
the <tt class="docutils literal"><span class="pre">HADOOP_HOME</span></tt> and <tt class="docutils literal"><span class="pre">HADOOP_CONF_DIR</span></tt> environment variables
to the appropriate locations;</p>
</li>
<li><p class="first">since one of the test cases tests the connection to an HDFS
instance with <em>explicitly set</em> host and port, if in your case these
are different from, respectively, &#8220;localhost&#8221; and 9000 (8020 for
package-based CDH), you must set the <tt class="docutils literal"><span class="pre">HDFS_HOST</span></tt> and
<tt class="docutils literal"><span class="pre">HDFS_PORT</span></tt> environment variables accordingly;</p>
</li>
<li><p class="first">start HDFS:</p>
<div class="highlight-python"><div class="highlight"><pre>${HADOOP_HOME}/bin/start-dfs.sh
</pre></div>
</div>
</li>
<li><p class="first">wait until HDFS exits from safe mode:</p>
<div class="highlight-python"><div class="highlight"><pre>${HADOOP_HOME}/bin/hadoop dfsadmin -safemode wait
</pre></div>
</div>
</li>
</ol>
<p>To run the unit tests, move to the <tt class="docutils literal"><span class="pre">test</span></tt> subdirectory and run <em>as
the cluster superuser</em> (see below):</p>
<div class="highlight-python"><div class="highlight"><pre>python all_tests.py
</pre></div>
</div>
<div class="section" id="superuser-privileges">
<h3>Superuser Privileges<a class="headerlink" href="#superuser-privileges" title="Permalink to this headline">¶</a></h3>
<p>The following HDFS tests may fail if not run by the cluster superuser:
<tt class="docutils literal"><span class="pre">capacity</span></tt>, <tt class="docutils literal"><span class="pre">chown</span></tt> and <tt class="docutils literal"><span class="pre">used</span></tt>.  To get superuser privileges,
you can either:</p>
<ul class="simple">
<li>start the cluster with your own user account;</li>
<li>edit <tt class="docutils literal"><span class="pre">hdfs-site.xml</span></tt> in your configuration and set the
<tt class="docutils literal"><span class="pre">dfs.permissions.supergroup</span></tt> property to one of your unix groups
(type <tt class="docutils literal"><span class="pre">groups</span></tt> at the command prompt to see to which groups your
account belongs), then restart the Hadoop daemons:</li>
</ul>
<div class="highlight-xml"><div class="highlight"><pre><span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.permissions.supergroup<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>admin<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</pre></div>
</div>
<p>If you can&#8217;t acquire superuser privileges to run the tests, just keep in mind
that the failures reported may be due to this reason.</p>
</div>
<div class="section" id="hadoop-2-2-0">
<h3>Hadoop 2.2.0<a class="headerlink" href="#hadoop-2-2-0" title="Permalink to this headline">¶</a></h3>
<p>In Hadoop 2.2.0 it is necessary to edit <tt class="docutils literal"><span class="pre">hdfs-site.xml</span></tt> and set dfs.namenode.fs-limits.min-block-size to a low value:</p>
<div class="highlight-xml"><div class="highlight"><pre><span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.namenode.fs-limits.min-block-size<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>512<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</pre></div>
</div>
<p>then restart Hadoop daemons.</p>
</div>
<div class="section" id="using-pydoop-with-yarn">
<h3>Using Pydoop with YARN<a class="headerlink" href="#using-pydoop-with-yarn" title="Permalink to this headline">¶</a></h3>
<dl class="docutils">
<dt>Since Hadoop 2.* and CDH 4.* it is possible to run YARN, the next generation MapReduce framework. Using Pydoop with YARN does not require any further configuration &#8211; of course, you need a properly configured Hadoop cluster, see:</dt>
<dd><ul class="first last simple">
<li><a class="reference external" href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html</a></li>
<li><a class="reference external" href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.3.0/CDH4-Installation-Guide/cdh4ig_topic_11_4.html">http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.3.0/CDH4-Installation-Guide/cdh4ig_topic_11_4.html</a></li>
</ul>
</dd>
</dl>
<p class="rubric">Footnotes</p>
<table class="docutils footnote" frame="void" id="id8" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[1]</a></td><td>To make Pydoop work with Python 2.6 you need to install the
following additional modules: <a class="reference external" href="http://pypi.python.org/pypi/importlib">importlib</a> and <a class="reference external" href="http://pypi.python.org/pypi/argparse">argparse</a>.</td></tr>
</tbody>
</table>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pydoop_script.html" title="Pydoop Script User Guide"
             >next</a> |</li>
        <li class="right" >
          <a href="tutorial/mapred_api.html" title="Writing Full-Featured Applications"
             >previous</a> |</li>
	<li><a href="index.html">Home</a>|&nbsp;</li>
	<li><a href="#">Download & Install</a>|&nbsp;</li>
	<li><a href="https://sourceforge.net/projects/pydoop/forums/forum/990018">Support</a>|&nbsp;</li>
	<li><a href="http://sourceforge.net/projects/pydoop/">Pydoop on SF</a></li>
 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2009-2014, CRS4.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>
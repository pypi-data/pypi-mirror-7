<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Ideas List &mdash; Pydoop 0.12.0 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.12.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Pydoop 0.12.0 documentation" href="index.html" />
    <link rel="prev" title="Pydoop for Dumbo Users" href="for_dumbo_users.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="for_dumbo_users.html" title="Pydoop for Dumbo Users"
             accesskey="P">previous</a> |</li>
	<li><a href="index.html">Home</a>|&nbsp;</li>
	<li><a href="installation.html">Download & Install</a>|&nbsp;</li>
	<li><a href="https://sourceforge.net/projects/pydoop/forums/forum/990018">Support</a>|&nbsp;</li>
	<li><a href="http://sourceforge.net/projects/pydoop/">Pydoop on SF</a></li>
 
      </ul>
    </div>

      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.png" alt="Logo"/>
            </a></p>
            <h3><a href="index.html">Table Of Contents</a></h3>
            <ul>
<li><a class="reference internal" href="#">Ideas List</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#new-python-hdfs-library">New Python HDFS library</a></li>
<li><a class="reference internal" href="#alternative-implementation-of-hadoop-pipes">Alternative implementation of Hadoop Pipes</a></li>
<li><a class="reference internal" href="#customizing-inputsplits-in-python">Customizing InputSplits in Python</a></li>
<li><a class="reference internal" href="#python-3-porting">Python 3 porting</a></li>
</ul>
</li>
</ul>

            <h4>Previous topic</h4>
            <p class="topless"><a href="for_dumbo_users.html"
                                  title="previous chapter">Pydoop for Dumbo Users</a></p>

					<h4>Get Pydoop</h4>
					<ul>
						<li> <a href="http://sourceforge.net/projects/pydoop/files/">Download page</a> </li>
						<li> <a href="installation.html"> Installation Instructions </a> </li>
					</ul>

					<h4>Contributors</h4>
					<p class="topless">
					Pydoop is developed by:
					<a href="http://www.crs4.it">
						<img src="_static/crs4.png" alt="CRS4" width="200" height="60" />
					</a>
					</p>

					And generously hosted by:
					<a href="http://sourceforge.net/projects/pydoop">
						<img src="http://sflogo.sourceforge.net/sflogo.php?group_id=536922&amp;type=13" width="120" height="30" 
						alt="Get Pydoop at SourceForge.net. Fast, secure and Free Open Source software downloads" />
					</a>
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms or a module, class or function name.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>


    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="ideas-list">
<span id="id1"></span><h1>Ideas List<a class="headerlink" href="#ideas-list" title="Permalink to this headline">¶</a></h1>
<p>This page contains a list of future development ideas which we
currently can&#8217;t pursue due to lack of resources.  They are accessible
to developers with a good knowledge of Python and Java, possibly in
addition to some degree of familiarity with <a class="reference external" href="http://hadoop.apache.org">Hadoop</a>.  If you find anything you&#8217;d like to work
on, just <a class="reference external" href="https://github.com/crs4/pydoop/fork">fork us on GitHub</a>
and start coding!</p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Pydoop provides a Python MapReduce and HDFS API for Hadoop. Its
current implementation relies on extension modules that wrap Hadoop
Pipes (C++) and libhdfs (C) using <a class="reference external" href="http://www.boost.org/doc/libs/1_55_0/libs/python/doc">Boost.Python</a>.  While this
solution has been effective, it has several important drawbacks.</p>
<p>First, the system incurs the overhead of traversing two language
boundaries: Java to C++ to Python.  This design entails a significant
overhead in type conversion and data copying; moreover, it limits the
types of Python components that can be plugged into the framework and
it complicates the interaction of the client Python code with the
Hadoop framework since much of the API is not exposed through these
levels.</p>
<p>Furthermore, the current design increases the maintenance effort
required to keep Pydoop working with new Hadoop versions.  In fact,
Hadoop Pipes and libhdfs are not maintained with the same level of
care as the rest of the Hadoop code base.  As such, Pydoop needs to
patch and rebuild these components as part of its installation, thus
requiring the Pydoop developers to generate new patches for each new
supported Hadoop version. In addition, building and installing the
binary libraries themselves requires the support if the cluster
administrator which &#8211; especially when summed with the Boost.Python
dependency &#8211; makes installing Pydoop a complicated matter.</p>
<p>For these reasons, we would like to gradually make Pydoop “C++ free”,
with a Python implementation that interfaces directly with the
Java-based Hadoop framework.  Interested in helping out?  The
following ideas take Pydoop in this direction, one step at a time.</p>
</div>
<div class="section" id="new-python-hdfs-library">
<h2>New Python HDFS library<a class="headerlink" href="#new-python-hdfs-library" title="Permalink to this headline">¶</a></h2>
<p>libhdfs is a JNI-based C API for the Hadoop Distributed File System
(HDFS). It provides a simple subset of HDFS APIs to manipulate and
access files and the filesystem structure.  Pydoop wraps libhdfs in
Python, but in doing so it introduces the aforementioned maintenance
and overhead issues.</p>
<p>We would like to change all this and see a new implementation that
wraps the Java HDFS API directly with Python &#8211; using a framework like
<a class="reference external" href="http://jpype.sourceforge.net/">JPype</a>. Such a direct wrapping
should eliminate the main issues highlighted with the current
implementation and allow us to expose the entire functionality
provided by the Java-based API to Python code.</p>
<p><strong>Knowledge prerequisites:</strong> Python, Java, basic knowledge of C/C++</p>
<p><strong>Skill level:</strong> advanced</p>
</div>
<div class="section" id="alternative-implementation-of-hadoop-pipes">
<h2>Alternative implementation of Hadoop Pipes<a class="headerlink" href="#alternative-implementation-of-hadoop-pipes" title="Permalink to this headline">¶</a></h2>
<p>Hadoop Pipes is the C++ interface to Hadoop MapReduce.  Pydoop’s
MapReduce API is currently implemented as a Boost.Python wrapper for
Hadoop Pipes’ C++ API . Hadoop Pipes uses a Java client that launches
an executable and interacts with it through a dedicated protocol. This
solution has some drawbacks.  For instance, piping data to the worker
process incurs data (de)serialization and copying overhead, in
addition to making it difficult to reuse standard InputFormat and
OutputFormat implementations and limiting the framework components
that can be overridden with Python code to the bare minimum.</p>
<p>We would like to have a better solution that implements a custom Java
client that communicates directly with Python to improve performance
and allow for more pythonic code. Frameworks like JPype would allow
pure Python customization of a wider array of MapReduce components.</p>
<p><strong>Knowledge prerequisites:</strong> Python, Java, basic knowledge of C/C++</p>
<p><strong>Skill level:</strong> advanced</p>
</div>
<div class="section" id="customizing-inputsplits-in-python">
<h2>Customizing InputSplits in Python<a class="headerlink" href="#customizing-inputsplits-in-python" title="Permalink to this headline">¶</a></h2>
<p>In the Hadoop workflow, one of the first steps the framework performs
when running a job is to look over the input data and decide how to
split it among a number of independent processing tasks. Within Hadoop
this functionality is implemented in an InputFormat class. Overriding
this class allows you to customize how input files are split &#8211;
information which is captured in a list of InputSplit objects.</p>
<p>At the moment it is not possible to implement your own InputFormat in
Python and plug it into the framework; Java must be used instead. The
idea is to add the feature to Pydoop so that developers could
implement custom input splitting in pure Python, which would
complement the currently available possibility to write a custom
record reader in Python &#8211; i.e., a full input data format
implementation in Python.</p>
<p><strong>Knowledge prerequisites:</strong> Python, Java</p>
<p><strong>Skill level:</strong> medium</p>
</div>
<div class="section" id="python-3-porting">
<h2>Python 3 porting<a class="headerlink" href="#python-3-porting" title="Permalink to this headline">¶</a></h2>
<p>Pydoop currently runs on Python 2.7 (and 2.6, with some backports). It
would be nice to make it available to Python 3 users.</p>
<p><strong>Knowledge prerequisites:</strong> Python 2 (Python 3 is a plus)</p>
<p><strong>Skill level:</strong> basic</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="for_dumbo_users.html" title="Pydoop for Dumbo Users"
             >previous</a> |</li>
	<li><a href="index.html">Home</a>|&nbsp;</li>
	<li><a href="installation.html">Download & Install</a>|&nbsp;</li>
	<li><a href="https://sourceforge.net/projects/pydoop/forums/forum/990018">Support</a>|&nbsp;</li>
	<li><a href="http://sourceforge.net/projects/pydoop/">Pydoop on SF</a></li>
 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2009-2014, CRS4.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>
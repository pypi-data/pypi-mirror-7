<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Pydoop for Dumbo Users &mdash; Pydoop 0.12.0 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.12.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Pydoop 0.12.0 documentation" href="index.html" />
    <link rel="next" title="Ideas List" href="ideas_list.html" />
    <link rel="prev" title="Installation-free Usage" href="self_contained.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="ideas_list.html" title="Ideas List"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="self_contained.html" title="Installation-free Usage"
             accesskey="P">previous</a> |</li>
	<li><a href="index.html">Home</a>|&nbsp;</li>
	<li><a href="installation.html">Download & Install</a>|&nbsp;</li>
	<li><a href="https://sourceforge.net/projects/pydoop/forums/forum/990018">Support</a>|&nbsp;</li>
	<li><a href="http://sourceforge.net/projects/pydoop/">Pydoop on SF</a></li>
 
      </ul>
    </div>

      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.png" alt="Logo"/>
            </a></p>
            <h3><a href="index.html">Table Of Contents</a></h3>
            <ul>
<li><a class="reference internal" href="#">Pydoop for Dumbo Users</a><ul>
<li><a class="reference internal" href="#counting-ips-from-an-apache-access-log">Counting IPs from an Apache Access Log</a><ul>
<li><a class="reference internal" href="#input-from-arbitrary-files">Input from Arbitrary Files</a></li>
<li><a class="reference internal" href="#status-reports-counters-and-configuration-parameters">Status Reports, Counters and Configuration Parameters</a></li>
<li><a class="reference internal" href="#input-and-output-formats">Input and Output Formats</a></li>
<li><a class="reference internal" href="#automatic-deployment-of-python-packages">Automatic Deployment of Python Packages</a></li>
<li><a class="reference internal" href="#performance">Performance</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            <h4>Previous topic</h4>
            <p class="topless"><a href="self_contained.html"
                                  title="previous chapter">Installation-free Usage</a></p>
            <h4>Next topic</h4>
            <p class="topless"><a href="ideas_list.html"
                                  title="next chapter">Ideas List</a></p>

					<h4>Get Pydoop</h4>
					<ul>
						<li> <a href="http://sourceforge.net/projects/pydoop/files/">Download page</a> </li>
						<li> <a href="installation.html"> Installation Instructions </a> </li>
					</ul>

					<h4>Contributors</h4>
					<p class="topless">
					Pydoop is developed by:
					<a href="http://www.crs4.it">
						<img src="_static/crs4.png" alt="CRS4" width="200" height="60" />
					</a>
					</p>

					And generously hosted by:
					<a href="http://sourceforge.net/projects/pydoop">
						<img src="http://sflogo.sourceforge.net/sflogo.php?group_id=536922&amp;type=13" width="120" height="30" 
						alt="Get Pydoop at SourceForge.net. Fast, secure and Free Open Source software downloads" />
					</a>
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms or a module, class or function name.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>


    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="pydoop-for-dumbo-users">
<h1>Pydoop for Dumbo Users<a class="headerlink" href="#pydoop-for-dumbo-users" title="Permalink to this headline">¶</a></h1>
<p>Pydoop is not the only way to write Hadoop applications in Python. The
&#8220;built-in&#8221; solutions are Hadoop Streaming with Python executables and
Jython. The main disadvantages with these approaches are the
following:</p>
<ol class="arabic simple">
<li>Streaming does not provide an API: the developer writes a mapper
and a reducer script that communicate with the framework via
standard input/output. The programming style is therefore rather
awkward, especially in the case of reducers, where developers must
manually handle key switching. More importantly, there is no way to
write a Python RecordReader, RecordWriter or Partitioner. In Hadoop
versions that do not include the <a class="reference external" href="https://issues.apache.org/jira/browse/HADOOP-1722">HADOOP-1722</a> patch,
Streaming has the additional limitation of only being able to
process UTF-8 text records;</li>
<li>Jython is a Java implementation of the Python language: the
standard C implementation, in cases where ambiguity may arise, is
referred to as &#8220;CPython&#8221;. Although this approach gives access to
the full Hadoop API, it is limited by the fact that CPython
modules (including part of the standard library) cannot be used.</li>
</ol>
<p>As a consequence, few Python programmers use Streaming or Jython
directly. A popular alternative is offered by <a class="reference external" href="http://klbostee.github.com/dumbo">Dumbo</a>, a programming framework built as
a wrapper around Streaming that allows for a more elegant coding style
and also includes facilities to make job running easier. Its author,
Klaas Bosteels, is also the author of the aforementioned patch for
Streaming.</p>
<p>However, writing Python components other than the mapper, reducer and
combiner is not possible in Dumbo, and there is no HDFS API. Pydoop,
on the other hand, gives you almost complete access to MapReduce
components (you can write a Python RecordReader, RecordWriter and
Partitioner) and to HDFS without adding much complexity. As an
example, in this section we will show how to rewrite Dumbo&#8217;s tutorial
example in Pydoop. Throughout the rest of this section we refer to
examples and results from Dumbo version 0.21.28.</p>
<div class="section" id="counting-ips-from-an-apache-access-log">
<h2>Counting IPs from an Apache Access Log<a class="headerlink" href="#counting-ips-from-an-apache-access-log" title="Permalink to this headline">¶</a></h2>
<p>The <tt class="docutils literal"><span class="pre">examples</span></tt> directory includes a Pydoop reimplementation of
<a class="reference external" href="http://wiki.github.com/klbostee/dumbo/short-tutorial">Dumbo&#8217;s tutorial example</a>, an
application for generating a list of the IPs that occur more
frequently in an <a class="reference external" href="http://httpd.apache.org/docs/1.3/logs.html#common">Apache access log</a>.</p>
<p>The Dumbo MapReduce code for the basic example is:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">mapper</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
  <span class="k">yield</span> <span class="n">value</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot; &quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">reducer</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
  <span class="k">yield</span> <span class="n">key</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="p">:</span>
  <span class="kn">import</span> <span class="nn">dumbo</span>
  <span class="n">dumbo</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">mapper</span><span class="p">,</span> <span class="n">reducer</span><span class="p">,</span> <span class="n">combiner</span><span class="o">=</span><span class="n">reducer</span><span class="p">)</span>
</pre></div>
</div>
<p>and it is run with:</p>
<div class="highlight-python"><div class="highlight"><pre>dumbo start ipcount.py -input access.log -output ipcounts
dumbo cat ipcounts | sort -k2,2nr | head -n 5
</pre></div>
</div>
<p>With Pydoop, we could implement the above program using
<a class="reference internal" href="tutorial/pydoop_script.html#pydoop-script-tutorial"><em>Easy Hadoop Scripting with Pydoop Script</em></a>.  Write an <tt class="docutils literal"><span class="pre">ipcount_script.py</span></tt> module:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">mapper</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">writer</span><span class="p">):</span>
  <span class="n">writer</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot; &quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">reducer</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">itervalues</span><span class="p">,</span> <span class="n">writer</span><span class="p">):</span>
  <span class="n">writer</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">itervalues</span><span class="p">)))</span>
</pre></div>
</div>
<p>Then, run it with:</p>
<div class="highlight-python"><div class="highlight"><pre>pydoop script ipcount_script.py access.log ipcounts
hadoop fs -cat output/part* | sort -k2,2nr | head -n 5
</pre></div>
</div>
<p>It should be noted that Pydoop Script doesn&#8217;t allow you to set a combiner
class, nor to tackle more sophisticated problems, perhaps where you would need
to track a state within your mapper or reducer objects.  If you need that sort
of functionality then step up to the full Pydoop framework.  In that case, you
would implement the program above as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c">#!/usr/bin/env python</span>

<span class="kn">import</span> <span class="nn">pydoop.pipes</span> <span class="kn">as</span> <span class="nn">pp</span>

<span class="k">class</span> <span class="nc">Mapper</span><span class="p">(</span><span class="n">pp</span><span class="o">.</span><span class="n">Mapper</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="n">context</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">getInputValue</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot; &quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&quot;1&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Reducer</span><span class="p">(</span><span class="n">pp</span><span class="o">.</span><span class="n">Reducer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">reduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">context</span><span class="o">.</span><span class="n">nextValue</span><span class="p">():</span>
      <span class="n">s</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">getInputValue</span><span class="p">())</span>
    <span class="n">context</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">getInputKey</span><span class="p">(),</span> <span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="p">:</span>
  <span class="n">pp</span><span class="o">.</span><span class="n">runTask</span><span class="p">(</span><span class="n">pp</span><span class="o">.</span><span class="n">Factory</span><span class="p">(</span><span class="n">Mapper</span><span class="p">,</span> <span class="n">Reducer</span><span class="p">,</span> <span class="n">combiner_class</span><span class="o">=</span><span class="n">Reducer</span><span class="p">))</span>
</pre></div>
</div>
<p>To run the application, save the above code to <tt class="docutils literal"><span class="pre">ipcount_pydoop.py</span></tt> and run:</p>
<div class="highlight-python"><div class="highlight"><pre>hadoop fs -put ipcount_pydoop.py ipcount_pydoop.py
hadoop pipes \
  -D hadoop.pipes.java.recordreader=true \
  -D hadoop.pipes.java.recordwriter=true \
  -program ipcount_pydoop.py \
  -input access.log \
  -output ipcounts
hadoop fs -cat output/part* | sort -k2,2nr | head -n 5
</pre></div>
</div>
<p>It&#8217;s easy enough to wrap all steps needed to execute the application
in a driver Python script with a nice command line interface: an
example is given in the <tt class="docutils literal"><span class="pre">examples/ipcount</span></tt>
directory. In particular, by leveraging Pydoop&#8217;s HDFS API,
manipulation of output files such as the one performed by the last
command and HDFS uploads can be done within Python, without any need
to call the Hadoop command line programs:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">collect_output</span><span class="p">(</span><span class="n">mr_out_dir</span><span class="p">):</span>
  <span class="n">ip_list</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">hdfs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="n">mr_out_dir</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">hdfs</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">&quot;part&quot;</span><span class="p">):</span>
      <span class="k">with</span> <span class="n">hdfs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
          <span class="n">ip</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\t</span><span class="s">&quot;</span><span class="p">)</span>
          <span class="n">ip_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">ip</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">count</span><span class="p">)))</span>
  <span class="k">return</span> <span class="n">ip_list</span>

<span class="n">ip_list</span> <span class="o">=</span> <span class="n">collect_output</span><span class="p">(</span><span class="s">&quot;ipcounts&quot;</span><span class="p">)</span>
<span class="n">ip_list</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">operator</span><span class="o">.</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ip</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">ip_list</span><span class="p">[:</span><span class="mi">5</span><span class="p">]:</span>
  <span class="k">print</span> <span class="s">&quot;</span><span class="si">%s</span><span class="se">\t</span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ip</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span>
</pre></div>
</div>
<p>To run the example, do the following (from Pydoop&#8217;s distribution root):</p>
<div class="highlight-python"><div class="highlight"><pre>cd examples/ipcount
./run
</pre></div>
</div>
<div class="section" id="input-from-arbitrary-files">
<h3>Input from Arbitrary Files<a class="headerlink" href="#input-from-arbitrary-files" title="Permalink to this headline">¶</a></h3>
<p>The next step in the Dumbo tutorial shows how to get additional input
from arbitrary files. Specifically, the application reads a file
containing a list of IP addresses that must not be taken into account
when building the top five list:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">Mapper</span><span class="p">:</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;excludes.txt&quot;</span><span class="p">,</span> <span class="s">&quot;r&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">excludes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">file</span><span class="p">)</span>
    <span class="nb">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">ip</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot; &quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ip</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">excludes</span><span class="p">:</span>
      <span class="k">yield</span> <span class="n">ip</span><span class="p">,</span> <span class="mi">1</span>
</pre></div>
</div>
<p>Pydoop&#8217;s implementation is quite similar:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">Mapper</span><span class="p">(</span><span class="n">pp</span><span class="o">.</span><span class="n">Mapper</span><span class="p">):</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Mapper</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;excludes.txt&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">excludes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="n">ip</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">getInputValue</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">ip</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">excludes</span><span class="p">:</span>
      <span class="n">context</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="n">ip</span><span class="p">,</span> <span class="s">&quot;1&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The main difference lies in the way you distribute the &#8220;exclude.txt&#8221;
file to all cluster nodes. Dumbo takes advantage of Streaming&#8217;s
<tt class="docutils literal"><span class="pre">-file</span></tt> option which, in turn, uses <a class="reference external" href="http://hadoop.apache.org/common/docs/r0.20.2/mapred_tutorial.html#DistributedCache">Hadoop&#8217;s distributed cache</a>:</p>
<div class="highlight-python"><div class="highlight"><pre>$ dumbo start ipcount.py -input access.log -output ipcounts -file excludes.txt
</pre></div>
</div>
<p>In the case of Pydoop, you can use the distributed cache by setting
the following configuration parameters in your XML conf file:</p>
<div class="highlight-xml"><div class="highlight"><pre><span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>mapred.cache.files<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>excludes.txt#excludes.txt<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>mapred.create.symlink<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>yes<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</pre></div>
</div>
<p>Alternatively, you can set them directly as command line options for
pipes, by adding <tt class="docutils literal"><span class="pre">-D</span> <span class="pre">mapred.cache.files=excludes.txt#excludes.txt</span> <span class="pre">-D</span>
<span class="pre">mapred.create.symlink=yes</span></tt> right after the <tt class="docutils literal"><span class="pre">pipes</span></tt> command. The
latter approach is the one we used in the example (check the code for
details):</p>
<div class="highlight-python"><div class="highlight"><pre>cd examples/ipcount
python ipcount.py -e excludes.txt -i access.log -n 5
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">-e</span></tt> option is turned into a MapReduce JobConf parameter by the
Python code. In the next section we will see how JobConf parameters
are passed to the MapReduce application in both Dumbo and Pydoop.</p>
</div>
<div class="section" id="status-reports-counters-and-configuration-parameters">
<h3>Status Reports, Counters and Configuration Parameters<a class="headerlink" href="#status-reports-counters-and-configuration-parameters" title="Permalink to this headline">¶</a></h3>
<p>Being built as a wrapper around Streaming, Dumbo sends status reports
and counter updates to the framework via standard error. This is,
however, hidden from the programmer:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">Mapper</span><span class="p">:</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="s">&quot;Initialization started&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">excludes_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">&quot;excludes&quot;</span><span class="p">]</span>
    <span class="nb">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">excludes_fn</span><span class="p">,</span> <span class="s">&quot;r&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">excludes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">file</span><span class="p">)</span>
    <span class="nb">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="s">&quot;Initialization done&quot;</span>

  <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">ip</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot; &quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ip</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">excludes</span><span class="p">:</span>
      <span class="k">yield</span> <span class="n">ip</span><span class="p">,</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">counters</span><span class="p">[</span><span class="s">&quot;Excluded lines&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>In Dumbo, values for parameters are supplied via the <tt class="docutils literal"><span class="pre">-param</span></tt>
option: in this case, for instance, you would add <tt class="docutils literal"><span class="pre">-param</span>
<span class="pre">excludes=excludes.txt</span></tt> to Dumbo&#8217;s command line.</p>
<p>The Pydoop equivalent of the above is:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">Mapper</span><span class="p">(</span><span class="n">pp</span><span class="o">.</span><span class="n">Mapper</span><span class="p">):</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Mapper</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
    <span class="n">context</span><span class="o">.</span><span class="n">setStatus</span><span class="p">(</span><span class="s">&quot;Initialization started&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">excluded_counter</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">getCounter</span><span class="p">(</span><span class="s">&quot;IPCOUNT&quot;</span><span class="p">,</span> <span class="s">&quot;EXCLUDED_LINES&quot;</span><span class="p">)</span>
    <span class="n">jc</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">getJobConf</span><span class="p">()</span>
    <span class="n">pu</span><span class="o">.</span><span class="n">jc_configure</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">jc</span><span class="p">,</span> <span class="s">&quot;ipcount.excludes&quot;</span><span class="p">,</span> <span class="s">&quot;excludes_fn&quot;</span><span class="p">,</span> <span class="s">&quot;&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">excludes_fn</span><span class="p">:</span>
      <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">excludes_fn</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">excludes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">excludes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">context</span><span class="o">.</span><span class="n">setStatus</span><span class="p">(</span><span class="s">&quot;Initialization done&quot;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="n">ip</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">getInputValue</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">ip</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">excludes</span><span class="p">:</span>
      <span class="n">context</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="n">ip</span><span class="p">,</span> <span class="s">&quot;1&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">context</span><span class="o">.</span><span class="n">incrementCounter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">excluded_counter</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">ipcount.excludes</span></tt> parameter is passed in the same way as any
other configuration parameter (see the distributed cache example in
the previous section).</p>
</div>
<div class="section" id="input-and-output-formats">
<h3>Input and Output Formats<a class="headerlink" href="#input-and-output-formats" title="Permalink to this headline">¶</a></h3>
<p>Just like Dumbo, Pydoop has currently no support for writing Python
input and output format classes (however, unlike Dumbo, Pydoop allows
you to write record readers/writers). You can use Java input/output
formats by setting the <tt class="docutils literal"><span class="pre">mapred.input.format.class</span></tt> and the
<tt class="docutils literal"><span class="pre">mapred.output.format.class</span></tt> properties: see
<a class="reference internal" href="examples/sequence_file.html"><em>Using the Hadoop SequenceFile Format</em></a> for an example. Note that if you write
your own Java input/output format class, you need to pass the
corresponding jar file name to pipes via the <tt class="docutils literal"><span class="pre">-jar</span></tt> option.</p>
</div>
<div class="section" id="automatic-deployment-of-python-packages">
<h3>Automatic Deployment of Python Packages<a class="headerlink" href="#automatic-deployment-of-python-packages" title="Permalink to this headline">¶</a></h3>
<p>Dumbo includes a <tt class="docutils literal"><span class="pre">-libegg</span></tt> option for automatic distribution of
<a class="reference external" href="http://peak.telecommunity.com/DevCenter/PythonEggs">Python eggs</a>. For an example
on how to distribute arbitrary Python packages, possibly including
Pydoop itself, to all cluster nodes, see <a class="reference internal" href="self_contained.html"><em>Installation-free Usage</em></a>.</p>
</div>
<div class="section" id="performance">
<h3>Performance<a class="headerlink" href="#performance" title="Permalink to this headline">¶</a></h3>
<p>We tested Pydoop (version 0.3.6) and Dumbo (version 0.21.28) with
their respective wordcount examples. The test we ran was very similar
to the one described in <a class="footnote-reference" href="#pydoop" id="id1">[1]</a> (wordcount on 20 GB of random
English text &#8211; average completion time over five iterations), but
this time we used only 48 CPUs distributed over 24 nodes and a block
size of 64 MB. In <a class="footnote-reference" href="#pydoop" id="id2">[1]</a> we found out that pre-HADOOP-1722
Streaming was about 2.6 times slower than Pydoop, while in this test
Dumbo was only 1.9 times slower.</p>
<p class="rubric">Footnotes</p>
<table class="docutils footnote" frame="void" id="pydoop" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id1">1</a>, <a class="fn-backref" href="#id2">2</a>)</em> Simone Leo, Gianluigi Zanetti. <a class="reference external" href="http://dx.doi.org/10.1145/1851476.1851594">Pydoop: a Python
MapReduce and HDFS API for Hadoop.</a>, Proceedings Of The
19th ACM International Symposium On High Performance Distributed
Computing, page 819&#8211;825, 2010</td></tr>
</tbody>
</table>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="ideas_list.html" title="Ideas List"
             >next</a> |</li>
        <li class="right" >
          <a href="self_contained.html" title="Installation-free Usage"
             >previous</a> |</li>
	<li><a href="index.html">Home</a>|&nbsp;</li>
	<li><a href="installation.html">Download & Install</a>|&nbsp;</li>
	<li><a href="https://sourceforge.net/projects/pydoop/forums/forum/990018">Support</a>|&nbsp;</li>
	<li><a href="http://sourceforge.net/projects/pydoop/">Pydoop on SF</a></li>
 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2009-2014, CRS4.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>
import os
from glob import glob
from util import *
from LogParser import *
from FileWriter import *

class EventBuilder(object):
    """passes a list of files to the appropriate LogParser
    subclass to get a list of dictionaries representing rows
    of the log file, then passes those lists to self.events_for_rows()
    to generate a list of dictionaries representing events.

    The start of a new file is always the start of a new run.
    If run_field is set, we'll also break up the files into sections
    with identical values for that field. Take note, we'll do this by
    stepping through the rows in sequence, and looking for changes in
    the field's value. This means that if the field has value A, then B,
    then A again, you will get three runs out of that file. This would
    be a weird thing to have happen in your file, but be forewarned.

    Note that we'll take care of adding the duration of the preceding
    runs to any onsets provided. Just implement duration_for_run(), and
    we'll handle the rest. That means that if you're going to be
    concatenating runs, you only need to provide onsets relative to the
    beginning of the run.

    Supported output formats include 'spm', 'fidl', 'pickle'

    # TODO: More doco

    # TODO: look for multiple runs in the same file if you have run_field
    """
    subjects = None
    data_glob_templates = None
    run_field = None
    output_dir = None
    concat_sets = None
    output_formats = None
    current_sub = None
    sub_data = None

    def __init__(self,*args,**kwargs):
        self.output_dir = os.path.join(os.getcwd(), 'events_parsed')
        self.output_formats = ['pickle']
        self.last_event_sets = None
        self.skip_output = False
        self.sub_data = {}
        super(EventBuilder, self).__init__()
    
    def run(self):
        self.check_settings()
        # convert raw logs per subject
        self.sub_data = {}
        for sub in self.subjects:
            self.current_sub = sub
            # so subclasses can do... whatever
            self.pre_subj_setup()
            # gather all of the raw files
            gs = [temp % sub for temp in self.data_glob_templates]
            raw_bs = []
            for g in gs:
                raw_bs += glob(g)
            if not raw_bs:
                print "Couldn't find any files for subject %s" % str(sub)
                continue
            # make sure we've got a subject output dir
            sub_dir = os.path.join(self.output_dir, str(sub))
            if not self.skip_output:
                ensure_dir(sub_dir, overwrite=True)
            # parse all of the files... memory intensive, but hey
            data = [LogParser.parse_file(bs) for bs in raw_bs]
            # break the files into runs. should come back as:
            # [[f1_run1_rows_list, f1_run2_rows_list], [f2_run1_rows_list], ...]
            data_runs_separated = [self.separate_runs(fd) for fd in data]
            concat_needed = self.concat_sets != None and len(self.concat_sets) > 0
            forced_concat = 'fidl' in self.output_formats # fidl has to have concatenated runs
            event_lists = []
            durations = []
            r = 0
            for i, file_rows in enumerate(data_runs_separated):
                for run_rows in file_rows:
                    self.handle_run_start(r, run_rows, raw_bs[i])
                    es = self.events_for_rows(run_rows)
                    if es == None:
                        es = []
                    event_lists.append(es)
                    # if we're going to concat, we'll need a duration for each of the files
                    if concat_needed or forced_concat:
                        durations.append(self.duration_for_run(r, raw_bs[i], data[i], es))
                    self.handle_run_end(r, run_rows, raw_bs[i])
                    r += 1
            # make sure all of the events belong to a set
            check_events_for_set_names(event_lists)
            # get all of the unique event set names
            eset_names = get_all_event_set_names(event_lists)
            # make a dict whose keys are set names, and whose values are lists of lists of event dicts
            event_sets = events_to_event_sets(event_lists, eset_names)
            # concatenate any sets that need concatenation
            forced_concat_events = {}
            if forced_concat:
                for set_name in event_sets.keys():
                    forced_concat_events[set_name] = concat_event_lists(event_sets[set_name], durations)
            if concat_needed:
                for set_name in event_sets.keys():
                    if not set_name in self.concat_sets:
                        continue
                    event_sets[set_name] = concat_event_lists(event_sets[set_name], durations)
            # write each of the requested file formats, plus a pickle format
            if not self.skip_output:
                for set_name in event_sets.keys():
                    set_dir = os.path.join(sub_dir, set_name)
                    ensure_dir(set_dir)
                    ofs = self.output_formats
                    if not 'pickle' in ofs:
                        ofs.append('pickle')
                    for format in ofs:
                        FileWriter.write_set(format, event_sets[set_name], set_dir, forced_concat_events.get(set_name,None), **self.get_write_args())
            self.sub_data[sub] = event_sets
        self.current_sub = None

    def separate_runs(self, dict_list):
        if self.run_field == None or self.run_field not in dict_list[0].keys():
            return [dict_list]
        r_val = dict_list[0][self.run_field]
        runs = [[]]
        for d in dict_list:
            if d[self.run_field] != r_val:
                r_val = d[self.run_field]
                runs.append([])
            runs[-1].append(d)
        return runs

    def check_settings(self):
        if self.output_dir == None:
            raise ValueError("output_dir must be set")
        if self.data_glob_templates == None:
            raise ValueError("data_glob_templates must be set")
        if self.output_formats == None:
            raise ValueError("output_formats must be set")
        if self.subjects == None or len(self.subjects) == 0:
            raise ValueError("no subjects to convert...")
        pass

    def pre_subj_setup(self):
        self._run_num = 0

    """ OVERRIDE IN SUBCLASSES """

    def events_for_rows(self, rows):
        """ events_for_rows() should return a list of dictionaries with the keys:
        {set:(string) name:(string), onset:(float)seconds, duration:(float)seconds}
        'set' is the name of the event set. sets will be saved into separate folders.
        This is so you can use one EventBuilder to create multiple event sets, for 
        example, you might want one set listing all events with duration 0, and another
        that lists block events with their true durations.
        The rows will always be from the same trial.
        """
        raise NotImplementedError()

    def duration_for_run(self, run_idx, file_name, raw_rows, events):
        """ return duration of the given run in seconds.
        only needed if you're concatenating files, or using fidl output
        """
        raise NotImplementedError()

    def get_write_args(self):
        """return a dict of extra args to be passed to write_set().
        eg. 'tr' if you want to write fidl files
        """
        return {}

    def handle_run_start(self, run_idx, run_data, file_name):
        """do anything you need to do at the start of a run.
        a good example is setting aside some time that you'd like to use as
        the run's '0' point, which you'll subtract from the onset time of all
        events in the run.
        """
        pass

    def handle_run_end(self, run_idx, run_data, file_name):
        """do anything you need to do at the end of a run."""
        pass

class fMRI_EventBuilder(EventBuilder):
    """a variant with some features specific to fMRI.
    These include the use of TR to calculate run durations, and passing
    TR to write_set so we can write fidl files.
    """
    def duration_for_run(self, run_idx, file_name, raw_rows, events):
        return self.tr_count_for_run(run_idx, file_name, raw_rows, events) * self.get_tr()

    def get_write_args(self):
        return {'tr':self.get_tr()}

    """ OVERRIDE IN SUBCLASSES """

    def tr_count_for_run(self, run_idx, file_name, raw_rows, events):
        """ return the TR count for the given run. """
        raise NotImplementedError()

    def get_tr(self):
        """ return the TR used for bold runs """
        raise NotImplementedError()    

class TrialWise_EventBuilder(EventBuilder):
    """a variant that collects events by run.
    
    Main changes are that you should override events_for_trial() as your main
    event returning method, and you can provide a value for trial_field to
    separate each run into trials, the same way the main class uses run_field
    to separate runs.
    
    """
    trial_field = None
    def events_for_rows(self, rows):
        es = []
        trials = self.separate_trials(rows)
        for i, t in enumerate(trials):
            t_es = self.events_for_trial(i, t)
            if t_es != None and len(t_es) > 0:
                es.extend(t_es)
        return es

    def separate_trials(self, dict_list):
        if self.trial_field == None or self.trial_field not in dict_list[0].keys():
            return [dict_list]
        r_val = dict_list[0][self.trial_field]
        runs = [[]]
        for d in dict_list:
            if d[self.trial_field] != r_val:
                r_val = d[self.trial_field]
                runs.append([])
            runs[-1].append(d)
        return runs

    """ OVERRIDE IN SUBCLASSES """

    def events_for_trial(self, trial_idx, trial_rows):
        raise NotImplementedError()
        
class RowWise_EventBuilder(EventBuilder):
    """a variant that collects events by row.
    Take note that this is a subclass of Runwise_EventBuilder, so you also
    have the option to implement handle_run_start() and handle_run_end().
    # TODO: More doco on how to subclass.
    """
    def events_for_rows(self, rows):
        es = []
        for r in rows:
            r_es = self.events_for_row(r)
            if r_es != None and len(r_es) > 0:
                es.extend(r_es)
        return es

    """ OVERRIDE IN SUBCLASSES """

    def events_for_row(self, row_dict):
        """return an array containing any number of events.
        This is the heart of this class. We'll call this from within
        events_for_rows(). You might use this method to check the row for values
        that signify an event of interest, its onset time, and its duration.
        """
        return []

class RowWise_fMRI_EventBuilder(fMRI_EventBuilder, RowWise_EventBuilder):
     """a variant that combines rowwise and fmri-specific features
     The choice you'll probably want to make if you're implementing a behavioral
     log parser as part of an fMRI experiment. You'll most likely want to override
     events_for_row() and perhaps handle_run_start(). See doco on the two
     superclasses FMI.
     """
     def __init__(self):
         super(RowWise_fMRI_EventBuilder, self).__init__()
          

def events_to_event_sets(dict_lists, set_names):
    sets = {}
    for s_name in set_names:
        sets[s_name] = []
    for d_list in dict_lists:
        for s_name in set_names:
            sets[s_name].append([])
        for d in d_list:
            dc = dict(d)
            s = dc['set']
            del dc['set']
            sets[s][-1].append(dc)
    return sets

def get_all_event_set_names(dict_lists):
    names = []
    for d_list in dict_lists:
        for d in d_list:
            if d['set'] not in names:
                names.append(d['set'])
    return names

def check_events_for_set_names(dict_lists):
    if not all(['set' in d for d_list in dict_lists for d in d_list]):
        raise ValueError('All events must have a value for key "set". '+
                         'Check your event definitions!')

def concat_event_lists(event_lists, durations):
    new_list = []
    d = 0
    for i, e_list in enumerate(event_lists):
        if i > 0:
            d += durations[i-1]
        for e in e_list:
            ec = dict(e)
            ec['onset'] += d
            new_list.append(ec)
    return [new_list]

